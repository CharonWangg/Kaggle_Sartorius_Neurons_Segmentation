{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "import pycocotools\n",
    "from pycocotools import mask\n",
    "import random\n",
    "import cv2\n",
    "import re\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def random_seed(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def flatten_l_o_l(nested_list):\n",
    "    \"\"\" Flatten a list of lists \"\"\"\n",
    "    return [item for sublist in nested_list for item in sublist]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def load_json_to_dict(json_path):\n",
    "    \"\"\" tbd \"\"\"\n",
    "    with open(json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def get_img_and_mask(img_path, annotation, width, height):\n",
    "    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n",
    "    img_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for i, annot in enumerate(annotation): \n",
    "        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n",
    "    img = cv2.imread(img_path)[..., ::-1]\n",
    "    return img[..., 0], img_mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "config = {'width':704,'height':520,'seed':42,'folds':5}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "train_df = pd.read_csv('/home/data1/hanfeng/code/kaggle/kaggle-Sartorius-main/swin-mmdet/dataset/train.csv')\n",
    "lines = []\n",
    "for f in train_df.itertuples():\n",
    "    lines.append('../input/sartorius-cell-instance-segmentation/train/' + f[1] + '.png')\n",
    "lins = pd.Series(lines, name='img_path')\n",
    "train_df = pd.concat([train_df, lins], axis=1)\n",
    "\n",
    "tmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\n",
    "tmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\n",
    "train_df = tmp_df.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "random_seed(config['seed'])\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "Fold = KFold(n_splits=config['folds'], shuffle=True, random_state=42)\n",
    "train_df['fold'] = -1\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train_df)):\n",
    "    train_df.iloc[val_index,-1] = int(n)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def get_img_and_annot_info(df,annot_id_start=1):\n",
    "    for f in df.itertuples():\n",
    "        image_id = f[1]\n",
    "        file_path = f[-2]\n",
    "        width = f[3]\n",
    "        height = f[4]\n",
    "        category = categories[f[5]]\n",
    "        image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"file_name\": file_path,\n",
    "        }\n",
    "        output_json_dict['images'].append(image_info)\n",
    "        for annot in np.unique(f[2]):\n",
    "            annotation = rle_decode(annot, (config['height'], config['width']))\n",
    "            _, count = np.unique(annotation, return_counts=True)\n",
    "            annot_mask = annotation.astype(np.bool)\n",
    "            annot_mask = np.asfortranarray(annot_mask)\n",
    "            Rs = mask.encode(annot_mask)\n",
    "            Rs['counts'] = Rs['counts'].decode('utf-8')\n",
    "            bbox = mask.toBbox(Rs)\n",
    "            bbox_list = []\n",
    "            for element in bbox:\n",
    "                bbox_list.append(int(element))\n",
    "            annot_dict = {\n",
    "                \"category_id\": category,\n",
    "                \"segmentation\": Rs,\n",
    "                \"area\": int(mask.area(Rs)),\n",
    "                \"bbox\": bbox_list,\n",
    "                \"id\": annot_id_start,\n",
    "                \"image_id\": image_id,\n",
    "                \"iscrowd\": 0}\n",
    "            output_json_dict[\"annotations\"].append(annot_dict)\n",
    "            annot_id_start += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "categories = {\"cort\": 2, \"shsy5y\": 1, \"astro\": 3}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def get_img_and_annot_info(df,output_json_dict,annot_id_start=1):\n",
    "    for f in df.itertuples():\n",
    "        image_id = f[0]\n",
    "        file_path = f[-2]\n",
    "        width = f[3]\n",
    "        height = f[4]\n",
    "        category = categories[f[5]]\n",
    "        image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"file_name\": file_path,\n",
    "        }\n",
    "        output_json_dict['images'].append(image_info)\n",
    "        for annot in np.unique(f[2]):\n",
    "            annotation = rle_decode(annot, (config['height'], config['width']))\n",
    "            _, count = np.unique(annotation, return_counts=True)\n",
    "            annot_mask = annotation.astype(np.bool)\n",
    "            annot_mask = np.asfortranarray(annot_mask)\n",
    "            Rs = mask.encode(annot_mask)\n",
    "            Rs['counts'] = Rs['counts'].decode('utf-8')\n",
    "            bbox = mask.toBbox(Rs)\n",
    "            bbox_list = []\n",
    "            for element in bbox:\n",
    "                bbox_list.append(int(element))\n",
    "            annot_dict = {\n",
    "                \"category_id\": category,\n",
    "                \"segmentation\": Rs,\n",
    "                \"area\": int(mask.area(Rs)),\n",
    "                \"bbox\": bbox_list,\n",
    "                \"id\": annot_id_start,\n",
    "                \"image_id\": image_id,\n",
    "                \"iscrowd\": 0}\n",
    "            output_json_dict[\"annotations\"].append(annot_dict)\n",
    "            annot_id_start += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from copy import deepcopy\n",
    "for fold in range(config['folds']):\n",
    "    trn_idx = train_df[train_df['fold'] != fold].index\n",
    "    val_idx = train_df[train_df['fold'] == fold].index\n",
    "\n",
    "    train_folds = deepcopy(train_df.loc[trn_idx].reset_index(drop=True))\n",
    "    valid_folds = deepcopy(train_df.loc[val_idx].reset_index(drop=True))\n",
    "    \n",
    "    final_train = deepcopy(train_folds)\n",
    "    final_eval = deepcopy(valid_folds)\n",
    "\n",
    "    output_json_dict = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    category_dict = {\"id\": 1, \"name\": \"shsy5y\", \"supercategory\": \"none\"}\n",
    "    output_json_dict[\"categories\"].append(category_dict)\n",
    "    category_dict = {\"id\": 2, \"name\": \"cort\", \"supercategory\": \"none\"}\n",
    "    output_json_dict[\"categories\"].append(category_dict)\n",
    "    category_dict = {\"id\": 3, \"name\": \"astro\", \"supercategory\": \"none\"}\n",
    "    output_json_dict[\"categories\"].append(category_dict)\n",
    "\n",
    "    get_img_and_annot_info(final_train,output_json_dict)\n",
    "    with open(f'{fold}_new_train_dataset.json', 'w') as f:\n",
    "        output_json = json.dumps(output_json_dict)\n",
    "        f.write(output_json)\n",
    "        f.close()\n",
    "\n",
    "    output_json_dict = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [], \n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    category_dict = {\"id\": 1, \"name\": \"shsy5y\", \"supercategory\": \"none\"}\n",
    "    output_json_dict[\"categories\"].append(category_dict)\n",
    "    category_dict = {\"id\": 2, \"name\": \"cort\", \"supercategory\": \"none\"}\n",
    "    output_json_dict[\"categories\"].append(category_dict)\n",
    "    category_dict = {\"id\": 3, \"name\": \"astro\", \"supercategory\": \"none\"}\n",
    "    output_json_dict[\"categories\"].append(category_dict)\n",
    "\n",
    "    get_img_and_annot_info(final_eval,output_json_dict)\n",
    "    with open(f'{fold}_new_val_dataset.json', 'w') as f:\n",
    "        output_json = json.dumps(output_json_dict)\n",
    "        f.write(output_json)\n",
    "        f.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/data1/hanfeng/envs/anaconda3/envs/torch1.7/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('torch1.7': conda)"
  },
  "interpreter": {
   "hash": "5e1d2f57f8a5fc0e95294f65a91b9e32dfc981d54334eb83a699b998be9b830b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}