{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "GS-wk4MOLgU7",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-u4kiogyc\n",
      "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-u4kiogyc\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (8.3.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (3.4.2)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.3.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.8.9)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (4.53.0)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (2.5.0)\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.18.2)\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (1.4.2)\n",
      "Collecting omegaconf>=2.1\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting black==21.4b2\n",
      "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex>=2020.1.8 in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (2021.4.4)\n",
      "Collecting pathspec<1,>=0.8.1\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n",
      "Requirement already satisfied: toml>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (0.10.2)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.4.1)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.8/site-packages (from pycocotools>=2.0.2->detectron2==0.6) (49.6.0.post20210108)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.8/site-packages (from pycocotools>=2.0.2->detectron2==0.6) (0.28.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.38.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (3.17.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.30.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.36.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.13.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.1.1)\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, pycocotools, termcolor\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=7338214 sha256=cd21645f934dfebeb2c8b38216ec544d6e02531400c602ec436a0ca26837f46a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xi72arzr/wheels/19/ac/65/e48e5e4ec2702274d927c5a6efb75709b24014371d3bb778f2\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60943 sha256=5f87647841266a5c0a4ddd439f5949391ce3de895788475441036ab6030b2a96\n",
      "  Stored in directory: /home/.cache/pip/wheels/2e/af/94/f7fe3caa2a9b593e13e495d93c43c3245e3b01ee7b069010bc\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=c906714b5affcfa60153f7c16cabed55cc9df080e5b01e372aa3af9ff104b477\n",
      "  Stored in directory: /home/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.3-cp38-cp38-linux_x86_64.whl size=422828 sha256=c052691fba3c55e179c266d4180fdf108f6665487217c861ad4ec3d3d7268ea6\n",
      "  Stored in directory: /home/.cache/pip/wheels/59/5b/26/04441bc1820bf3622e0ea8616bef01b02cad3415ad880b834a\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=fdde3d78f94d6d7318da5b0d8a408ec2c5ca6c7e88dd50952bc81235ab9da500\n",
      "  Stored in directory: /home/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime pycocotools termcolor\n",
      "Installing collected packages: portalocker, antlr4-python3-runtime, termcolor, pathspec, omegaconf, mypy-extensions, iopath, importlib-resources, pycocotools, hydra-core, fvcore, cloudpickle, black, detectron2\n",
      "  Attempting uninstall: pycocotools\n",
      "    Found existing installation: pycocotools 2.0+nv0.5.1\n",
      "    Uninstalling pycocotools-2.0+nv0.5.1:\n",
      "      Successfully uninstalled pycocotools-2.0+nv0.5.1\n",
      "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 cloudpickle-2.0.0 detectron2-0.6 fvcore-0.1.5.post20211023 hydra-core-1.1.1 importlib-resources-5.4.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 pycocotools-2.0.3 termcolor-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting git+https://github.com/albumentations-team/albumentations.git\n",
      "  Cloning https://github.com/albumentations-team/albumentations.git to /tmp/pip-req-build-w0iry53a\n",
      "  Running command git clone -q https://github.com/albumentations-team/albumentations.git /tmp/pip-req-build-w0iry53a\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (1.20.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (1.6.3)\n",
      "Requirement already satisfied: scikit-image<0.19,>=0.16.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (0.18.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (4.5.3.56)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations==1.1.0) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations==1.1.0) (3.10.0.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (3.4.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (8.3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2021.7.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.16.0)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.8/site-packages (from networkx>=2.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (5.0.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (2.1.0)\n",
      "Building wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for albumentations: filename=albumentations-1.1.0-py3-none-any.whl size=105142 sha256=3ee4008ca0b5d65ac2bb86287140580ff02f5daf1b3aef2a8a336902be66b9d9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-paje3460/wheels/bf/89/e3/323a3ae2345101d172eadac18193e5c6d1d2111201a624620a\n",
      "Successfully built albumentations\n",
      "Installing collected packages: qudida, albumentations\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 1.0.2\n",
      "    Uninstalling albumentations-1.0.2:\n",
      "      Successfully uninstalled albumentations-1.0.2\n",
      "Successfully installed albumentations-1.1.0 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install \"git+https://github.com/albumentations-team/albumentations.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1639767323377,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "y3aYkCLn_OP_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1639767327266,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "OKuetLmaKrFq"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.engine import BestCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from albumentations import *\n",
    "import torch\n",
    "import os\n",
    "from detectron2.data import detection_utils\n",
    "from utils.aug import MyMapper\n",
    "from detectron2.solver.build import *\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import opendatasets as od\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1639767327267,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "m7lpIyvHKw4R"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "  pixel_mean = [128,128,128]\n",
    "  pixel_std = [13.235,13.235,13.235]\n",
    "  anchor_generators_sizes = [[8], [16], [32], [64],[128]]\n",
    "  anchor_generators_aspect_ratios = [[0.5, 1.0, 2.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1639767327267,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "VPliT5cXKyei"
   },
   "outputs": [],
   "source": [
    "# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    false_negatives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "\n",
    "#     @classmethod\n",
    "#     def build_train_loader(cls, cfg, sampler=None):\n",
    "#         return build_detection_train_loader(\n",
    "#             cfg, mapper=MyMapper(cfg), sampler=sampler\n",
    "#         )\n",
    "\n",
    "    def build_hooks(self):\n",
    "      # copy of cfg\n",
    "      cfg = self.cfg.clone()\n",
    "\n",
    "      # build the original model hooks\n",
    "      hooks = super().build_hooks()\n",
    "\n",
    "      # add the best checkpointer hook\n",
    "      hooks.insert(-1, BestCheckpointer(cfg.TEST.EVAL_PERIOD, \n",
    "                                        DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                                        \"MaP IoU\",\n",
    "                                        \"max\",\n",
    "                                        ))\n",
    "      return hooks\n",
    "\n",
    "    # @classmethod\n",
    "    # def build_optimizer(cls,cfg,model) -> torch.optim.Optimizer:\n",
    "    #   \"\"\"\n",
    "    #   Build an optimizer from config.\n",
    "    #   \"\"\"\n",
    "    #   params = get_default_optimizer_params(\n",
    "    #       model,\n",
    "    #       base_lr=cfg.SOLVER.BASE_LR,\n",
    "    #       weight_decay_norm=cfg.SOLVER.WEIGHT_DECAY_NORM,\n",
    "    #       bias_lr_factor=cfg.SOLVER.BIAS_LR_FACTOR,\n",
    "    #       weight_decay_bias=cfg.SOLVER.WEIGHT_DECAY_BIAS,\n",
    "    #   )\n",
    "    #   return maybe_add_gradient_clipping(cfg, torch.optim.SGD)(\n",
    "    #       params,\n",
    "    #       lr=cfg.SOLVER.BASE_LR,\n",
    "    #       momentum=cfg.SOLVER.MOMENTUM,\n",
    "    #       nesterov=cfg.SOLVER.NESTEROV,\n",
    "    #       weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n",
    "    #   )\n",
    "\n",
    "    # @classmethod\n",
    "    # def build_lr_scheduler(cls,cfg, optimizer) -> torch.optim.lr_scheduler._LRScheduler:\n",
    "    #   \"\"\"\n",
    "    #   Build a LR scheduler from config.\n",
    "    #   \"\"\"\n",
    "    #   name = cfg.SOLVER.LR_SCHEDULER_NAME\n",
    "\n",
    "    #   if name == \"WarmupMultiStepLR\":\n",
    "    #       steps = [x for x in cfg.SOLVER.STEPS if x <= cfg.SOLVER.MAX_ITER]\n",
    "    #       if len(steps) != len(cfg.SOLVER.STEPS):\n",
    "    #           logger = logging.getLogger(__name__)\n",
    "    #           logger.warning(\n",
    "    #               \"SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. \"\n",
    "    #               \"These values will be ignored.\"\n",
    "    #           )\n",
    "    #       sched = MultiStepParamScheduler(\n",
    "    #           values=[cfg.SOLVER.GAMMA ** k for k in range(len(steps) + 1)],\n",
    "    #           milestones=steps,\n",
    "    #           num_updates=cfg.SOLVER.MAX_ITER,\n",
    "    #       )\n",
    "    #   elif name == \"WarmupCosineLR\":\n",
    "    #       sched = CosineParamScheduler(1, 1/40)\n",
    "    #   elif name == \"CyclicLR\":\n",
    "    #       sched = torch.optim.lr_scheduler.CyclicLR(optimizer,\n",
    "    #                                                 base_lr=cfg.SOLVER.BASE_LR, max_lr=5*cfg.SOLVER.BASE_LR,\n",
    "    #                                                 base_momentum=0.85, max_momentum=0.95)\n",
    "\n",
    "    #   else:\n",
    "    #       raise ValueError(\"Unknown LR scheduler: {}\".format(name))\n",
    "\n",
    "    #   sched = WarmupParamScheduler(\n",
    "    #       sched,\n",
    "    #       cfg.SOLVER.WARMUP_FACTOR,\n",
    "    #       min(cfg.SOLVER.WARMUP_ITERS / cfg.SOLVER.MAX_ITER, 1.0),\n",
    "    #       cfg.SOLVER.WARMUP_METHOD,\n",
    "    #   )\n",
    "    #   return LRMultiplier(optimizer, multiplier=sched, max_iter=cfg.SOLVER.MAX_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1639767327268,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "dv3P0E4fK0DR"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "  dataDir = \"data\"\n",
    "  DatasetCatalog.clear()\n",
    "  MetadataCatalog.clear()\n",
    "  register_coco_instances(f'sartorius_train',{}, 'input/all/annotations_train.json'.format(fold), dataDir)\n",
    "  register_coco_instances(f'sartorius_val',{},'input/all/annotations_val.json'.format(fold), dataDir)\n",
    "\n",
    "  cfg = get_cfg()\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n",
    "  cfg.DATASETS.TRAIN = (f\"sartorius_train\",)\n",
    "  cfg.DATASETS.TEST = (f\"sartorius_val\",)\n",
    "  # cfg.MODEL.PIXEL_MEAN = Config.pixel_mean\n",
    "  # cfg.MODEL.PIXEL_STD = Config.pixel_std\n",
    "\n",
    "  cfg.DATALOADER.NUM_WORKERS = 7\n",
    "  cfg.MODEL.WEIGHTS = \"pretrained/final_weapon_without_copy/model_0029999.pth\"#\"/content/drive/MyDrive/Kaggle/Sartorius/model/pretrained/LIVECell_anchor_based_model.pth\"\n",
    "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "  cfg.SOLVER.BASE_LR = 1e-3\n",
    "  cfg.SOLVER.WEIGHT_DECAY = 5e-5\n",
    "  cfg.SOLVER.WARMUP_ITERS = 200\n",
    "  #cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "  cfg.SOLVER.MAX_ITER = 10000 #len(DatasetCatalog.get(f\"sartorius_train\")) // cfg.SOLVER.IMS_PER_BATCH * 20 #尝试20ep 用lr调整\n",
    "  cfg.SOLVER.STEPS = (7000,9000,9500)\n",
    "  #cfg.SOLVER.GAMMA = 0.2\n",
    "  cfg.INPUT.MIN_SIZE_TRAIN = (1000,1100,1200,1300)\n",
    "  cfg.INPUT.MAX_SIZE_TRAIN = 2000\n",
    "  cfg.INPUT.CROP.ENABLE = False\n",
    "  cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
    "  cfg.INPUT.MIN_SIZE_TEST = 1300\n",
    "  cfg.INPUT.MAX_SIZE_TEST = 2000\n",
    "  cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 256\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "  #cfg.TEST.EVAL_PERIOD = \n",
    "  cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get(f\"sartorius_train\")) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "\n",
    "  cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "  cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "  cfg.SOLVER.AMP.ENABLED  = False\n",
    "  cfg.SEED = 42\n",
    "\n",
    "#   cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = Config.anchor_generators_aspect_ratios\n",
    "#   cfg.MODEL.ANCHOR_GENERATOR.SIZES = Config.anchor_generators_sizes\n",
    "  # cfg.MODEL.RESNETS.OUT_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "  # cfg.MODEL.ROI_HEADS.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "  # cfg.MODEL.RESNETS.OUT_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # #cfg.MODEL.FPN.NORM = \"GN\"\n",
    "  # cfg.MODEL.ROI_HEADS.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\",\"p6\"]\n",
    "  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "\n",
    "  # cfg.MODEL.RESNETS.DEFORM_ON_PER_STAGE = [False, True, True, True] # on Res3,Res4,Res5\n",
    "  # cfg.MODEL.RESNETS.DEFORM_MODULATED = True\n",
    "  # cfg.MODEL.RESNETS.DEFORM_NUM_GROUPS = 2\n",
    "  # cfg.MODEL.RESNETS.NORM = \"GN\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NUM_CONV = 4\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NUM_FC = 1\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NORM = \"GN\"  \n",
    "  # cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 7\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG = True  \n",
    "  # cfg.MODEL.ROI_MASK_HEAD.NUM_CONV = 8\n",
    "  # cfg.MODEL.ROI_MASK_HEAD.NORM = \"GN\"\n",
    "  # cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5]\n",
    "  # cfg.MODEL.ROI_BOX_CASCADE_HEAD.IOUS = (0.5, 0.6, 0.7)\n",
    "\n",
    "  cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "  cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 3000\n",
    "  \n",
    "    \n",
    "  # cfg.MODEL.RPN.BBOX_REG_LOSS_TYPE = \"ciou\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"ciou\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 10.0\n",
    "  #cfg.SOLVER.AMP.ENABLED = True\n",
    "\n",
    "  cfg.OUTPUT_DIR = \"pretrained/final_weapon_without_copy/finetuned/\".format(fold)\n",
    "\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "  trainer = Trainer(cfg) \n",
    "  trainer.resume_or_load(resume=False)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apzlCYlQK1m2",
    "outputId": "445d1533-13e5-410a-db1a-1cf5a78c0ea7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 02:18:32 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): DeformBottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): DeformBottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (23): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (24): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (25): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (26): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (27): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (28): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (29): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (30): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (31): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (32): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (33): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (34): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (35): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): DeformBottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn5): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn6): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn7): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn8): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/29 02:18:33 d2.data.datasets.coco]: \u001b[0mLoading input/all/annotations_train.json takes 1.01 seconds.\n",
      "\u001b[32m[12/29 02:18:33 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from input/all/annotations_train.json\n",
      "\u001b[32m[12/29 02:18:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[12/29 02:18:34 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/29 02:18:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(1000, 1100, 1200, 1300), max_size=2000, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/29 02:18:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/29 02:18:34 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:18:34 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (11, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (11,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (11, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (11,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (11, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (11,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (10, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (10,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.0.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.1.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.2.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 02:18:35 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W LegacyTypeDispatch.h:74] Warning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 02:19:33 d2.utils.events]: \u001b[0m eta: 6:09:57  iter: 19  total_loss: 7.446  loss_cls_stage0: 1.308  loss_box_reg_stage0: 0.4966  loss_cls_stage1: 1.286  loss_box_reg_stage1: 0.8747  loss_cls_stage2: 1.3  loss_box_reg_stage2: 0.8636  loss_mask: 0.6821  loss_rpn_cls: 0.4162  loss_rpn_loc: 0.262  time: 2.1819  data_time: 0.6252  lr: 9.5905e-05  max_mem: 24696M\n",
      "\u001b[32m[12/29 02:20:17 d2.utils.events]: \u001b[0m eta: 6:08:03  iter: 39  total_loss: 5.564  loss_cls_stage0: 0.7845  loss_box_reg_stage0: 0.4847  loss_cls_stage1: 0.8014  loss_box_reg_stage1: 0.8118  loss_cls_stage2: 0.785  loss_box_reg_stage2: 0.8589  loss_mask: 0.5508  loss_rpn_cls: 0.2279  loss_rpn_loc: 0.2505  time: 2.1916  data_time: 0.0746  lr: 0.0001958  max_mem: 24709M\n",
      "\u001b[32m[12/29 02:21:01 d2.utils.events]: \u001b[0m eta: 6:10:27  iter: 59  total_loss: 4.691  loss_cls_stage0: 0.5868  loss_box_reg_stage0: 0.4691  loss_cls_stage1: 0.5752  loss_box_reg_stage1: 0.8431  loss_cls_stage2: 0.546  loss_box_reg_stage2: 0.9057  loss_mask: 0.4305  loss_rpn_cls: 0.1405  loss_rpn_loc: 0.236  time: 2.1989  data_time: 0.0585  lr: 0.00029571  max_mem: 24861M\n",
      "\u001b[32m[12/29 02:21:46 d2.utils.events]: \u001b[0m eta: 6:10:53  iter: 79  total_loss: 4.585  loss_cls_stage0: 0.5048  loss_box_reg_stage0: 0.4931  loss_cls_stage1: 0.5035  loss_box_reg_stage1: 0.8816  loss_cls_stage2: 0.4782  loss_box_reg_stage2: 0.7815  loss_mask: 0.3509  loss_rpn_cls: 0.1436  loss_rpn_loc: 0.2344  time: 2.2136  data_time: 0.0860  lr: 0.00039561  max_mem: 25315M\n",
      "\u001b[32m[12/29 02:22:32 d2.utils.events]: \u001b[0m eta: 6:10:34  iter: 99  total_loss: 4.325  loss_cls_stage0: 0.4761  loss_box_reg_stage0: 0.5007  loss_cls_stage1: 0.5063  loss_box_reg_stage1: 0.9264  loss_cls_stage2: 0.498  loss_box_reg_stage2: 0.8961  loss_mask: 0.3116  loss_rpn_cls: 0.1232  loss_rpn_loc: 0.2044  time: 2.2269  data_time: 0.0953  lr: 0.00049551  max_mem: 25903M\n",
      "\u001b[32m[12/29 02:23:16 d2.utils.events]: \u001b[0m eta: 6:09:49  iter: 119  total_loss: 4.079  loss_cls_stage0: 0.3535  loss_box_reg_stage0: 0.5184  loss_cls_stage1: 0.3746  loss_box_reg_stage1: 0.9077  loss_cls_stage2: 0.3819  loss_box_reg_stage2: 0.8206  loss_mask: 0.3084  loss_rpn_cls: 0.1265  loss_rpn_loc: 0.2399  time: 2.2234  data_time: 0.0764  lr: 0.00059541  max_mem: 25903M\n",
      "\u001b[32m[12/29 02:24:04 d2.utils.events]: \u001b[0m eta: 6:12:09  iter: 139  total_loss: 3.985  loss_cls_stage0: 0.3864  loss_box_reg_stage0: 0.513  loss_cls_stage1: 0.4318  loss_box_reg_stage1: 0.9436  loss_cls_stage2: 0.4136  loss_box_reg_stage2: 0.9788  loss_mask: 0.2925  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2062  time: 2.2456  data_time: 0.0930  lr: 0.00069531  max_mem: 25903M\n",
      "\u001b[32m[12/29 02:24:50 d2.utils.events]: \u001b[0m eta: 6:12:37  iter: 159  total_loss: 4.131  loss_cls_stage0: 0.3279  loss_box_reg_stage0: 0.5397  loss_cls_stage1: 0.3617  loss_box_reg_stage1: 0.9351  loss_cls_stage2: 0.364  loss_box_reg_stage2: 0.947  loss_mask: 0.298  loss_rpn_cls: 0.09066  loss_rpn_loc: 0.2199  time: 2.2568  data_time: 0.0725  lr: 0.00079521  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:25:36 d2.utils.events]: \u001b[0m eta: 6:12:47  iter: 179  total_loss: 3.904  loss_cls_stage0: 0.2838  loss_box_reg_stage0: 0.5257  loss_cls_stage1: 0.3085  loss_box_reg_stage1: 0.8791  loss_cls_stage2: 0.3365  loss_box_reg_stage2: 0.8439  loss_mask: 0.3006  loss_rpn_cls: 0.08544  loss_rpn_loc: 0.2186  time: 2.2579  data_time: 0.0806  lr: 0.0008951  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:26:22 d2.utils.events]: \u001b[0m eta: 6:12:47  iter: 199  total_loss: 3.983  loss_cls_stage0: 0.2843  loss_box_reg_stage0: 0.5084  loss_cls_stage1: 0.2948  loss_box_reg_stage1: 0.9126  loss_cls_stage2: 0.3336  loss_box_reg_stage2: 0.8547  loss_mask: 0.2851  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.2193  time: 2.2624  data_time: 0.0791  lr: 0.000995  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:27:05 d2.utils.events]: \u001b[0m eta: 6:09:27  iter: 219  total_loss: 3.847  loss_cls_stage0: 0.2377  loss_box_reg_stage0: 0.5169  loss_cls_stage1: 0.2725  loss_box_reg_stage1: 0.986  loss_cls_stage2: 0.2991  loss_box_reg_stage2: 0.9107  loss_mask: 0.2923  loss_rpn_cls: 0.08734  loss_rpn_loc: 0.2091  time: 2.2548  data_time: 0.0823  lr: 0.001  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:27:51 d2.utils.events]: \u001b[0m eta: 6:10:30  iter: 239  total_loss: 3.674  loss_cls_stage0: 0.2617  loss_box_reg_stage0: 0.5168  loss_cls_stage1: 0.3035  loss_box_reg_stage1: 0.8907  loss_cls_stage2: 0.3113  loss_box_reg_stage2: 0.8947  loss_mask: 0.2864  loss_rpn_cls: 0.09861  loss_rpn_loc: 0.2124  time: 2.2586  data_time: 0.1079  lr: 0.001  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:27:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:27:56 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/29 02:27:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:27:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:27:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:27:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:27:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0018 s/iter. Inference: 0.3511 s/iter. Eval: 0.0250 s/iter. Total: 0.3780 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 02:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0024 s/iter. Inference: 0.3592 s/iter. Eval: 0.0341 s/iter. Total: 0.3960 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 02:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0028 s/iter. Inference: 0.3519 s/iter. Eval: 0.0360 s/iter. Total: 0.3908 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 02:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0029 s/iter. Inference: 0.3538 s/iter. Eval: 0.0413 s/iter. Total: 0.3982 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 02:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0028 s/iter. Inference: 0.3505 s/iter. Eval: 0.0424 s/iter. Total: 0.3959 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 02:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0027 s/iter. Inference: 0.3497 s/iter. Eval: 0.0415 s/iter. Total: 0.3942 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 02:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0027 s/iter. Inference: 0.3488 s/iter. Eval: 0.0439 s/iter. Total: 0.3957 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 02:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0027 s/iter. Inference: 0.3479 s/iter. Eval: 0.0466 s/iter. Total: 0.3974 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 02:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0026 s/iter. Inference: 0.3463 s/iter. Eval: 0.0450 s/iter. Total: 0.3941 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 02:28:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.869401 (0.395426 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:28:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.346682 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:28:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:28:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24187640884268322\n",
      "\u001b[32m[12/29 02:28:49 d2.engine.hooks]: \u001b[0mSaved first model at 0.24188 @ 241 steps\n",
      "\u001b[32m[12/29 02:29:27 d2.utils.events]: \u001b[0m eta: 6:07:37  iter: 259  total_loss: 3.788  loss_cls_stage0: 0.2543  loss_box_reg_stage0: 0.5155  loss_cls_stage1: 0.2697  loss_box_reg_stage1: 0.955  loss_cls_stage2: 0.3075  loss_box_reg_stage2: 0.9573  loss_mask: 0.2889  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.1942  time: 2.2466  data_time: 0.0954  lr: 0.001  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:30:12 d2.utils.events]: \u001b[0m eta: 6:06:52  iter: 279  total_loss: 3.686  loss_cls_stage0: 0.2753  loss_box_reg_stage0: 0.5134  loss_cls_stage1: 0.2948  loss_box_reg_stage1: 0.8861  loss_cls_stage2: 0.2942  loss_box_reg_stage2: 0.8555  loss_mask: 0.2857  loss_rpn_cls: 0.08675  loss_rpn_loc: 0.2115  time: 2.2474  data_time: 0.0889  lr: 0.001  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:30:57 d2.utils.events]: \u001b[0m eta: 6:06:07  iter: 299  total_loss: 3.615  loss_cls_stage0: 0.2458  loss_box_reg_stage0: 0.5232  loss_cls_stage1: 0.2626  loss_box_reg_stage1: 0.9058  loss_cls_stage2: 0.2704  loss_box_reg_stage2: 0.866  loss_mask: 0.2811  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.2  time: 2.2474  data_time: 0.0823  lr: 0.001  max_mem: 26349M\n",
      "\u001b[32m[12/29 02:31:42 d2.utils.events]: \u001b[0m eta: 6:05:21  iter: 319  total_loss: 3.66  loss_cls_stage0: 0.2392  loss_box_reg_stage0: 0.5273  loss_cls_stage1: 0.2927  loss_box_reg_stage1: 0.8432  loss_cls_stage2: 0.2991  loss_box_reg_stage2: 0.8083  loss_mask: 0.2898  loss_rpn_cls: 0.08665  loss_rpn_loc: 0.2215  time: 2.2468  data_time: 0.1015  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:32:26 d2.utils.events]: \u001b[0m eta: 6:02:50  iter: 339  total_loss: 3.735  loss_cls_stage0: 0.2431  loss_box_reg_stage0: 0.5012  loss_cls_stage1: 0.2552  loss_box_reg_stage1: 0.9421  loss_cls_stage2: 0.2715  loss_box_reg_stage2: 0.9571  loss_mask: 0.2881  loss_rpn_cls: 0.07053  loss_rpn_loc: 0.1853  time: 2.2444  data_time: 0.0769  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:33:10 d2.utils.events]: \u001b[0m eta: 6:01:59  iter: 359  total_loss: 3.632  loss_cls_stage0: 0.2423  loss_box_reg_stage0: 0.4948  loss_cls_stage1: 0.2614  loss_box_reg_stage1: 0.9318  loss_cls_stage2: 0.2792  loss_box_reg_stage2: 0.9343  loss_mask: 0.2779  loss_rpn_cls: 0.04789  loss_rpn_loc: 0.1764  time: 2.2436  data_time: 0.0750  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:33:54 d2.utils.events]: \u001b[0m eta: 6:01:11  iter: 379  total_loss: 3.553  loss_cls_stage0: 0.2613  loss_box_reg_stage0: 0.4963  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.8942  loss_cls_stage2: 0.2907  loss_box_reg_stage2: 0.9173  loss_mask: 0.2916  loss_rpn_cls: 0.08555  loss_rpn_loc: 0.226  time: 2.2402  data_time: 0.0846  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:34:39 d2.utils.events]: \u001b[0m eta: 6:00:31  iter: 399  total_loss: 3.678  loss_cls_stage0: 0.2335  loss_box_reg_stage0: 0.5141  loss_cls_stage1: 0.2523  loss_box_reg_stage1: 0.867  loss_cls_stage2: 0.2714  loss_box_reg_stage2: 0.9203  loss_mask: 0.2892  loss_rpn_cls: 0.07837  loss_rpn_loc: 0.2264  time: 2.2416  data_time: 0.0838  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:35:26 d2.utils.events]: \u001b[0m eta: 5:59:52  iter: 419  total_loss: 3.787  loss_cls_stage0: 0.2392  loss_box_reg_stage0: 0.5158  loss_cls_stage1: 0.2569  loss_box_reg_stage1: 0.9401  loss_cls_stage2: 0.2758  loss_box_reg_stage2: 0.9569  loss_mask: 0.2817  loss_rpn_cls: 0.07822  loss_rpn_loc: 0.2083  time: 2.2460  data_time: 0.1218  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:36:12 d2.utils.events]: \u001b[0m eta: 5:59:07  iter: 439  total_loss: 3.742  loss_cls_stage0: 0.2392  loss_box_reg_stage0: 0.4889  loss_cls_stage1: 0.2496  loss_box_reg_stage1: 0.8996  loss_cls_stage2: 0.2705  loss_box_reg_stage2: 0.8806  loss_mask: 0.2776  loss_rpn_cls: 0.0818  loss_rpn_loc: 0.2271  time: 2.2489  data_time: 0.1256  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:36:57 d2.utils.events]: \u001b[0m eta: 5:58:16  iter: 459  total_loss: 3.598  loss_cls_stage0: 0.2664  loss_box_reg_stage0: 0.4859  loss_cls_stage1: 0.2789  loss_box_reg_stage1: 0.854  loss_cls_stage2: 0.2799  loss_box_reg_stage2: 0.8157  loss_mask: 0.29  loss_rpn_cls: 0.09299  loss_rpn_loc: 0.2138  time: 2.2490  data_time: 0.1351  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:37:42 d2.utils.events]: \u001b[0m eta: 5:57:29  iter: 479  total_loss: 3.691  loss_cls_stage0: 0.2507  loss_box_reg_stage0: 0.5127  loss_cls_stage1: 0.2697  loss_box_reg_stage1: 0.8707  loss_cls_stage2: 0.2842  loss_box_reg_stage2: 0.8498  loss_mask: 0.2938  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.2007  time: 2.2484  data_time: 0.0813  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:37:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:37:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:37:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:37:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:37:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:37:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.3719 s/iter. Eval: 0.0195 s/iter. Total: 0.3929 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/29 02:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0019 s/iter. Inference: 0.3720 s/iter. Eval: 0.0431 s/iter. Total: 0.4171 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 02:38:08 d2.evaluation.evaluator]: \u001b[0mInference done 34/121. Dataloading: 0.0022 s/iter. Inference: 0.3805 s/iter. Eval: 0.0497 s/iter. Total: 0.4326 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 02:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0022 s/iter. Inference: 0.3727 s/iter. Eval: 0.0503 s/iter. Total: 0.4254 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 02:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 60/121. Dataloading: 0.0024 s/iter. Inference: 0.3675 s/iter. Eval: 0.0483 s/iter. Total: 0.4183 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 02:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0023 s/iter. Inference: 0.3632 s/iter. Eval: 0.0473 s/iter. Total: 0.4130 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 02:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0023 s/iter. Inference: 0.3622 s/iter. Eval: 0.0557 s/iter. Total: 0.4204 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 02:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0023 s/iter. Inference: 0.3611 s/iter. Eval: 0.0589 s/iter. Total: 0.4226 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 02:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0023 s/iter. Inference: 0.3598 s/iter. Eval: 0.0586 s/iter. Total: 0.4210 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 02:38:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.469645 (0.417842 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:38:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.357804 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:38:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:38:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2838495580290078\n",
      "\u001b[32m[12/29 02:38:48 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.28385, better than last best score 0.24188 @ iteration 241.\n",
      "\u001b[32m[12/29 02:39:24 d2.utils.events]: \u001b[0m eta: 5:56:46  iter: 499  total_loss: 3.786  loss_cls_stage0: 0.2374  loss_box_reg_stage0: 0.5236  loss_cls_stage1: 0.2543  loss_box_reg_stage1: 0.8876  loss_cls_stage2: 0.2733  loss_box_reg_stage2: 0.8655  loss_mask: 0.3064  loss_rpn_cls: 0.092  loss_rpn_loc: 0.2247  time: 2.2485  data_time: 0.1144  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:40:08 d2.utils.events]: \u001b[0m eta: 5:55:56  iter: 519  total_loss: 3.57  loss_cls_stage0: 0.2214  loss_box_reg_stage0: 0.5016  loss_cls_stage1: 0.237  loss_box_reg_stage1: 0.9052  loss_cls_stage2: 0.2492  loss_box_reg_stage2: 0.8695  loss_mask: 0.2907  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1985  time: 2.2466  data_time: 0.0844  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:40:53 d2.utils.events]: \u001b[0m eta: 5:55:14  iter: 539  total_loss: 3.922  loss_cls_stage0: 0.2408  loss_box_reg_stage0: 0.5312  loss_cls_stage1: 0.2613  loss_box_reg_stage1: 0.9804  loss_cls_stage2: 0.2808  loss_box_reg_stage2: 0.9618  loss_mask: 0.2875  loss_rpn_cls: 0.05867  loss_rpn_loc: 0.1991  time: 2.2471  data_time: 0.0880  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:41:35 d2.utils.events]: \u001b[0m eta: 5:54:12  iter: 559  total_loss: 3.456  loss_cls_stage0: 0.214  loss_box_reg_stage0: 0.4958  loss_cls_stage1: 0.2214  loss_box_reg_stage1: 0.8859  loss_cls_stage2: 0.2517  loss_box_reg_stage2: 0.9438  loss_mask: 0.2676  loss_rpn_cls: 0.07094  loss_rpn_loc: 0.1702  time: 2.2423  data_time: 0.0617  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:42:24 d2.utils.events]: \u001b[0m eta: 5:53:41  iter: 579  total_loss: 3.537  loss_cls_stage0: 0.2255  loss_box_reg_stage0: 0.5007  loss_cls_stage1: 0.251  loss_box_reg_stage1: 0.9156  loss_cls_stage2: 0.2677  loss_box_reg_stage2: 0.9152  loss_mask: 0.2877  loss_rpn_cls: 0.06502  loss_rpn_loc: 0.2163  time: 2.2482  data_time: 0.1448  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:43:08 d2.utils.events]: \u001b[0m eta: 5:52:50  iter: 599  total_loss: 3.663  loss_cls_stage0: 0.2326  loss_box_reg_stage0: 0.5231  loss_cls_stage1: 0.2577  loss_box_reg_stage1: 0.8399  loss_cls_stage2: 0.2724  loss_box_reg_stage2: 0.8395  loss_mask: 0.2821  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.1926  time: 2.2480  data_time: 0.0900  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:43:54 d2.utils.events]: \u001b[0m eta: 5:52:16  iter: 619  total_loss: 3.593  loss_cls_stage0: 0.2095  loss_box_reg_stage0: 0.4996  loss_cls_stage1: 0.2337  loss_box_reg_stage1: 0.9271  loss_cls_stage2: 0.2552  loss_box_reg_stage2: 0.905  loss_mask: 0.2764  loss_rpn_cls: 0.06995  loss_rpn_loc: 0.1806  time: 2.2490  data_time: 0.0838  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:44:38 d2.utils.events]: \u001b[0m eta: 5:51:30  iter: 639  total_loss: 3.62  loss_cls_stage0: 0.2287  loss_box_reg_stage0: 0.4804  loss_cls_stage1: 0.241  loss_box_reg_stage1: 0.8685  loss_cls_stage2: 0.2644  loss_box_reg_stage2: 0.8684  loss_mask: 0.286  loss_rpn_cls: 0.09496  loss_rpn_loc: 0.2026  time: 2.2479  data_time: 0.0885  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:45:22 d2.utils.events]: \u001b[0m eta: 5:50:35  iter: 659  total_loss: 3.599  loss_cls_stage0: 0.1996  loss_box_reg_stage0: 0.4514  loss_cls_stage1: 0.2121  loss_box_reg_stage1: 0.8942  loss_cls_stage2: 0.2394  loss_box_reg_stage2: 0.9313  loss_mask: 0.2731  loss_rpn_cls: 0.07361  loss_rpn_loc: 0.2043  time: 2.2467  data_time: 0.0864  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:46:07 d2.utils.events]: \u001b[0m eta: 5:49:47  iter: 679  total_loss: 3.618  loss_cls_stage0: 0.2058  loss_box_reg_stage0: 0.4875  loss_cls_stage1: 0.2338  loss_box_reg_stage1: 0.8966  loss_cls_stage2: 0.2635  loss_box_reg_stage2: 0.9285  loss_mask: 0.2765  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.1795  time: 2.2465  data_time: 0.0871  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:46:54 d2.utils.events]: \u001b[0m eta: 5:49:05  iter: 699  total_loss: 3.703  loss_cls_stage0: 0.2467  loss_box_reg_stage0: 0.5021  loss_cls_stage1: 0.2541  loss_box_reg_stage1: 0.9071  loss_cls_stage2: 0.272  loss_box_reg_stage2: 0.8699  loss_mask: 0.2974  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.1861  time: 2.2486  data_time: 0.1322  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:47:40 d2.utils.events]: \u001b[0m eta: 5:48:28  iter: 719  total_loss: 3.594  loss_cls_stage0: 0.2365  loss_box_reg_stage0: 0.4904  loss_cls_stage1: 0.258  loss_box_reg_stage1: 0.8467  loss_cls_stage2: 0.2768  loss_box_reg_stage2: 0.9065  loss_mask: 0.2773  loss_rpn_cls: 0.07825  loss_rpn_loc: 0.2043  time: 2.2511  data_time: 0.1699  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:47:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:47:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:47:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:47:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:47:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:47:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0018 s/iter. Inference: 0.3483 s/iter. Eval: 0.0190 s/iter. Total: 0.3691 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 02:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0023 s/iter. Inference: 0.3656 s/iter. Eval: 0.0437 s/iter. Total: 0.4117 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 02:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0023 s/iter. Inference: 0.3654 s/iter. Eval: 0.0532 s/iter. Total: 0.4210 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/29 02:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0023 s/iter. Inference: 0.3596 s/iter. Eval: 0.0538 s/iter. Total: 0.4158 s/iter. ETA=0:00:30\n",
      "\u001b[32m[12/29 02:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 60/121. Dataloading: 0.0024 s/iter. Inference: 0.3638 s/iter. Eval: 0.0525 s/iter. Total: 0.4189 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 02:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0024 s/iter. Inference: 0.3598 s/iter. Eval: 0.0512 s/iter. Total: 0.4135 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 02:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0024 s/iter. Inference: 0.3669 s/iter. Eval: 0.0615 s/iter. Total: 0.4310 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 02:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0025 s/iter. Inference: 0.3725 s/iter. Eval: 0.0627 s/iter. Total: 0.4379 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 02:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0026 s/iter. Inference: 0.3700 s/iter. Eval: 0.0627 s/iter. Total: 0.4356 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 02:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0026 s/iter. Inference: 0.3673 s/iter. Eval: 0.0600 s/iter. Total: 0.4302 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/29 02:48:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.155193 (0.432372 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:48:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.367503 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:48:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:48:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28667332936305584\n",
      "\u001b[32m[12/29 02:48:53 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.28667, better than last best score 0.28385 @ iteration 483.\n",
      "\u001b[32m[12/29 02:49:24 d2.utils.events]: \u001b[0m eta: 5:47:48  iter: 739  total_loss: 3.65  loss_cls_stage0: 0.227  loss_box_reg_stage0: 0.4764  loss_cls_stage1: 0.2528  loss_box_reg_stage1: 0.8472  loss_cls_stage2: 0.2827  loss_box_reg_stage2: 0.8972  loss_mask: 0.2928  loss_rpn_cls: 0.07024  loss_rpn_loc: 0.2195  time: 2.2535  data_time: 0.1067  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:50:11 d2.utils.events]: \u001b[0m eta: 5:47:25  iter: 759  total_loss: 3.706  loss_cls_stage0: 0.2494  loss_box_reg_stage0: 0.5275  loss_cls_stage1: 0.2782  loss_box_reg_stage1: 0.8485  loss_cls_stage2: 0.2901  loss_box_reg_stage2: 0.8534  loss_mask: 0.293  loss_rpn_cls: 0.09401  loss_rpn_loc: 0.2268  time: 2.2561  data_time: 0.0973  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:50:58 d2.utils.events]: \u001b[0m eta: 5:47:26  iter: 779  total_loss: 3.564  loss_cls_stage0: 0.2196  loss_box_reg_stage0: 0.4927  loss_cls_stage1: 0.2426  loss_box_reg_stage1: 0.8836  loss_cls_stage2: 0.2741  loss_box_reg_stage2: 0.8931  loss_mask: 0.2898  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1934  time: 2.2586  data_time: 0.0950  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:51:45 d2.utils.events]: \u001b[0m eta: 5:47:14  iter: 799  total_loss: 3.604  loss_cls_stage0: 0.2012  loss_box_reg_stage0: 0.5029  loss_cls_stage1: 0.2254  loss_box_reg_stage1: 0.8977  loss_cls_stage2: 0.2541  loss_box_reg_stage2: 0.8883  loss_mask: 0.2789  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.2028  time: 2.2600  data_time: 0.0940  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:52:30 d2.utils.events]: \u001b[0m eta: 5:46:29  iter: 819  total_loss: 3.671  loss_cls_stage0: 0.2106  loss_box_reg_stage0: 0.5025  loss_cls_stage1: 0.2304  loss_box_reg_stage1: 0.8918  loss_cls_stage2: 0.2504  loss_box_reg_stage2: 0.9466  loss_mask: 0.2687  loss_rpn_cls: 0.05827  loss_rpn_loc: 0.1663  time: 2.2598  data_time: 0.0513  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:53:17 d2.utils.events]: \u001b[0m eta: 5:45:53  iter: 839  total_loss: 3.458  loss_cls_stage0: 0.2167  loss_box_reg_stage0: 0.47  loss_cls_stage1: 0.2506  loss_box_reg_stage1: 0.8304  loss_cls_stage2: 0.2546  loss_box_reg_stage2: 0.8862  loss_mask: 0.2708  loss_rpn_cls: 0.07953  loss_rpn_loc: 0.1825  time: 2.2616  data_time: 0.1005  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:54:02 d2.utils.events]: \u001b[0m eta: 5:45:07  iter: 859  total_loss: 3.553  loss_cls_stage0: 0.2308  loss_box_reg_stage0: 0.5  loss_cls_stage1: 0.2309  loss_box_reg_stage1: 0.8988  loss_cls_stage2: 0.2689  loss_box_reg_stage2: 0.8335  loss_mask: 0.2898  loss_rpn_cls: 0.06191  loss_rpn_loc: 0.1937  time: 2.2614  data_time: 0.0717  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:54:48 d2.utils.events]: \u001b[0m eta: 5:44:37  iter: 879  total_loss: 3.704  loss_cls_stage0: 0.269  loss_box_reg_stage0: 0.4885  loss_cls_stage1: 0.2637  loss_box_reg_stage1: 0.8743  loss_cls_stage2: 0.2817  loss_box_reg_stage2: 0.9779  loss_mask: 0.2663  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.1899  time: 2.2625  data_time: 0.1233  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:55:34 d2.utils.events]: \u001b[0m eta: 5:43:58  iter: 899  total_loss: 3.778  loss_cls_stage0: 0.2384  loss_box_reg_stage0: 0.518  loss_cls_stage1: 0.2556  loss_box_reg_stage1: 0.9079  loss_cls_stage2: 0.2835  loss_box_reg_stage2: 0.907  loss_mask: 0.2922  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.2079  time: 2.2640  data_time: 0.0908  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:56:22 d2.utils.events]: \u001b[0m eta: 5:43:29  iter: 919  total_loss: 3.748  loss_cls_stage0: 0.2592  loss_box_reg_stage0: 0.5167  loss_cls_stage1: 0.2829  loss_box_reg_stage1: 0.8875  loss_cls_stage2: 0.2954  loss_box_reg_stage2: 0.87  loss_mask: 0.2898  loss_rpn_cls: 0.08303  loss_rpn_loc: 0.2179  time: 2.2664  data_time: 0.1326  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:57:06 d2.utils.events]: \u001b[0m eta: 5:42:24  iter: 939  total_loss: 3.83  loss_cls_stage0: 0.2441  loss_box_reg_stage0: 0.5142  loss_cls_stage1: 0.2634  loss_box_reg_stage1: 0.9453  loss_cls_stage2: 0.2738  loss_box_reg_stage2: 1.007  loss_mask: 0.2971  loss_rpn_cls: 0.05688  loss_rpn_loc: 0.1891  time: 2.2653  data_time: 0.0719  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:57:50 d2.utils.events]: \u001b[0m eta: 5:41:36  iter: 959  total_loss: 3.586  loss_cls_stage0: 0.2467  loss_box_reg_stage0: 0.4793  loss_cls_stage1: 0.2666  loss_box_reg_stage1: 0.9074  loss_cls_stage2: 0.2857  loss_box_reg_stage2: 0.9735  loss_mask: 0.2706  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.202  time: 2.2642  data_time: 0.0744  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 02:58:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:58:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:58:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:58:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:58:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:58:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.3884 s/iter. Eval: 0.0217 s/iter. Total: 0.4115 s/iter. ETA=0:00:45\n",
      "\u001b[32m[12/29 02:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0020 s/iter. Inference: 0.3778 s/iter. Eval: 0.0434 s/iter. Total: 0.4234 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 02:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 34/121. Dataloading: 0.0030 s/iter. Inference: 0.3838 s/iter. Eval: 0.0516 s/iter. Total: 0.4386 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 02:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0028 s/iter. Inference: 0.3922 s/iter. Eval: 0.0529 s/iter. Total: 0.4481 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 02:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 57/121. Dataloading: 0.0028 s/iter. Inference: 0.3954 s/iter. Eval: 0.0461 s/iter. Total: 0.4445 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 02:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0028 s/iter. Inference: 0.3876 s/iter. Eval: 0.0470 s/iter. Total: 0.4376 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 02:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0028 s/iter. Inference: 0.3840 s/iter. Eval: 0.0573 s/iter. Total: 0.4444 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 02:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0032 s/iter. Inference: 0.3853 s/iter. Eval: 0.0596 s/iter. Total: 0.4482 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 02:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0031 s/iter. Inference: 0.3826 s/iter. Eval: 0.0586 s/iter. Total: 0.4445 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 02:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0031 s/iter. Inference: 0.3811 s/iter. Eval: 0.0572 s/iter. Total: 0.4416 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 02:59:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.127163 (0.440751 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:59:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.379089 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:59:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:59:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27293484458564865\n",
      "\u001b[32m[12/29 02:59:05 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.27293, not better than best score 0.28667 @ iteration 725.\n",
      "\u001b[32m[12/29 02:59:32 d2.utils.events]: \u001b[0m eta: 5:40:57  iter: 979  total_loss: 3.47  loss_cls_stage0: 0.1994  loss_box_reg_stage0: 0.4759  loss_cls_stage1: 0.2086  loss_box_reg_stage1: 0.8408  loss_cls_stage2: 0.2395  loss_box_reg_stage2: 0.8774  loss_mask: 0.2758  loss_rpn_cls: 0.07854  loss_rpn_loc: 0.2104  time: 2.2647  data_time: 0.0785  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:00:16 d2.utils.events]: \u001b[0m eta: 5:40:08  iter: 999  total_loss: 3.542  loss_cls_stage0: 0.2246  loss_box_reg_stage0: 0.4764  loss_cls_stage1: 0.2372  loss_box_reg_stage1: 0.8172  loss_cls_stage2: 0.2534  loss_box_reg_stage2: 0.8823  loss_mask: 0.2921  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.2409  time: 2.2635  data_time: 0.0829  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:01:01 d2.utils.events]: \u001b[0m eta: 5:39:55  iter: 1019  total_loss: 3.663  loss_cls_stage0: 0.2205  loss_box_reg_stage0: 0.5201  loss_cls_stage1: 0.2474  loss_box_reg_stage1: 0.9328  loss_cls_stage2: 0.2709  loss_box_reg_stage2: 0.9426  loss_mask: 0.2803  loss_rpn_cls: 0.0747  loss_rpn_loc: 0.1979  time: 2.2632  data_time: 0.1198  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:01:46 d2.utils.events]: \u001b[0m eta: 5:39:13  iter: 1039  total_loss: 3.421  loss_cls_stage0: 0.2157  loss_box_reg_stage0: 0.4698  loss_cls_stage1: 0.242  loss_box_reg_stage1: 0.8011  loss_cls_stage2: 0.254  loss_box_reg_stage2: 0.8415  loss_mask: 0.2807  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.1887  time: 2.2632  data_time: 0.0954  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:02:29 d2.utils.events]: \u001b[0m eta: 5:37:56  iter: 1059  total_loss: 3.692  loss_cls_stage0: 0.2007  loss_box_reg_stage0: 0.487  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.9072  loss_cls_stage2: 0.2675  loss_box_reg_stage2: 0.9969  loss_mask: 0.2635  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1885  time: 2.2604  data_time: 0.0582  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:03:16 d2.utils.events]: \u001b[0m eta: 5:37:42  iter: 1079  total_loss: 3.632  loss_cls_stage0: 0.2438  loss_box_reg_stage0: 0.4792  loss_cls_stage1: 0.2615  loss_box_reg_stage1: 0.906  loss_cls_stage2: 0.2753  loss_box_reg_stage2: 0.9047  loss_mask: 0.2831  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1836  time: 2.2623  data_time: 0.0829  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:04:02 d2.utils.events]: \u001b[0m eta: 5:36:56  iter: 1099  total_loss: 3.418  loss_cls_stage0: 0.2135  loss_box_reg_stage0: 0.4888  loss_cls_stage1: 0.2363  loss_box_reg_stage1: 0.8483  loss_cls_stage2: 0.247  loss_box_reg_stage2: 0.889  loss_mask: 0.2829  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.1958  time: 2.2633  data_time: 0.1072  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:04:45 d2.utils.events]: \u001b[0m eta: 5:35:36  iter: 1119  total_loss: 3.671  loss_cls_stage0: 0.2256  loss_box_reg_stage0: 0.4905  loss_cls_stage1: 0.2292  loss_box_reg_stage1: 0.9119  loss_cls_stage2: 0.2587  loss_box_reg_stage2: 0.9974  loss_mask: 0.2757  loss_rpn_cls: 0.05388  loss_rpn_loc: 0.169  time: 2.2610  data_time: 0.0572  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:05:32 d2.utils.events]: \u001b[0m eta: 5:35:07  iter: 1139  total_loss: 3.579  loss_cls_stage0: 0.2102  loss_box_reg_stage0: 0.4911  loss_cls_stage1: 0.2308  loss_box_reg_stage1: 0.9389  loss_cls_stage2: 0.2496  loss_box_reg_stage2: 0.9877  loss_mask: 0.2735  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.1666  time: 2.2621  data_time: 0.0660  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:06:19 d2.utils.events]: \u001b[0m eta: 5:34:33  iter: 1159  total_loss: 3.542  loss_cls_stage0: 0.2303  loss_box_reg_stage0: 0.5218  loss_cls_stage1: 0.2653  loss_box_reg_stage1: 0.8656  loss_cls_stage2: 0.2763  loss_box_reg_stage2: 0.8376  loss_mask: 0.2813  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.1716  time: 2.2639  data_time: 0.1102  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:07:06 d2.utils.events]: \u001b[0m eta: 5:33:48  iter: 1179  total_loss: 3.749  loss_cls_stage0: 0.2402  loss_box_reg_stage0: 0.5195  loss_cls_stage1: 0.2603  loss_box_reg_stage1: 0.931  loss_cls_stage2: 0.2851  loss_box_reg_stage2: 0.9137  loss_mask: 0.2885  loss_rpn_cls: 0.05612  loss_rpn_loc: 0.2122  time: 2.2658  data_time: 0.0978  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:07:51 d2.utils.events]: \u001b[0m eta: 5:33:02  iter: 1199  total_loss: 3.685  loss_cls_stage0: 0.2065  loss_box_reg_stage0: 0.4988  loss_cls_stage1: 0.2349  loss_box_reg_stage1: 0.8763  loss_cls_stage2: 0.2532  loss_box_reg_stage2: 0.8868  loss_mask: 0.2889  loss_rpn_cls: 0.08342  loss_rpn_loc: 0.1907  time: 2.2654  data_time: 0.0977  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:08:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:08:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:08:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:08:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:08:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:08:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.3510 s/iter. Eval: 0.0243 s/iter. Total: 0.3768 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 03:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0027 s/iter. Inference: 0.3526 s/iter. Eval: 0.0526 s/iter. Total: 0.4081 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 03:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0027 s/iter. Inference: 0.3502 s/iter. Eval: 0.0526 s/iter. Total: 0.4057 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 03:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0027 s/iter. Inference: 0.3479 s/iter. Eval: 0.0556 s/iter. Total: 0.4065 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 03:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0028 s/iter. Inference: 0.3505 s/iter. Eval: 0.0556 s/iter. Total: 0.4092 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0028 s/iter. Inference: 0.3487 s/iter. Eval: 0.0577 s/iter. Total: 0.4094 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 03:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0027 s/iter. Inference: 0.3481 s/iter. Eval: 0.0625 s/iter. Total: 0.4136 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0027 s/iter. Inference: 0.3497 s/iter. Eval: 0.0648 s/iter. Total: 0.4175 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 03:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0028 s/iter. Inference: 0.3490 s/iter. Eval: 0.0624 s/iter. Total: 0.4144 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 03:09:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.172954 (0.415284 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:09:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.349337 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:09:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:09:07 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2904288608975661\n",
      "\u001b[32m[12/29 03:09:08 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.29043, better than last best score 0.28667 @ iteration 725.\n",
      "\u001b[32m[12/29 03:09:30 d2.utils.events]: \u001b[0m eta: 5:32:21  iter: 1219  total_loss: 3.597  loss_cls_stage0: 0.2043  loss_box_reg_stage0: 0.4723  loss_cls_stage1: 0.2093  loss_box_reg_stage1: 0.8739  loss_cls_stage2: 0.2531  loss_box_reg_stage2: 0.9122  loss_mask: 0.28  loss_rpn_cls: 0.07255  loss_rpn_loc: 0.226  time: 2.2646  data_time: 0.1032  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:10:16 d2.utils.events]: \u001b[0m eta: 5:31:38  iter: 1239  total_loss: 3.544  loss_cls_stage0: 0.221  loss_box_reg_stage0: 0.4743  loss_cls_stage1: 0.2344  loss_box_reg_stage1: 0.8628  loss_cls_stage2: 0.2466  loss_box_reg_stage2: 0.8921  loss_mask: 0.2785  loss_rpn_cls: 0.07854  loss_rpn_loc: 0.1979  time: 2.2659  data_time: 0.0986  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:11:02 d2.utils.events]: \u001b[0m eta: 5:31:08  iter: 1259  total_loss: 3.575  loss_cls_stage0: 0.2144  loss_box_reg_stage0: 0.4942  loss_cls_stage1: 0.2201  loss_box_reg_stage1: 0.9113  loss_cls_stage2: 0.2431  loss_box_reg_stage2: 0.9833  loss_mask: 0.2816  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.1865  time: 2.2658  data_time: 0.0843  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:11:46 d2.utils.events]: \u001b[0m eta: 5:30:10  iter: 1279  total_loss: 3.627  loss_cls_stage0: 0.205  loss_box_reg_stage0: 0.5055  loss_cls_stage1: 0.2255  loss_box_reg_stage1: 0.8795  loss_cls_stage2: 0.2495  loss_box_reg_stage2: 0.9024  loss_mask: 0.2773  loss_rpn_cls: 0.063  loss_rpn_loc: 0.2006  time: 2.2653  data_time: 0.0653  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:12:33 d2.utils.events]: \u001b[0m eta: 5:29:40  iter: 1299  total_loss: 3.534  loss_cls_stage0: 0.2106  loss_box_reg_stage0: 0.4838  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.8838  loss_cls_stage2: 0.254  loss_box_reg_stage2: 0.9593  loss_mask: 0.2799  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.2011  time: 2.2664  data_time: 0.1241  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:13:16 d2.utils.events]: \u001b[0m eta: 5:28:37  iter: 1319  total_loss: 3.725  loss_cls_stage0: 0.2513  loss_box_reg_stage0: 0.5056  loss_cls_stage1: 0.261  loss_box_reg_stage1: 0.9281  loss_cls_stage2: 0.2802  loss_box_reg_stage2: 0.938  loss_mask: 0.2606  loss_rpn_cls: 0.07155  loss_rpn_loc: 0.2124  time: 2.2647  data_time: 0.0719  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:14:02 d2.utils.events]: \u001b[0m eta: 5:28:13  iter: 1339  total_loss: 3.664  loss_cls_stage0: 0.2179  loss_box_reg_stage0: 0.5076  loss_cls_stage1: 0.22  loss_box_reg_stage1: 0.8868  loss_cls_stage2: 0.2596  loss_box_reg_stage2: 0.981  loss_mask: 0.2777  loss_rpn_cls: 0.0607  loss_rpn_loc: 0.1829  time: 2.2652  data_time: 0.0831  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:14:50 d2.utils.events]: \u001b[0m eta: 5:28:06  iter: 1359  total_loss: 3.565  loss_cls_stage0: 0.2508  loss_box_reg_stage0: 0.4848  loss_cls_stage1: 0.2705  loss_box_reg_stage1: 0.8338  loss_cls_stage2: 0.2791  loss_box_reg_stage2: 0.8325  loss_mask: 0.2759  loss_rpn_cls: 0.09275  loss_rpn_loc: 0.2096  time: 2.2667  data_time: 0.1195  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:15:34 d2.utils.events]: \u001b[0m eta: 5:27:01  iter: 1379  total_loss: 3.463  loss_cls_stage0: 0.2013  loss_box_reg_stage0: 0.4774  loss_cls_stage1: 0.228  loss_box_reg_stage1: 0.888  loss_cls_stage2: 0.2416  loss_box_reg_stage2: 0.9057  loss_mask: 0.2812  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.1911  time: 2.2662  data_time: 0.1021  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:16:20 d2.utils.events]: \u001b[0m eta: 5:26:16  iter: 1399  total_loss: 3.716  loss_cls_stage0: 0.2179  loss_box_reg_stage0: 0.4957  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.8923  loss_cls_stage2: 0.2633  loss_box_reg_stage2: 0.9026  loss_mask: 0.2928  loss_rpn_cls: 0.07635  loss_rpn_loc: 0.203  time: 2.2663  data_time: 0.1026  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:17:06 d2.utils.events]: \u001b[0m eta: 5:25:49  iter: 1419  total_loss: 3.428  loss_cls_stage0: 0.1765  loss_box_reg_stage0: 0.4685  loss_cls_stage1: 0.2031  loss_box_reg_stage1: 0.905  loss_cls_stage2: 0.2393  loss_box_reg_stage2: 0.9272  loss_mask: 0.292  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1763  time: 2.2668  data_time: 0.0906  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:17:52 d2.utils.events]: \u001b[0m eta: 5:25:10  iter: 1439  total_loss: 3.635  loss_cls_stage0: 0.2396  loss_box_reg_stage0: 0.5017  loss_cls_stage1: 0.2428  loss_box_reg_stage1: 0.8491  loss_cls_stage2: 0.2817  loss_box_reg_stage2: 0.8903  loss_mask: 0.2756  loss_rpn_cls: 0.06255  loss_rpn_loc: 0.2075  time: 2.2677  data_time: 0.0981  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:18:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:18:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:18:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:18:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:18:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:18:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0021 s/iter. Inference: 0.3778 s/iter. Eval: 0.0195 s/iter. Total: 0.3995 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/29 03:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0021 s/iter. Inference: 0.3732 s/iter. Eval: 0.0455 s/iter. Total: 0.4209 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 03:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0026 s/iter. Inference: 0.3665 s/iter. Eval: 0.0525 s/iter. Total: 0.4217 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/29 03:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0028 s/iter. Inference: 0.3740 s/iter. Eval: 0.0545 s/iter. Total: 0.4315 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 03:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0028 s/iter. Inference: 0.3716 s/iter. Eval: 0.0528 s/iter. Total: 0.4275 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/29 03:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0028 s/iter. Inference: 0.3672 s/iter. Eval: 0.0513 s/iter. Total: 0.4215 s/iter. ETA=0:00:20\n",
      "\u001b[32m[12/29 03:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0029 s/iter. Inference: 0.3685 s/iter. Eval: 0.0605 s/iter. Total: 0.4321 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 03:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0031 s/iter. Inference: 0.3663 s/iter. Eval: 0.0611 s/iter. Total: 0.4306 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/29 03:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0031 s/iter. Inference: 0.3636 s/iter. Eval: 0.0607 s/iter. Total: 0.4276 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 03:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0030 s/iter. Inference: 0.3599 s/iter. Eval: 0.0583 s/iter. Total: 0.4215 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/29 03:19:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.091787 (0.423205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:19:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.359902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:19:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:19:13 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2958716310078182\n",
      "\u001b[32m[12/29 03:19:16 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.29587, better than last best score 0.29043 @ iteration 1209.\n",
      "\u001b[32m[12/29 03:19:33 d2.utils.events]: \u001b[0m eta: 5:24:18  iter: 1459  total_loss: 3.431  loss_cls_stage0: 0.2018  loss_box_reg_stage0: 0.4667  loss_cls_stage1: 0.2092  loss_box_reg_stage1: 0.9007  loss_cls_stage2: 0.2423  loss_box_reg_stage2: 0.8854  loss_mask: 0.2759  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.1923  time: 2.2668  data_time: 0.0644  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:20:17 d2.utils.events]: \u001b[0m eta: 5:23:39  iter: 1479  total_loss: 3.593  loss_cls_stage0: 0.242  loss_box_reg_stage0: 0.4654  loss_cls_stage1: 0.2582  loss_box_reg_stage1: 0.8839  loss_cls_stage2: 0.2713  loss_box_reg_stage2: 0.924  loss_mask: 0.2709  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.2106  time: 2.2656  data_time: 0.0663  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:21:02 d2.utils.events]: \u001b[0m eta: 5:22:36  iter: 1499  total_loss: 3.615  loss_cls_stage0: 0.2236  loss_box_reg_stage0: 0.513  loss_cls_stage1: 0.2463  loss_box_reg_stage1: 0.9018  loss_cls_stage2: 0.2652  loss_box_reg_stage2: 0.9322  loss_mask: 0.2849  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.1974  time: 2.2653  data_time: 0.0843  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:21:47 d2.utils.events]: \u001b[0m eta: 5:22:09  iter: 1519  total_loss: 3.607  loss_cls_stage0: 0.2272  loss_box_reg_stage0: 0.4835  loss_cls_stage1: 0.2459  loss_box_reg_stage1: 0.9042  loss_cls_stage2: 0.2754  loss_box_reg_stage2: 0.8816  loss_mask: 0.2685  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.201  time: 2.2650  data_time: 0.0893  lr: 0.001  max_mem: 29511M\n",
      "\u001b[32m[12/29 03:22:32 d2.utils.events]: \u001b[0m eta: 5:21:37  iter: 1539  total_loss: 3.414  loss_cls_stage0: 0.2085  loss_box_reg_stage0: 0.467  loss_cls_stage1: 0.2172  loss_box_reg_stage1: 0.8598  loss_cls_stage2: 0.2488  loss_box_reg_stage2: 0.9302  loss_mask: 0.2729  loss_rpn_cls: 0.05825  loss_rpn_loc: 0.176  time: 2.2654  data_time: 0.0799  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:23:19 d2.utils.events]: \u001b[0m eta: 5:21:10  iter: 1559  total_loss: 3.571  loss_cls_stage0: 0.2124  loss_box_reg_stage0: 0.4893  loss_cls_stage1: 0.2413  loss_box_reg_stage1: 0.9302  loss_cls_stage2: 0.2601  loss_box_reg_stage2: 0.9533  loss_mask: 0.2756  loss_rpn_cls: 0.04709  loss_rpn_loc: 0.1882  time: 2.2662  data_time: 0.0848  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:24:05 d2.utils.events]: \u001b[0m eta: 5:20:24  iter: 1579  total_loss: 3.68  loss_cls_stage0: 0.2214  loss_box_reg_stage0: 0.5141  loss_cls_stage1: 0.2468  loss_box_reg_stage1: 0.9244  loss_cls_stage2: 0.2623  loss_box_reg_stage2: 0.8892  loss_mask: 0.2772  loss_rpn_cls: 0.09313  loss_rpn_loc: 0.2165  time: 2.2668  data_time: 0.0972  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:24:50 d2.utils.events]: \u001b[0m eta: 5:19:49  iter: 1599  total_loss: 3.627  loss_cls_stage0: 0.2128  loss_box_reg_stage0: 0.4809  loss_cls_stage1: 0.223  loss_box_reg_stage1: 0.907  loss_cls_stage2: 0.2583  loss_box_reg_stage2: 0.9359  loss_mask: 0.2743  loss_rpn_cls: 0.07022  loss_rpn_loc: 0.2022  time: 2.2664  data_time: 0.0704  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:25:35 d2.utils.events]: \u001b[0m eta: 5:18:39  iter: 1619  total_loss: 3.515  loss_cls_stage0: 0.1992  loss_box_reg_stage0: 0.5018  loss_cls_stage1: 0.225  loss_box_reg_stage1: 0.928  loss_cls_stage2: 0.2441  loss_box_reg_stage2: 0.9473  loss_mask: 0.2694  loss_rpn_cls: 0.06735  loss_rpn_loc: 0.1819  time: 2.2662  data_time: 0.1075  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:26:21 d2.utils.events]: \u001b[0m eta: 5:17:58  iter: 1639  total_loss: 3.59  loss_cls_stage0: 0.218  loss_box_reg_stage0: 0.4974  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.8543  loss_cls_stage2: 0.2637  loss_box_reg_stage2: 0.8789  loss_mask: 0.291  loss_rpn_cls: 0.0731  loss_rpn_loc: 0.1824  time: 2.2668  data_time: 0.1265  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:27:07 d2.utils.events]: \u001b[0m eta: 5:17:22  iter: 1659  total_loss: 3.553  loss_cls_stage0: 0.2191  loss_box_reg_stage0: 0.5098  loss_cls_stage1: 0.2392  loss_box_reg_stage1: 0.8933  loss_cls_stage2: 0.2505  loss_box_reg_stage2: 0.8871  loss_mask: 0.2783  loss_rpn_cls: 0.06685  loss_rpn_loc: 0.2152  time: 2.2670  data_time: 0.1078  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:27:56 d2.utils.events]: \u001b[0m eta: 5:17:02  iter: 1679  total_loss: 3.643  loss_cls_stage0: 0.2073  loss_box_reg_stage0: 0.4954  loss_cls_stage1: 0.2381  loss_box_reg_stage1: 0.8697  loss_cls_stage2: 0.2524  loss_box_reg_stage2: 0.9389  loss_mask: 0.276  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.1976  time: 2.2692  data_time: 0.0996  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:28:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:28:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:28:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:28:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:28:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:28:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0021 s/iter. Inference: 0.3478 s/iter. Eval: 0.0185 s/iter. Total: 0.3684 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 03:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0034 s/iter. Inference: 0.3427 s/iter. Eval: 0.0517 s/iter. Total: 0.3981 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0031 s/iter. Inference: 0.3408 s/iter. Eval: 0.0533 s/iter. Total: 0.3973 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 03:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0029 s/iter. Inference: 0.3393 s/iter. Eval: 0.0540 s/iter. Total: 0.3965 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 03:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0029 s/iter. Inference: 0.3365 s/iter. Eval: 0.0531 s/iter. Total: 0.3927 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 03:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0028 s/iter. Inference: 0.3386 s/iter. Eval: 0.0556 s/iter. Total: 0.3972 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 03:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0029 s/iter. Inference: 0.3447 s/iter. Eval: 0.0598 s/iter. Total: 0.4075 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0029 s/iter. Inference: 0.3469 s/iter. Eval: 0.0637 s/iter. Total: 0.4136 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 03:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0029 s/iter. Inference: 0.3479 s/iter. Eval: 0.0609 s/iter. Total: 0.4119 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 03:29:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.739219 (0.411545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:29:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.347301 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:29:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:29:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3047511727059562\n",
      "\u001b[32m[12/29 03:29:23 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.30475, better than last best score 0.29587 @ iteration 1451.\n",
      "\u001b[32m[12/29 03:29:37 d2.utils.events]: \u001b[0m eta: 5:16:27  iter: 1699  total_loss: 3.573  loss_cls_stage0: 0.2167  loss_box_reg_stage0: 0.4944  loss_cls_stage1: 0.2224  loss_box_reg_stage1: 0.8816  loss_cls_stage2: 0.2575  loss_box_reg_stage2: 0.9447  loss_mask: 0.2804  loss_rpn_cls: 0.07093  loss_rpn_loc: 0.1983  time: 2.2694  data_time: 0.1071  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:30:22 d2.utils.events]: \u001b[0m eta: 5:15:31  iter: 1719  total_loss: 3.459  loss_cls_stage0: 0.2222  loss_box_reg_stage0: 0.4648  loss_cls_stage1: 0.2216  loss_box_reg_stage1: 0.8479  loss_cls_stage2: 0.2322  loss_box_reg_stage2: 0.8953  loss_mask: 0.269  loss_rpn_cls: 0.05026  loss_rpn_loc: 0.1894  time: 2.2694  data_time: 0.0786  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:31:06 d2.utils.events]: \u001b[0m eta: 5:14:35  iter: 1739  total_loss: 3.443  loss_cls_stage0: 0.19  loss_box_reg_stage0: 0.4617  loss_cls_stage1: 0.2083  loss_box_reg_stage1: 0.9004  loss_cls_stage2: 0.2322  loss_box_reg_stage2: 0.9603  loss_mask: 0.2766  loss_rpn_cls: 0.05695  loss_rpn_loc: 0.1766  time: 2.2686  data_time: 0.0807  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:31:53 d2.utils.events]: \u001b[0m eta: 5:13:33  iter: 1759  total_loss: 3.608  loss_cls_stage0: 0.2305  loss_box_reg_stage0: 0.5089  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.8781  loss_cls_stage2: 0.2741  loss_box_reg_stage2: 0.9102  loss_mask: 0.2779  loss_rpn_cls: 0.08473  loss_rpn_loc: 0.2022  time: 2.2692  data_time: 0.1226  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:32:38 d2.utils.events]: \u001b[0m eta: 5:12:34  iter: 1779  total_loss: 3.544  loss_cls_stage0: 0.2202  loss_box_reg_stage0: 0.4688  loss_cls_stage1: 0.2274  loss_box_reg_stage1: 0.8551  loss_cls_stage2: 0.2511  loss_box_reg_stage2: 0.9616  loss_mask: 0.2644  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.1793  time: 2.2692  data_time: 0.1246  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:33:22 d2.utils.events]: \u001b[0m eta: 5:11:31  iter: 1799  total_loss: 3.543  loss_cls_stage0: 0.1992  loss_box_reg_stage0: 0.4971  loss_cls_stage1: 0.2267  loss_box_reg_stage1: 0.8891  loss_cls_stage2: 0.261  loss_box_reg_stage2: 1.012  loss_mask: 0.2818  loss_rpn_cls: 0.04749  loss_rpn_loc: 0.1649  time: 2.2682  data_time: 0.0881  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:34:07 d2.utils.events]: \u001b[0m eta: 5:10:38  iter: 1819  total_loss: 3.489  loss_cls_stage0: 0.2113  loss_box_reg_stage0: 0.4923  loss_cls_stage1: 0.2268  loss_box_reg_stage1: 0.8646  loss_cls_stage2: 0.2491  loss_box_reg_stage2: 0.9038  loss_mask: 0.2775  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.197  time: 2.2682  data_time: 0.0801  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:34:52 d2.utils.events]: \u001b[0m eta: 5:09:58  iter: 1839  total_loss: 3.545  loss_cls_stage0: 0.2056  loss_box_reg_stage0: 0.4784  loss_cls_stage1: 0.2226  loss_box_reg_stage1: 0.8897  loss_cls_stage2: 0.2531  loss_box_reg_stage2: 0.9044  loss_mask: 0.2779  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1835  time: 2.2682  data_time: 0.1353  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:35:39 d2.utils.events]: \u001b[0m eta: 5:09:14  iter: 1859  total_loss: 3.586  loss_cls_stage0: 0.2163  loss_box_reg_stage0: 0.4959  loss_cls_stage1: 0.2402  loss_box_reg_stage1: 0.9277  loss_cls_stage2: 0.2469  loss_box_reg_stage2: 0.9053  loss_mask: 0.2951  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.2112  time: 2.2687  data_time: 0.1172  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:36:24 d2.utils.events]: \u001b[0m eta: 5:08:27  iter: 1879  total_loss: 3.517  loss_cls_stage0: 0.213  loss_box_reg_stage0: 0.4776  loss_cls_stage1: 0.2177  loss_box_reg_stage1: 0.9176  loss_cls_stage2: 0.2293  loss_box_reg_stage2: 1.022  loss_mask: 0.2702  loss_rpn_cls: 0.04293  loss_rpn_loc: 0.1427  time: 2.2686  data_time: 0.0711  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:37:09 d2.utils.events]: \u001b[0m eta: 5:07:29  iter: 1899  total_loss: 3.473  loss_cls_stage0: 0.2241  loss_box_reg_stage0: 0.4501  loss_cls_stage1: 0.2501  loss_box_reg_stage1: 0.8117  loss_cls_stage2: 0.2588  loss_box_reg_stage2: 0.8386  loss_mask: 0.2644  loss_rpn_cls: 0.09086  loss_rpn_loc: 0.1781  time: 2.2684  data_time: 0.1003  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:37:56 d2.utils.events]: \u001b[0m eta: 5:06:51  iter: 1919  total_loss: 3.529  loss_cls_stage0: 0.2047  loss_box_reg_stage0: 0.4634  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.8832  loss_cls_stage2: 0.2424  loss_box_reg_stage2: 0.9073  loss_mask: 0.29  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.183  time: 2.2691  data_time: 0.0999  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:38:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:38:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:38:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:38:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:38:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:38:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0020 s/iter. Inference: 0.3382 s/iter. Eval: 0.0200 s/iter. Total: 0.3601 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 03:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0025 s/iter. Inference: 0.3457 s/iter. Eval: 0.0441 s/iter. Total: 0.3925 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0027 s/iter. Inference: 0.3468 s/iter. Eval: 0.0431 s/iter. Total: 0.3928 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 03:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0028 s/iter. Inference: 0.3568 s/iter. Eval: 0.0456 s/iter. Total: 0.4057 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 03:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0027 s/iter. Inference: 0.3563 s/iter. Eval: 0.0440 s/iter. Total: 0.4036 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0029 s/iter. Inference: 0.3580 s/iter. Eval: 0.0462 s/iter. Total: 0.4075 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 03:39:09 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0029 s/iter. Inference: 0.3598 s/iter. Eval: 0.0506 s/iter. Total: 0.4137 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 03:39:14 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0029 s/iter. Inference: 0.3604 s/iter. Eval: 0.0536 s/iter. Total: 0.4173 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 03:39:19 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0028 s/iter. Inference: 0.3617 s/iter. Eval: 0.0514 s/iter. Total: 0.4165 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 03:39:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.084989 (0.414526 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:39:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.359839 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:39:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:39:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2987837654101612\n",
      "\u001b[32m[12/29 03:39:23 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29878, not better than best score 0.30475 @ iteration 1693.\n",
      "\u001b[32m[12/29 03:39:33 d2.utils.events]: \u001b[0m eta: 5:06:05  iter: 1939  total_loss: 3.523  loss_cls_stage0: 0.2298  loss_box_reg_stage0: 0.4986  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.8767  loss_cls_stage2: 0.2743  loss_box_reg_stage2: 0.8665  loss_mask: 0.2858  loss_rpn_cls: 0.06238  loss_rpn_loc: 0.1899  time: 2.2687  data_time: 0.1112  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:40:16 d2.utils.events]: \u001b[0m eta: 5:05:19  iter: 1959  total_loss: 3.462  loss_cls_stage0: 0.2057  loss_box_reg_stage0: 0.5063  loss_cls_stage1: 0.21  loss_box_reg_stage1: 0.9031  loss_cls_stage2: 0.2454  loss_box_reg_stage2: 0.9393  loss_mask: 0.2816  loss_rpn_cls: 0.0481  loss_rpn_loc: 0.1652  time: 2.2678  data_time: 0.0655  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:41:02 d2.utils.events]: \u001b[0m eta: 5:04:34  iter: 1979  total_loss: 3.411  loss_cls_stage0: 0.2124  loss_box_reg_stage0: 0.4697  loss_cls_stage1: 0.2283  loss_box_reg_stage1: 0.864  loss_cls_stage2: 0.256  loss_box_reg_stage2: 0.8517  loss_mask: 0.2661  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.1872  time: 2.2681  data_time: 0.0978  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:41:47 d2.utils.events]: \u001b[0m eta: 5:03:59  iter: 1999  total_loss: 3.679  loss_cls_stage0: 0.2401  loss_box_reg_stage0: 0.4997  loss_cls_stage1: 0.256  loss_box_reg_stage1: 0.8845  loss_cls_stage2: 0.2619  loss_box_reg_stage2: 0.892  loss_mask: 0.2769  loss_rpn_cls: 0.07347  loss_rpn_loc: 0.1961  time: 2.2680  data_time: 0.0879  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:42:33 d2.utils.events]: \u001b[0m eta: 5:03:08  iter: 2019  total_loss: 3.452  loss_cls_stage0: 0.2172  loss_box_reg_stage0: 0.4725  loss_cls_stage1: 0.2306  loss_box_reg_stage1: 0.8632  loss_cls_stage2: 0.2461  loss_box_reg_stage2: 0.89  loss_mask: 0.2681  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.1825  time: 2.2683  data_time: 0.0960  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:43:17 d2.utils.events]: \u001b[0m eta: 5:01:29  iter: 2039  total_loss: 3.609  loss_cls_stage0: 0.1812  loss_box_reg_stage0: 0.487  loss_cls_stage1: 0.182  loss_box_reg_stage1: 0.8968  loss_cls_stage2: 0.222  loss_box_reg_stage2: 0.9106  loss_mask: 0.289  loss_rpn_cls: 0.05179  loss_rpn_loc: 0.1941  time: 2.2673  data_time: 0.0594  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:44:01 d2.utils.events]: \u001b[0m eta: 5:01:07  iter: 2059  total_loss: 3.394  loss_cls_stage0: 0.1875  loss_box_reg_stage0: 0.4628  loss_cls_stage1: 0.197  loss_box_reg_stage1: 0.8907  loss_cls_stage2: 0.237  loss_box_reg_stage2: 0.9229  loss_mask: 0.2501  loss_rpn_cls: 0.06229  loss_rpn_loc: 0.1839  time: 2.2670  data_time: 0.0935  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:44:47 d2.utils.events]: \u001b[0m eta: 4:59:58  iter: 2079  total_loss: 3.517  loss_cls_stage0: 0.1973  loss_box_reg_stage0: 0.4934  loss_cls_stage1: 0.2229  loss_box_reg_stage1: 0.8776  loss_cls_stage2: 0.2587  loss_box_reg_stage2: 0.9486  loss_mask: 0.2794  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.1879  time: 2.2671  data_time: 0.0940  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:45:35 d2.utils.events]: \u001b[0m eta: 4:59:36  iter: 2099  total_loss: 3.47  loss_cls_stage0: 0.2187  loss_box_reg_stage0: 0.4836  loss_cls_stage1: 0.2322  loss_box_reg_stage1: 0.8036  loss_cls_stage2: 0.2514  loss_box_reg_stage2: 0.8352  loss_mask: 0.2766  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.2043  time: 2.2682  data_time: 0.1158  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:46:22 d2.utils.events]: \u001b[0m eta: 4:59:39  iter: 2119  total_loss: 3.451  loss_cls_stage0: 0.2211  loss_box_reg_stage0: 0.4854  loss_cls_stage1: 0.2484  loss_box_reg_stage1: 0.834  loss_cls_stage2: 0.2615  loss_box_reg_stage2: 0.8757  loss_mask: 0.2975  loss_rpn_cls: 0.08211  loss_rpn_loc: 0.2254  time: 2.2691  data_time: 0.0920  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:47:07 d2.utils.events]: \u001b[0m eta: 4:58:53  iter: 2139  total_loss: 3.578  loss_cls_stage0: 0.22  loss_box_reg_stage0: 0.4752  loss_cls_stage1: 0.2516  loss_box_reg_stage1: 0.8881  loss_cls_stage2: 0.2759  loss_box_reg_stage2: 0.9193  loss_mask: 0.27  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1998  time: 2.2692  data_time: 0.1097  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:47:55 d2.utils.events]: \u001b[0m eta: 4:58:21  iter: 2159  total_loss: 3.474  loss_cls_stage0: 0.2218  loss_box_reg_stage0: 0.4867  loss_cls_stage1: 0.235  loss_box_reg_stage1: 0.8336  loss_cls_stage2: 0.2511  loss_box_reg_stage2: 0.8275  loss_mask: 0.2758  loss_rpn_cls: 0.06885  loss_rpn_loc: 0.2037  time: 2.2704  data_time: 0.1383  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:48:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:48:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:48:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:48:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:48:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:48:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0019 s/iter. Inference: 0.3599 s/iter. Eval: 0.0187 s/iter. Total: 0.3805 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 03:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0024 s/iter. Inference: 0.3903 s/iter. Eval: 0.0443 s/iter. Total: 0.4373 s/iter. ETA=0:00:42\n",
      "\u001b[32m[12/29 03:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0026 s/iter. Inference: 0.3826 s/iter. Eval: 0.0514 s/iter. Total: 0.4371 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 03:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0027 s/iter. Inference: 0.3727 s/iter. Eval: 0.0528 s/iter. Total: 0.4286 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 03:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0028 s/iter. Inference: 0.3686 s/iter. Eval: 0.0504 s/iter. Total: 0.4221 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 03:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0027 s/iter. Inference: 0.3661 s/iter. Eval: 0.0514 s/iter. Total: 0.4206 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 03:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0027 s/iter. Inference: 0.3660 s/iter. Eval: 0.0589 s/iter. Total: 0.4280 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 03:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0027 s/iter. Inference: 0.3636 s/iter. Eval: 0.0607 s/iter. Total: 0.4274 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 03:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0027 s/iter. Inference: 0.3608 s/iter. Eval: 0.0576 s/iter. Total: 0.4214 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 03:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.660220 (0.419485 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.358868 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:49:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:49:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2909991448035262\n",
      "\u001b[32m[12/29 03:49:29 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29100, not better than best score 0.30475 @ iteration 1693.\n",
      "\u001b[32m[12/29 03:49:34 d2.utils.events]: \u001b[0m eta: 4:57:28  iter: 2179  total_loss: 3.386  loss_cls_stage0: 0.1813  loss_box_reg_stage0: 0.458  loss_cls_stage1: 0.2037  loss_box_reg_stage1: 0.8766  loss_cls_stage2: 0.2223  loss_box_reg_stage2: 0.9685  loss_mask: 0.2722  loss_rpn_cls: 0.0463  loss_rpn_loc: 0.1697  time: 2.2704  data_time: 0.0691  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:50:17 d2.utils.events]: \u001b[0m eta: 4:56:22  iter: 2199  total_loss: 3.493  loss_cls_stage0: 0.2248  loss_box_reg_stage0: 0.4802  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.8485  loss_cls_stage2: 0.2576  loss_box_reg_stage2: 0.8968  loss_mask: 0.2798  loss_rpn_cls: 0.08195  loss_rpn_loc: 0.2034  time: 2.2698  data_time: 0.0849  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:51:03 d2.utils.events]: \u001b[0m eta: 4:55:50  iter: 2219  total_loss: 3.699  loss_cls_stage0: 0.2144  loss_box_reg_stage0: 0.4904  loss_cls_stage1: 0.2519  loss_box_reg_stage1: 0.893  loss_cls_stage2: 0.2698  loss_box_reg_stage2: 0.8671  loss_mask: 0.2807  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.1844  time: 2.2698  data_time: 0.1209  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:51:50 d2.utils.events]: \u001b[0m eta: 4:54:59  iter: 2239  total_loss: 3.361  loss_cls_stage0: 0.2044  loss_box_reg_stage0: 0.4854  loss_cls_stage1: 0.2262  loss_box_reg_stage1: 0.8404  loss_cls_stage2: 0.2421  loss_box_reg_stage2: 0.852  loss_mask: 0.2746  loss_rpn_cls: 0.06055  loss_rpn_loc: 0.2187  time: 2.2705  data_time: 0.1400  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:52:36 d2.utils.events]: \u001b[0m eta: 4:54:19  iter: 2259  total_loss: 3.499  loss_cls_stage0: 0.1834  loss_box_reg_stage0: 0.4748  loss_cls_stage1: 0.1963  loss_box_reg_stage1: 0.9079  loss_cls_stage2: 0.2339  loss_box_reg_stage2: 0.9544  loss_mask: 0.284  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1767  time: 2.2708  data_time: 0.0819  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:53:22 d2.utils.events]: \u001b[0m eta: 4:53:39  iter: 2279  total_loss: 3.337  loss_cls_stage0: 0.1723  loss_box_reg_stage0: 0.457  loss_cls_stage1: 0.1946  loss_box_reg_stage1: 0.8277  loss_cls_stage2: 0.2119  loss_box_reg_stage2: 0.9132  loss_mask: 0.2714  loss_rpn_cls: 0.06534  loss_rpn_loc: 0.1767  time: 2.2709  data_time: 0.0964  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:54:08 d2.utils.events]: \u001b[0m eta: 4:52:42  iter: 2299  total_loss: 3.631  loss_cls_stage0: 0.2051  loss_box_reg_stage0: 0.4893  loss_cls_stage1: 0.2265  loss_box_reg_stage1: 0.9228  loss_cls_stage2: 0.2517  loss_box_reg_stage2: 0.9618  loss_mask: 0.2608  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.1749  time: 2.2711  data_time: 0.0801  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:54:51 d2.utils.events]: \u001b[0m eta: 4:52:05  iter: 2319  total_loss: 3.62  loss_cls_stage0: 0.2238  loss_box_reg_stage0: 0.4819  loss_cls_stage1: 0.233  loss_box_reg_stage1: 0.8803  loss_cls_stage2: 0.2618  loss_box_reg_stage2: 0.9272  loss_mask: 0.2661  loss_rpn_cls: 0.07492  loss_rpn_loc: 0.1945  time: 2.2700  data_time: 0.0762  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:55:37 d2.utils.events]: \u001b[0m eta: 4:51:11  iter: 2339  total_loss: 3.403  loss_cls_stage0: 0.1988  loss_box_reg_stage0: 0.4795  loss_cls_stage1: 0.2347  loss_box_reg_stage1: 0.8348  loss_cls_stage2: 0.2522  loss_box_reg_stage2: 0.8791  loss_mask: 0.2769  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.1772  time: 2.2704  data_time: 0.0921  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:56:20 d2.utils.events]: \u001b[0m eta: 4:50:11  iter: 2359  total_loss: 3.507  loss_cls_stage0: 0.2196  loss_box_reg_stage0: 0.4748  loss_cls_stage1: 0.2202  loss_box_reg_stage1: 0.8625  loss_cls_stage2: 0.2498  loss_box_reg_stage2: 0.8564  loss_mask: 0.2861  loss_rpn_cls: 0.05915  loss_rpn_loc: 0.1945  time: 2.2692  data_time: 0.0888  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:57:05 d2.utils.events]: \u001b[0m eta: 4:49:55  iter: 2379  total_loss: 3.436  loss_cls_stage0: 0.1904  loss_box_reg_stage0: 0.4811  loss_cls_stage1: 0.2104  loss_box_reg_stage1: 0.8508  loss_cls_stage2: 0.2347  loss_box_reg_stage2: 0.8864  loss_mask: 0.2826  loss_rpn_cls: 0.07321  loss_rpn_loc: 0.2134  time: 2.2694  data_time: 0.1029  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:57:50 d2.utils.events]: \u001b[0m eta: 4:48:49  iter: 2399  total_loss: 3.468  loss_cls_stage0: 0.1971  loss_box_reg_stage0: 0.4653  loss_cls_stage1: 0.2075  loss_box_reg_stage1: 0.8686  loss_cls_stage2: 0.2349  loss_box_reg_stage2: 0.9487  loss_mask: 0.2705  loss_rpn_cls: 0.05814  loss_rpn_loc: 0.2027  time: 2.2692  data_time: 0.0743  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 03:58:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:58:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:58:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:58:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:58:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:58:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0019 s/iter. Inference: 0.3507 s/iter. Eval: 0.0204 s/iter. Total: 0.3730 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 03:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0023 s/iter. Inference: 0.3499 s/iter. Eval: 0.0507 s/iter. Total: 0.4030 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 03:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0025 s/iter. Inference: 0.3478 s/iter. Eval: 0.0527 s/iter. Total: 0.4032 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 03:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0029 s/iter. Inference: 0.3582 s/iter. Eval: 0.0552 s/iter. Total: 0.4164 s/iter. ETA=0:00:30\n",
      "\u001b[32m[12/29 03:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 60/121. Dataloading: 0.0028 s/iter. Inference: 0.3620 s/iter. Eval: 0.0552 s/iter. Total: 0.4202 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 03:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0030 s/iter. Inference: 0.3683 s/iter. Eval: 0.0548 s/iter. Total: 0.4262 s/iter. ETA=0:00:21\n",
      "\u001b[32m[12/29 03:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0029 s/iter. Inference: 0.3686 s/iter. Eval: 0.0628 s/iter. Total: 0.4345 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 03:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0029 s/iter. Inference: 0.3681 s/iter. Eval: 0.0639 s/iter. Total: 0.4351 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/29 03:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0029 s/iter. Inference: 0.3677 s/iter. Eval: 0.0642 s/iter. Total: 0.4350 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 03:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0028 s/iter. Inference: 0.3646 s/iter. Eval: 0.0614 s/iter. Total: 0.4289 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/29 03:59:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.868958 (0.429905 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:59:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.364199 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:59:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:59:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3002434108954231\n",
      "\u001b[32m[12/29 03:59:30 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30024, not better than best score 0.30475 @ iteration 1693.\n",
      "\u001b[32m[12/29 03:59:30 d2.utils.events]: \u001b[0m eta: 4:48:05  iter: 2419  total_loss: 3.428  loss_cls_stage0: 0.189  loss_box_reg_stage0: 0.4483  loss_cls_stage1: 0.1944  loss_box_reg_stage1: 0.8404  loss_cls_stage2: 0.2297  loss_box_reg_stage2: 0.945  loss_mask: 0.269  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.1514  time: 2.2692  data_time: 0.1114  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:00:13 d2.utils.events]: \u001b[0m eta: 4:47:07  iter: 2439  total_loss: 3.585  loss_cls_stage0: 0.2189  loss_box_reg_stage0: 0.5016  loss_cls_stage1: 0.2324  loss_box_reg_stage1: 0.9041  loss_cls_stage2: 0.2483  loss_box_reg_stage2: 0.9539  loss_mask: 0.2753  loss_rpn_cls: 0.04699  loss_rpn_loc: 0.1584  time: 2.2681  data_time: 0.0459  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:00:57 d2.utils.events]: \u001b[0m eta: 4:46:13  iter: 2459  total_loss: 3.295  loss_cls_stage0: 0.1866  loss_box_reg_stage0: 0.4791  loss_cls_stage1: 0.2095  loss_box_reg_stage1: 0.822  loss_cls_stage2: 0.2362  loss_box_reg_stage2: 0.8264  loss_mask: 0.284  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.1639  time: 2.2674  data_time: 0.0827  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:01:41 d2.utils.events]: \u001b[0m eta: 4:44:49  iter: 2479  total_loss: 3.547  loss_cls_stage0: 0.2248  loss_box_reg_stage0: 0.4641  loss_cls_stage1: 0.2216  loss_box_reg_stage1: 0.911  loss_cls_stage2: 0.2494  loss_box_reg_stage2: 0.93  loss_mask: 0.2732  loss_rpn_cls: 0.04822  loss_rpn_loc: 0.1962  time: 2.2670  data_time: 0.0675  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:02:27 d2.utils.events]: \u001b[0m eta: 4:44:42  iter: 2499  total_loss: 3.461  loss_cls_stage0: 0.2274  loss_box_reg_stage0: 0.499  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.859  loss_cls_stage2: 0.248  loss_box_reg_stage2: 0.813  loss_mask: 0.2938  loss_rpn_cls: 0.07861  loss_rpn_loc: 0.2192  time: 2.2671  data_time: 0.1331  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:03:14 d2.utils.events]: \u001b[0m eta: 4:43:56  iter: 2519  total_loss: 3.421  loss_cls_stage0: 0.1857  loss_box_reg_stage0: 0.4789  loss_cls_stage1: 0.1983  loss_box_reg_stage1: 0.8688  loss_cls_stage2: 0.2279  loss_box_reg_stage2: 0.9585  loss_mask: 0.2799  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.1758  time: 2.2678  data_time: 0.1298  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:04:01 d2.utils.events]: \u001b[0m eta: 4:43:19  iter: 2539  total_loss: 3.349  loss_cls_stage0: 0.2202  loss_box_reg_stage0: 0.4663  loss_cls_stage1: 0.2299  loss_box_reg_stage1: 0.8616  loss_cls_stage2: 0.2427  loss_box_reg_stage2: 0.9056  loss_mask: 0.2617  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.1859  time: 2.2684  data_time: 0.0914  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:04:45 d2.utils.events]: \u001b[0m eta: 4:42:06  iter: 2559  total_loss: 3.566  loss_cls_stage0: 0.1892  loss_box_reg_stage0: 0.4538  loss_cls_stage1: 0.2135  loss_box_reg_stage1: 0.8581  loss_cls_stage2: 0.2572  loss_box_reg_stage2: 0.9892  loss_mask: 0.2849  loss_rpn_cls: 0.04713  loss_rpn_loc: 0.1824  time: 2.2681  data_time: 0.0739  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:05:30 d2.utils.events]: \u001b[0m eta: 4:40:45  iter: 2579  total_loss: 3.472  loss_cls_stage0: 0.1954  loss_box_reg_stage0: 0.4671  loss_cls_stage1: 0.2145  loss_box_reg_stage1: 0.8621  loss_cls_stage2: 0.2427  loss_box_reg_stage2: 0.9045  loss_mask: 0.2766  loss_rpn_cls: 0.0573  loss_rpn_loc: 0.1853  time: 2.2677  data_time: 0.1042  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:06:15 d2.utils.events]: \u001b[0m eta: 4:39:59  iter: 2599  total_loss: 3.437  loss_cls_stage0: 0.1896  loss_box_reg_stage0: 0.4756  loss_cls_stage1: 0.2043  loss_box_reg_stage1: 0.8488  loss_cls_stage2: 0.2427  loss_box_reg_stage2: 0.9319  loss_mask: 0.2874  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1928  time: 2.2679  data_time: 0.0944  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:07:01 d2.utils.events]: \u001b[0m eta: 4:39:15  iter: 2619  total_loss: 3.504  loss_cls_stage0: 0.2265  loss_box_reg_stage0: 0.4786  loss_cls_stage1: 0.2394  loss_box_reg_stage1: 0.8958  loss_cls_stage2: 0.2565  loss_box_reg_stage2: 0.8635  loss_mask: 0.2816  loss_rpn_cls: 0.04739  loss_rpn_loc: 0.174  time: 2.2681  data_time: 0.0750  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:07:48 d2.utils.events]: \u001b[0m eta: 4:38:34  iter: 2639  total_loss: 3.512  loss_cls_stage0: 0.2075  loss_box_reg_stage0: 0.4491  loss_cls_stage1: 0.2065  loss_box_reg_stage1: 0.8716  loss_cls_stage2: 0.2368  loss_box_reg_stage2: 0.9234  loss_mask: 0.2695  loss_rpn_cls: 0.06281  loss_rpn_loc: 0.1862  time: 2.2686  data_time: 0.1018  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:08:36 d2.utils.events]: \u001b[0m eta: 4:38:46  iter: 2659  total_loss: 3.626  loss_cls_stage0: 0.2235  loss_box_reg_stage0: 0.4858  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.9015  loss_cls_stage2: 0.2559  loss_box_reg_stage2: 0.9319  loss_mask: 0.283  loss_rpn_cls: 0.06394  loss_rpn_loc: 0.2141  time: 2.2694  data_time: 0.0891  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:08:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:08:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:08:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:08:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:08:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:08:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0017 s/iter. Inference: 0.3250 s/iter. Eval: 0.0189 s/iter. Total: 0.3456 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0020 s/iter. Inference: 0.3365 s/iter. Eval: 0.0459 s/iter. Total: 0.3847 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0021 s/iter. Inference: 0.3314 s/iter. Eval: 0.0441 s/iter. Total: 0.3779 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 04:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0022 s/iter. Inference: 0.3319 s/iter. Eval: 0.0460 s/iter. Total: 0.3803 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/29 04:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0023 s/iter. Inference: 0.3402 s/iter. Eval: 0.0466 s/iter. Total: 0.3893 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 04:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0024 s/iter. Inference: 0.3418 s/iter. Eval: 0.0477 s/iter. Total: 0.3920 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 04:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0024 s/iter. Inference: 0.3475 s/iter. Eval: 0.0504 s/iter. Total: 0.4005 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 04:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0026 s/iter. Inference: 0.3482 s/iter. Eval: 0.0530 s/iter. Total: 0.4040 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 04:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0027 s/iter. Inference: 0.3555 s/iter. Eval: 0.0520 s/iter. Total: 0.4104 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 04:09:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.732086 (0.411484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:09:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.357118 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:09:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:09:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28870177013340853\n",
      "\u001b[32m[12/29 04:09:32 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.28870, not better than best score 0.30475 @ iteration 1693.\n",
      "\u001b[32m[12/29 04:10:14 d2.utils.events]: \u001b[0m eta: 4:37:18  iter: 2679  total_loss: 3.443  loss_cls_stage0: 0.2068  loss_box_reg_stage0: 0.4742  loss_cls_stage1: 0.2168  loss_box_reg_stage1: 0.8305  loss_cls_stage2: 0.2358  loss_box_reg_stage2: 0.8797  loss_mask: 0.2648  loss_rpn_cls: 0.05743  loss_rpn_loc: 0.1937  time: 2.2701  data_time: 0.1407  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:11:00 d2.utils.events]: \u001b[0m eta: 4:36:17  iter: 2699  total_loss: 3.479  loss_cls_stage0: 0.2171  loss_box_reg_stage0: 0.4916  loss_cls_stage1: 0.2451  loss_box_reg_stage1: 0.822  loss_cls_stage2: 0.2528  loss_box_reg_stage2: 0.8363  loss_mask: 0.2756  loss_rpn_cls: 0.08011  loss_rpn_loc: 0.2239  time: 2.2700  data_time: 0.1478  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:11:47 d2.utils.events]: \u001b[0m eta: 4:36:22  iter: 2719  total_loss: 3.54  loss_cls_stage0: 0.2141  loss_box_reg_stage0: 0.5012  loss_cls_stage1: 0.2286  loss_box_reg_stage1: 0.859  loss_cls_stage2: 0.249  loss_box_reg_stage2: 0.9302  loss_mask: 0.2895  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1937  time: 2.2708  data_time: 0.1172  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:12:33 d2.utils.events]: \u001b[0m eta: 4:35:45  iter: 2739  total_loss: 3.398  loss_cls_stage0: 0.1816  loss_box_reg_stage0: 0.4435  loss_cls_stage1: 0.2024  loss_box_reg_stage1: 0.8597  loss_cls_stage2: 0.2224  loss_box_reg_stage2: 0.9906  loss_mask: 0.2635  loss_rpn_cls: 0.04998  loss_rpn_loc: 0.1797  time: 2.2709  data_time: 0.0888  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:13:19 d2.utils.events]: \u001b[0m eta: 4:35:00  iter: 2759  total_loss: 3.332  loss_cls_stage0: 0.1997  loss_box_reg_stage0: 0.4492  loss_cls_stage1: 0.1994  loss_box_reg_stage1: 0.8181  loss_cls_stage2: 0.2298  loss_box_reg_stage2: 0.8846  loss_mask: 0.2704  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.1924  time: 2.2712  data_time: 0.1004  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:14:03 d2.utils.events]: \u001b[0m eta: 4:34:15  iter: 2779  total_loss: 3.42  loss_cls_stage0: 0.2094  loss_box_reg_stage0: 0.4618  loss_cls_stage1: 0.2168  loss_box_reg_stage1: 0.8767  loss_cls_stage2: 0.2558  loss_box_reg_stage2: 0.8839  loss_mask: 0.2766  loss_rpn_cls: 0.07134  loss_rpn_loc: 0.1767  time: 2.2707  data_time: 0.0928  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:14:47 d2.utils.events]: \u001b[0m eta: 4:33:28  iter: 2799  total_loss: 3.45  loss_cls_stage0: 0.2044  loss_box_reg_stage0: 0.4628  loss_cls_stage1: 0.2088  loss_box_reg_stage1: 0.8691  loss_cls_stage2: 0.2389  loss_box_reg_stage2: 0.9308  loss_mask: 0.2767  loss_rpn_cls: 0.05453  loss_rpn_loc: 0.1549  time: 2.2701  data_time: 0.0747  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:15:32 d2.utils.events]: \u001b[0m eta: 4:32:48  iter: 2819  total_loss: 3.448  loss_cls_stage0: 0.2132  loss_box_reg_stage0: 0.4629  loss_cls_stage1: 0.2256  loss_box_reg_stage1: 0.8529  loss_cls_stage2: 0.2457  loss_box_reg_stage2: 0.9782  loss_mask: 0.2685  loss_rpn_cls: 0.03783  loss_rpn_loc: 0.1964  time: 2.2699  data_time: 0.0909  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:16:18 d2.utils.events]: \u001b[0m eta: 4:31:59  iter: 2839  total_loss: 3.555  loss_cls_stage0: 0.2238  loss_box_reg_stage0: 0.5008  loss_cls_stage1: 0.2512  loss_box_reg_stage1: 0.8839  loss_cls_stage2: 0.2594  loss_box_reg_stage2: 0.8572  loss_mask: 0.2792  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.2032  time: 2.2700  data_time: 0.1083  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:17:02 d2.utils.events]: \u001b[0m eta: 4:31:07  iter: 2859  total_loss: 3.579  loss_cls_stage0: 0.1897  loss_box_reg_stage0: 0.4766  loss_cls_stage1: 0.1967  loss_box_reg_stage1: 0.9014  loss_cls_stage2: 0.2593  loss_box_reg_stage2: 0.997  loss_mask: 0.2701  loss_rpn_cls: 0.0347  loss_rpn_loc: 0.1736  time: 2.2695  data_time: 0.0767  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:17:48 d2.utils.events]: \u001b[0m eta: 4:30:18  iter: 2879  total_loss: 3.563  loss_cls_stage0: 0.2326  loss_box_reg_stage0: 0.4657  loss_cls_stage1: 0.2446  loss_box_reg_stage1: 0.8572  loss_cls_stage2: 0.2571  loss_box_reg_stage2: 0.8994  loss_mask: 0.2741  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1924  time: 2.2698  data_time: 0.0886  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:18:34 d2.utils.events]: \u001b[0m eta: 4:29:32  iter: 2899  total_loss: 3.409  loss_cls_stage0: 0.2198  loss_box_reg_stage0: 0.471  loss_cls_stage1: 0.2318  loss_box_reg_stage1: 0.8297  loss_cls_stage2: 0.2547  loss_box_reg_stage2: 0.8821  loss_mask: 0.2747  loss_rpn_cls: 0.07974  loss_rpn_loc: 0.203  time: 2.2701  data_time: 0.1149  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:18:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:18:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:18:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:18:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:18:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:18:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0017 s/iter. Inference: 0.3502 s/iter. Eval: 0.0208 s/iter. Total: 0.3728 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 04:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0023 s/iter. Inference: 0.3466 s/iter. Eval: 0.0442 s/iter. Total: 0.3933 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0025 s/iter. Inference: 0.3482 s/iter. Eval: 0.0454 s/iter. Total: 0.3964 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 04:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0025 s/iter. Inference: 0.3439 s/iter. Eval: 0.0472 s/iter. Total: 0.3939 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 04:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0025 s/iter. Inference: 0.3427 s/iter. Eval: 0.0471 s/iter. Total: 0.3926 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 04:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0025 s/iter. Inference: 0.3434 s/iter. Eval: 0.0482 s/iter. Total: 0.3945 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 04:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0027 s/iter. Inference: 0.3438 s/iter. Eval: 0.0509 s/iter. Total: 0.3977 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 04:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0027 s/iter. Inference: 0.3476 s/iter. Eval: 0.0531 s/iter. Total: 0.4037 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 04:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0027 s/iter. Inference: 0.3471 s/iter. Eval: 0.0509 s/iter. Total: 0.4010 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 04:19:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.404574 (0.400039 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:19:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.345542 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:19:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:19:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.29377343115384524\n",
      "\u001b[32m[12/29 04:19:34 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29377, not better than best score 0.30475 @ iteration 1693.\n",
      "\u001b[32m[12/29 04:20:08 d2.utils.events]: \u001b[0m eta: 4:28:01  iter: 2919  total_loss: 3.534  loss_cls_stage0: 0.2082  loss_box_reg_stage0: 0.4715  loss_cls_stage1: 0.2288  loss_box_reg_stage1: 0.8958  loss_cls_stage2: 0.2618  loss_box_reg_stage2: 0.86  loss_mask: 0.2884  loss_rpn_cls: 0.05161  loss_rpn_loc: 0.1819  time: 2.2693  data_time: 0.0707  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:20:52 d2.utils.events]: \u001b[0m eta: 4:27:16  iter: 2939  total_loss: 3.587  loss_cls_stage0: 0.2002  loss_box_reg_stage0: 0.4848  loss_cls_stage1: 0.2174  loss_box_reg_stage1: 0.8692  loss_cls_stage2: 0.2444  loss_box_reg_stage2: 0.8954  loss_mask: 0.2779  loss_rpn_cls: 0.05629  loss_rpn_loc: 0.2067  time: 2.2687  data_time: 0.1329  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:21:37 d2.utils.events]: \u001b[0m eta: 4:26:39  iter: 2959  total_loss: 3.478  loss_cls_stage0: 0.1828  loss_box_reg_stage0: 0.4681  loss_cls_stage1: 0.205  loss_box_reg_stage1: 0.8723  loss_cls_stage2: 0.2336  loss_box_reg_stage2: 0.9138  loss_mask: 0.2848  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.1921  time: 2.2687  data_time: 0.1210  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:22:21 d2.utils.events]: \u001b[0m eta: 4:25:37  iter: 2979  total_loss: 3.504  loss_cls_stage0: 0.1933  loss_box_reg_stage0: 0.463  loss_cls_stage1: 0.2236  loss_box_reg_stage1: 0.8391  loss_cls_stage2: 0.2462  loss_box_reg_stage2: 0.9293  loss_mask: 0.272  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.1989  time: 2.2684  data_time: 0.0892  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:23:07 d2.utils.events]: \u001b[0m eta: 4:24:51  iter: 2999  total_loss: 3.578  loss_cls_stage0: 0.1992  loss_box_reg_stage0: 0.4712  loss_cls_stage1: 0.2216  loss_box_reg_stage1: 0.895  loss_cls_stage2: 0.2448  loss_box_reg_stage2: 0.9633  loss_mask: 0.2688  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1595  time: 2.2685  data_time: 0.1386  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:23:51 d2.utils.events]: \u001b[0m eta: 4:24:05  iter: 3019  total_loss: 3.448  loss_cls_stage0: 0.1892  loss_box_reg_stage0: 0.4491  loss_cls_stage1: 0.1973  loss_box_reg_stage1: 0.8849  loss_cls_stage2: 0.2304  loss_box_reg_stage2: 0.9919  loss_mask: 0.264  loss_rpn_cls: 0.04359  loss_rpn_loc: 0.1783  time: 2.2681  data_time: 0.0878  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:24:36 d2.utils.events]: \u001b[0m eta: 4:23:21  iter: 3039  total_loss: 3.54  loss_cls_stage0: 0.2069  loss_box_reg_stage0: 0.4906  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.9445  loss_cls_stage2: 0.2529  loss_box_reg_stage2: 0.9572  loss_mask: 0.2798  loss_rpn_cls: 0.05894  loss_rpn_loc: 0.1852  time: 2.2678  data_time: 0.0954  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:25:18 d2.utils.events]: \u001b[0m eta: 4:22:35  iter: 3059  total_loss: 3.468  loss_cls_stage0: 0.1937  loss_box_reg_stage0: 0.4394  loss_cls_stage1: 0.2223  loss_box_reg_stage1: 0.868  loss_cls_stage2: 0.2424  loss_box_reg_stage2: 0.9516  loss_mask: 0.2591  loss_rpn_cls: 0.05025  loss_rpn_loc: 0.1993  time: 2.2667  data_time: 0.0685  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:26:03 d2.utils.events]: \u001b[0m eta: 4:21:37  iter: 3079  total_loss: 3.363  loss_cls_stage0: 0.1889  loss_box_reg_stage0: 0.4778  loss_cls_stage1: 0.2229  loss_box_reg_stage1: 0.8506  loss_cls_stage2: 0.2426  loss_box_reg_stage2: 0.8523  loss_mask: 0.2911  loss_rpn_cls: 0.06851  loss_rpn_loc: 0.1927  time: 2.2666  data_time: 0.1049  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:26:48 d2.utils.events]: \u001b[0m eta: 4:20:34  iter: 3099  total_loss: 3.381  loss_cls_stage0: 0.2267  loss_box_reg_stage0: 0.4478  loss_cls_stage1: 0.2418  loss_box_reg_stage1: 0.8364  loss_cls_stage2: 0.2411  loss_box_reg_stage2: 0.8538  loss_mask: 0.2672  loss_rpn_cls: 0.05315  loss_rpn_loc: 0.2003  time: 2.2665  data_time: 0.1339  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:27:31 d2.utils.events]: \u001b[0m eta: 4:19:24  iter: 3119  total_loss: 3.307  loss_cls_stage0: 0.1736  loss_box_reg_stage0: 0.4538  loss_cls_stage1: 0.1937  loss_box_reg_stage1: 0.8984  loss_cls_stage2: 0.23  loss_box_reg_stage2: 1.007  loss_mask: 0.2565  loss_rpn_cls: 0.05872  loss_rpn_loc: 0.1498  time: 2.2658  data_time: 0.0574  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:28:17 d2.utils.events]: \u001b[0m eta: 4:18:40  iter: 3139  total_loss: 3.581  loss_cls_stage0: 0.2172  loss_box_reg_stage0: 0.4766  loss_cls_stage1: 0.2261  loss_box_reg_stage1: 0.8866  loss_cls_stage2: 0.2563  loss_box_reg_stage2: 0.8973  loss_mask: 0.2851  loss_rpn_cls: 0.07662  loss_rpn_loc: 0.1661  time: 2.2662  data_time: 0.1013  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:28:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:28:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:28:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:28:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:28:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:28:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0019 s/iter. Inference: 0.3412 s/iter. Eval: 0.0194 s/iter. Total: 0.3626 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 04:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0023 s/iter. Inference: 0.3415 s/iter. Eval: 0.0500 s/iter. Total: 0.3940 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0028 s/iter. Inference: 0.3455 s/iter. Eval: 0.0495 s/iter. Total: 0.3979 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 04:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0027 s/iter. Inference: 0.3473 s/iter. Eval: 0.0508 s/iter. Total: 0.4010 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 04:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0026 s/iter. Inference: 0.3441 s/iter. Eval: 0.0509 s/iter. Total: 0.3977 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 04:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0026 s/iter. Inference: 0.3488 s/iter. Eval: 0.0517 s/iter. Total: 0.4033 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 04:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0026 s/iter. Inference: 0.3475 s/iter. Eval: 0.0558 s/iter. Total: 0.4061 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 04:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0027 s/iter. Inference: 0.3489 s/iter. Eval: 0.0590 s/iter. Total: 0.4108 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 04:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0027 s/iter. Inference: 0.3469 s/iter. Eval: 0.0565 s/iter. Total: 0.4063 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 04:29:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.955002 (0.404784 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:29:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.345431 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:29:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:29:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3047862358085108\n",
      "\u001b[32m[12/29 04:29:27 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.30479, better than last best score 0.30475 @ iteration 1693.\n",
      "\u001b[32m[12/29 04:29:57 d2.utils.events]: \u001b[0m eta: 4:17:24  iter: 3159  total_loss: 3.404  loss_cls_stage0: 0.1853  loss_box_reg_stage0: 0.4446  loss_cls_stage1: 0.2114  loss_box_reg_stage1: 0.776  loss_cls_stage2: 0.2364  loss_box_reg_stage2: 0.9081  loss_mask: 0.2595  loss_rpn_cls: 0.06193  loss_rpn_loc: 0.1596  time: 2.2659  data_time: 0.0901  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:30:43 d2.utils.events]: \u001b[0m eta: 4:16:52  iter: 3179  total_loss: 3.429  loss_cls_stage0: 0.2113  loss_box_reg_stage0: 0.467  loss_cls_stage1: 0.2436  loss_box_reg_stage1: 0.8505  loss_cls_stage2: 0.265  loss_box_reg_stage2: 0.9213  loss_mask: 0.2829  loss_rpn_cls: 0.08346  loss_rpn_loc: 0.2005  time: 2.2662  data_time: 0.1211  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:31:28 d2.utils.events]: \u001b[0m eta: 4:16:25  iter: 3199  total_loss: 3.335  loss_cls_stage0: 0.1865  loss_box_reg_stage0: 0.4572  loss_cls_stage1: 0.2044  loss_box_reg_stage1: 0.8446  loss_cls_stage2: 0.2251  loss_box_reg_stage2: 0.914  loss_mask: 0.273  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.1699  time: 2.2661  data_time: 0.0854  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:32:11 d2.utils.events]: \u001b[0m eta: 4:15:15  iter: 3219  total_loss: 3.447  loss_cls_stage0: 0.1576  loss_box_reg_stage0: 0.4631  loss_cls_stage1: 0.1747  loss_box_reg_stage1: 0.8879  loss_cls_stage2: 0.2049  loss_box_reg_stage2: 0.8921  loss_mask: 0.2699  loss_rpn_cls: 0.04222  loss_rpn_loc: 0.1478  time: 2.2655  data_time: 0.0380  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:32:58 d2.utils.events]: \u001b[0m eta: 4:14:24  iter: 3239  total_loss: 3.246  loss_cls_stage0: 0.1758  loss_box_reg_stage0: 0.4507  loss_cls_stage1: 0.1938  loss_box_reg_stage1: 0.8148  loss_cls_stage2: 0.2177  loss_box_reg_stage2: 0.925  loss_mask: 0.2768  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.1747  time: 2.2659  data_time: 0.1290  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:33:46 d2.utils.events]: \u001b[0m eta: 4:13:51  iter: 3259  total_loss: 3.349  loss_cls_stage0: 0.2141  loss_box_reg_stage0: 0.4529  loss_cls_stage1: 0.2301  loss_box_reg_stage1: 0.8594  loss_cls_stage2: 0.2528  loss_box_reg_stage2: 0.9088  loss_mask: 0.2557  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.1786  time: 2.2667  data_time: 0.1507  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:34:31 d2.utils.events]: \u001b[0m eta: 4:13:00  iter: 3279  total_loss: 3.423  loss_cls_stage0: 0.1834  loss_box_reg_stage0: 0.469  loss_cls_stage1: 0.2025  loss_box_reg_stage1: 0.8601  loss_cls_stage2: 0.2436  loss_box_reg_stage2: 0.9376  loss_mask: 0.2744  loss_rpn_cls: 0.06106  loss_rpn_loc: 0.1654  time: 2.2666  data_time: 0.0983  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:35:17 d2.utils.events]: \u001b[0m eta: 4:12:27  iter: 3299  total_loss: 3.352  loss_cls_stage0: 0.2062  loss_box_reg_stage0: 0.4489  loss_cls_stage1: 0.2281  loss_box_reg_stage1: 0.7693  loss_cls_stage2: 0.2387  loss_box_reg_stage2: 0.8956  loss_mask: 0.2846  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.1931  time: 2.2670  data_time: 0.1501  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:36:04 d2.utils.events]: \u001b[0m eta: 4:11:56  iter: 3319  total_loss: 3.595  loss_cls_stage0: 0.2171  loss_box_reg_stage0: 0.477  loss_cls_stage1: 0.2251  loss_box_reg_stage1: 0.851  loss_cls_stage2: 0.2589  loss_box_reg_stage2: 0.9269  loss_mask: 0.2736  loss_rpn_cls: 0.07954  loss_rpn_loc: 0.2181  time: 2.2675  data_time: 0.1212  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:36:51 d2.utils.events]: \u001b[0m eta: 4:11:09  iter: 3339  total_loss: 3.492  loss_cls_stage0: 0.2152  loss_box_reg_stage0: 0.4539  loss_cls_stage1: 0.2303  loss_box_reg_stage1: 0.8611  loss_cls_stage2: 0.2459  loss_box_reg_stage2: 0.8804  loss_mask: 0.2763  loss_rpn_cls: 0.07582  loss_rpn_loc: 0.2082  time: 2.2679  data_time: 0.1272  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:37:38 d2.utils.events]: \u001b[0m eta: 4:10:50  iter: 3359  total_loss: 3.554  loss_cls_stage0: 0.2006  loss_box_reg_stage0: 0.5169  loss_cls_stage1: 0.2202  loss_box_reg_stage1: 0.8858  loss_cls_stage2: 0.2593  loss_box_reg_stage2: 0.9054  loss_mask: 0.2924  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.1874  time: 2.2685  data_time: 0.1021  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:38:22 d2.utils.events]: \u001b[0m eta: 4:09:26  iter: 3379  total_loss: 3.358  loss_cls_stage0: 0.1954  loss_box_reg_stage0: 0.4472  loss_cls_stage1: 0.1944  loss_box_reg_stage1: 0.8329  loss_cls_stage2: 0.2137  loss_box_reg_stage2: 0.9438  loss_mask: 0.2736  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.1716  time: 2.2679  data_time: 0.0719  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:38:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:38:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:38:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:38:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:38:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:38:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.3367 s/iter. Eval: 0.0219 s/iter. Total: 0.3602 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 04:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0019 s/iter. Inference: 0.3624 s/iter. Eval: 0.0460 s/iter. Total: 0.4105 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 04:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0022 s/iter. Inference: 0.3552 s/iter. Eval: 0.0520 s/iter. Total: 0.4095 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 04:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0023 s/iter. Inference: 0.3506 s/iter. Eval: 0.0534 s/iter. Total: 0.4064 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 04:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0023 s/iter. Inference: 0.3551 s/iter. Eval: 0.0522 s/iter. Total: 0.4098 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/29 04:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0024 s/iter. Inference: 0.3520 s/iter. Eval: 0.0527 s/iter. Total: 0.4072 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 04:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0024 s/iter. Inference: 0.3501 s/iter. Eval: 0.0590 s/iter. Total: 0.4117 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 04:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0024 s/iter. Inference: 0.3487 s/iter. Eval: 0.0621 s/iter. Total: 0.4133 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 04:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0024 s/iter. Inference: 0.3492 s/iter. Eval: 0.0595 s/iter. Total: 0.4113 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 04:39:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.207686 (0.415584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:39:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.353661 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:39:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:39:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3031806697093763\n",
      "\u001b[32m[12/29 04:39:32 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30318, not better than best score 0.30479 @ iteration 3145.\n",
      "\u001b[32m[12/29 04:39:59 d2.utils.events]: \u001b[0m eta: 4:08:35  iter: 3399  total_loss: 3.604  loss_cls_stage0: 0.2116  loss_box_reg_stage0: 0.4741  loss_cls_stage1: 0.2231  loss_box_reg_stage1: 0.9143  loss_cls_stage2: 0.2577  loss_box_reg_stage2: 0.9848  loss_mask: 0.2674  loss_rpn_cls: 0.06606  loss_rpn_loc: 0.166  time: 2.2677  data_time: 0.0917  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:40:45 d2.utils.events]: \u001b[0m eta: 4:07:57  iter: 3419  total_loss: 3.435  loss_cls_stage0: 0.2008  loss_box_reg_stage0: 0.439  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.8296  loss_cls_stage2: 0.2412  loss_box_reg_stage2: 0.8463  loss_mask: 0.2742  loss_rpn_cls: 0.08207  loss_rpn_loc: 0.2056  time: 2.2680  data_time: 0.1383  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:41:30 d2.utils.events]: \u001b[0m eta: 4:07:40  iter: 3439  total_loss: 3.437  loss_cls_stage0: 0.1832  loss_box_reg_stage0: 0.4299  loss_cls_stage1: 0.1901  loss_box_reg_stage1: 0.8583  loss_cls_stage2: 0.2185  loss_box_reg_stage2: 0.8633  loss_mask: 0.2553  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.1856  time: 2.2678  data_time: 0.0768  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:42:14 d2.utils.events]: \u001b[0m eta: 4:07:00  iter: 3459  total_loss: 3.502  loss_cls_stage0: 0.1852  loss_box_reg_stage0: 0.4767  loss_cls_stage1: 0.1828  loss_box_reg_stage1: 0.8746  loss_cls_stage2: 0.2143  loss_box_reg_stage2: 0.9887  loss_mask: 0.2818  loss_rpn_cls: 0.05007  loss_rpn_loc: 0.1736  time: 2.2673  data_time: 0.0556  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:42:58 d2.utils.events]: \u001b[0m eta: 4:06:14  iter: 3479  total_loss: 3.386  loss_cls_stage0: 0.1865  loss_box_reg_stage0: 0.4562  loss_cls_stage1: 0.1775  loss_box_reg_stage1: 0.8579  loss_cls_stage2: 0.2278  loss_box_reg_stage2: 0.9304  loss_mask: 0.2677  loss_rpn_cls: 0.05498  loss_rpn_loc: 0.2004  time: 2.2670  data_time: 0.1444  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:43:41 d2.utils.events]: \u001b[0m eta: 4:05:18  iter: 3499  total_loss: 3.508  loss_cls_stage0: 0.2258  loss_box_reg_stage0: 0.4741  loss_cls_stage1: 0.2448  loss_box_reg_stage1: 0.8522  loss_cls_stage2: 0.2577  loss_box_reg_stage2: 0.9549  loss_mask: 0.2724  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.2118  time: 2.2662  data_time: 0.0831  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:44:27 d2.utils.events]: \u001b[0m eta: 4:04:38  iter: 3519  total_loss: 3.486  loss_cls_stage0: 0.2249  loss_box_reg_stage0: 0.4639  loss_cls_stage1: 0.2496  loss_box_reg_stage1: 0.8536  loss_cls_stage2: 0.2583  loss_box_reg_stage2: 0.937  loss_mask: 0.2712  loss_rpn_cls: 0.05658  loss_rpn_loc: 0.1672  time: 2.2664  data_time: 0.0923  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:45:11 d2.utils.events]: \u001b[0m eta: 4:03:44  iter: 3539  total_loss: 3.535  loss_cls_stage0: 0.2215  loss_box_reg_stage0: 0.4948  loss_cls_stage1: 0.2362  loss_box_reg_stage1: 0.8718  loss_cls_stage2: 0.2509  loss_box_reg_stage2: 0.9439  loss_mask: 0.2684  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.2021  time: 2.2663  data_time: 0.0789  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:45:58 d2.utils.events]: \u001b[0m eta: 4:02:58  iter: 3559  total_loss: 3.44  loss_cls_stage0: 0.1869  loss_box_reg_stage0: 0.4454  loss_cls_stage1: 0.1993  loss_box_reg_stage1: 0.8587  loss_cls_stage2: 0.2238  loss_box_reg_stage2: 0.9187  loss_mask: 0.2587  loss_rpn_cls: 0.04474  loss_rpn_loc: 0.1716  time: 2.2666  data_time: 0.0941  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:46:44 d2.utils.events]: \u001b[0m eta: 4:02:17  iter: 3579  total_loss: 3.375  loss_cls_stage0: 0.1865  loss_box_reg_stage0: 0.4801  loss_cls_stage1: 0.2038  loss_box_reg_stage1: 0.8579  loss_cls_stage2: 0.2351  loss_box_reg_stage2: 0.9476  loss_mask: 0.2727  loss_rpn_cls: 0.04395  loss_rpn_loc: 0.1759  time: 2.2668  data_time: 0.1108  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:47:30 d2.utils.events]: \u001b[0m eta: 4:01:41  iter: 3599  total_loss: 3.448  loss_cls_stage0: 0.2053  loss_box_reg_stage0: 0.4508  loss_cls_stage1: 0.2266  loss_box_reg_stage1: 0.8743  loss_cls_stage2: 0.2429  loss_box_reg_stage2: 0.9574  loss_mask: 0.2714  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.1892  time: 2.2669  data_time: 0.0686  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:48:14 d2.utils.events]: \u001b[0m eta: 4:00:43  iter: 3619  total_loss: 3.385  loss_cls_stage0: 0.1882  loss_box_reg_stage0: 0.4667  loss_cls_stage1: 0.2004  loss_box_reg_stage1: 0.8374  loss_cls_stage2: 0.2402  loss_box_reg_stage2: 0.9306  loss_mask: 0.2804  loss_rpn_cls: 0.06012  loss_rpn_loc: 0.1854  time: 2.2667  data_time: 0.0844  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:48:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:48:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:48:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:48:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:48:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:48:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0030 s/iter. Inference: 0.3437 s/iter. Eval: 0.0201 s/iter. Total: 0.3668 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 04:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0027 s/iter. Inference: 0.3452 s/iter. Eval: 0.0470 s/iter. Total: 0.3950 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:48:54 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0026 s/iter. Inference: 0.3529 s/iter. Eval: 0.0461 s/iter. Total: 0.4017 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 04:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0031 s/iter. Inference: 0.3599 s/iter. Eval: 0.0496 s/iter. Total: 0.4127 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 04:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0029 s/iter. Inference: 0.3671 s/iter. Eval: 0.0481 s/iter. Total: 0.4183 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 04:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0029 s/iter. Inference: 0.3657 s/iter. Eval: 0.0492 s/iter. Total: 0.4180 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 04:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0029 s/iter. Inference: 0.3669 s/iter. Eval: 0.0564 s/iter. Total: 0.4263 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 04:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0029 s/iter. Inference: 0.3716 s/iter. Eval: 0.0576 s/iter. Total: 0.4322 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 04:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0028 s/iter. Inference: 0.3730 s/iter. Eval: 0.0574 s/iter. Total: 0.4334 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 04:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0028 s/iter. Inference: 0.3732 s/iter. Eval: 0.0546 s/iter. Total: 0.4308 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/29 04:49:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.132995 (0.432181 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:49:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.373210 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:49:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:49:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3011144357201618\n",
      "\u001b[32m[12/29 04:49:31 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30111, not better than best score 0.30479 @ iteration 3145.\n",
      "\u001b[32m[12/29 04:49:55 d2.utils.events]: \u001b[0m eta: 4:00:06  iter: 3639  total_loss: 3.331  loss_cls_stage0: 0.182  loss_box_reg_stage0: 0.4597  loss_cls_stage1: 0.179  loss_box_reg_stage1: 0.88  loss_cls_stage2: 0.2166  loss_box_reg_stage2: 0.9166  loss_mask: 0.2794  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.1567  time: 2.2669  data_time: 0.1074  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:50:41 d2.utils.events]: \u001b[0m eta: 3:59:05  iter: 3659  total_loss: 3.349  loss_cls_stage0: 0.1897  loss_box_reg_stage0: 0.4685  loss_cls_stage1: 0.2085  loss_box_reg_stage1: 0.8554  loss_cls_stage2: 0.2284  loss_box_reg_stage2: 0.8786  loss_mask: 0.2687  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1766  time: 2.2670  data_time: 0.0882  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:51:25 d2.utils.events]: \u001b[0m eta: 3:57:53  iter: 3679  total_loss: 3.462  loss_cls_stage0: 0.2053  loss_box_reg_stage0: 0.4807  loss_cls_stage1: 0.2141  loss_box_reg_stage1: 0.8441  loss_cls_stage2: 0.2373  loss_box_reg_stage2: 0.9163  loss_mask: 0.2731  loss_rpn_cls: 0.06737  loss_rpn_loc: 0.2049  time: 2.2666  data_time: 0.0710  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:52:11 d2.utils.events]: \u001b[0m eta: 3:57:36  iter: 3699  total_loss: 3.366  loss_cls_stage0: 0.1885  loss_box_reg_stage0: 0.4317  loss_cls_stage1: 0.2008  loss_box_reg_stage1: 0.8099  loss_cls_stage2: 0.2215  loss_box_reg_stage2: 0.9272  loss_mask: 0.2611  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.1715  time: 2.2667  data_time: 0.1030  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:52:55 d2.utils.events]: \u001b[0m eta: 3:56:07  iter: 3719  total_loss: 3.204  loss_cls_stage0: 0.1623  loss_box_reg_stage0: 0.4255  loss_cls_stage1: 0.1758  loss_box_reg_stage1: 0.8513  loss_cls_stage2: 0.2007  loss_box_reg_stage2: 1.05  loss_mask: 0.2568  loss_rpn_cls: 0.03116  loss_rpn_loc: 0.1516  time: 2.2665  data_time: 0.0954  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:53:42 d2.utils.events]: \u001b[0m eta: 3:55:22  iter: 3739  total_loss: 3.449  loss_cls_stage0: 0.1955  loss_box_reg_stage0: 0.4816  loss_cls_stage1: 0.221  loss_box_reg_stage1: 0.8931  loss_cls_stage2: 0.2606  loss_box_reg_stage2: 0.9093  loss_mask: 0.2863  loss_rpn_cls: 0.05563  loss_rpn_loc: 0.1863  time: 2.2668  data_time: 0.1067  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:54:27 d2.utils.events]: \u001b[0m eta: 3:54:37  iter: 3759  total_loss: 3.565  loss_cls_stage0: 0.2147  loss_box_reg_stage0: 0.4818  loss_cls_stage1: 0.2291  loss_box_reg_stage1: 0.8622  loss_cls_stage2: 0.2311  loss_box_reg_stage2: 0.9442  loss_mask: 0.282  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.2075  time: 2.2667  data_time: 0.0876  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:55:12 d2.utils.events]: \u001b[0m eta: 3:53:52  iter: 3779  total_loss: 3.465  loss_cls_stage0: 0.202  loss_box_reg_stage0: 0.4845  loss_cls_stage1: 0.2267  loss_box_reg_stage1: 0.8366  loss_cls_stage2: 0.2446  loss_box_reg_stage2: 0.8697  loss_mask: 0.2891  loss_rpn_cls: 0.07434  loss_rpn_loc: 0.2043  time: 2.2667  data_time: 0.1132  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:55:58 d2.utils.events]: \u001b[0m eta: 3:53:25  iter: 3799  total_loss: 3.37  loss_cls_stage0: 0.1969  loss_box_reg_stage0: 0.4545  loss_cls_stage1: 0.2175  loss_box_reg_stage1: 0.8439  loss_cls_stage2: 0.2462  loss_box_reg_stage2: 0.8633  loss_mask: 0.2698  loss_rpn_cls: 0.09124  loss_rpn_loc: 0.1735  time: 2.2668  data_time: 0.1389  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:56:43 d2.utils.events]: \u001b[0m eta: 3:52:32  iter: 3819  total_loss: 3.615  loss_cls_stage0: 0.2082  loss_box_reg_stage0: 0.481  loss_cls_stage1: 0.2194  loss_box_reg_stage1: 0.9104  loss_cls_stage2: 0.2341  loss_box_reg_stage2: 0.8865  loss_mask: 0.2661  loss_rpn_cls: 0.05762  loss_rpn_loc: 0.1821  time: 2.2669  data_time: 0.0710  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:57:27 d2.utils.events]: \u001b[0m eta: 3:51:40  iter: 3839  total_loss: 3.39  loss_cls_stage0: 0.2204  loss_box_reg_stage0: 0.4552  loss_cls_stage1: 0.2203  loss_box_reg_stage1: 0.801  loss_cls_stage2: 0.2381  loss_box_reg_stage2: 0.9407  loss_mask: 0.2687  loss_rpn_cls: 0.04299  loss_rpn_loc: 0.1667  time: 2.2664  data_time: 0.0574  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:58:10 d2.utils.events]: \u001b[0m eta: 3:50:55  iter: 3859  total_loss: 3.401  loss_cls_stage0: 0.21  loss_box_reg_stage0: 0.4579  loss_cls_stage1: 0.2128  loss_box_reg_stage1: 0.8418  loss_cls_stage2: 0.2344  loss_box_reg_stage2: 0.976  loss_mask: 0.2583  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.1791  time: 2.2659  data_time: 0.0663  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 04:58:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:58:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:58:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:58:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:58:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:58:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.3258 s/iter. Eval: 0.0179 s/iter. Total: 0.3453 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0022 s/iter. Inference: 0.3355 s/iter. Eval: 0.0466 s/iter. Total: 0.3844 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0024 s/iter. Inference: 0.3383 s/iter. Eval: 0.0468 s/iter. Total: 0.3876 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 04:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0024 s/iter. Inference: 0.3377 s/iter. Eval: 0.0489 s/iter. Total: 0.3891 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 04:59:05 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0024 s/iter. Inference: 0.3374 s/iter. Eval: 0.0489 s/iter. Total: 0.3888 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 04:59:10 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0024 s/iter. Inference: 0.3382 s/iter. Eval: 0.0504 s/iter. Total: 0.3911 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 04:59:16 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0023 s/iter. Inference: 0.3365 s/iter. Eval: 0.0540 s/iter. Total: 0.3930 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 04:59:21 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0023 s/iter. Inference: 0.3350 s/iter. Eval: 0.0562 s/iter. Total: 0.3937 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 04:59:26 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0023 s/iter. Inference: 0.3337 s/iter. Eval: 0.0539 s/iter. Total: 0.3900 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 04:59:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.353129 (0.390975 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:59:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.333394 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:59:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:59:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.30489550600504656\n",
      "\u001b[32m[12/29 04:59:31 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.30490, better than last best score 0.30479 @ iteration 3145.\n",
      "\u001b[32m[12/29 04:59:49 d2.utils.events]: \u001b[0m eta: 3:50:09  iter: 3879  total_loss: 3.432  loss_cls_stage0: 0.1768  loss_box_reg_stage0: 0.472  loss_cls_stage1: 0.2038  loss_box_reg_stage1: 0.8804  loss_cls_stage2: 0.2288  loss_box_reg_stage2: 0.9455  loss_mask: 0.2813  loss_rpn_cls: 0.04738  loss_rpn_loc: 0.1819  time: 2.2660  data_time: 0.0820  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:00:34 d2.utils.events]: \u001b[0m eta: 3:49:13  iter: 3899  total_loss: 3.418  loss_cls_stage0: 0.1817  loss_box_reg_stage0: 0.4439  loss_cls_stage1: 0.2021  loss_box_reg_stage1: 0.826  loss_cls_stage2: 0.2349  loss_box_reg_stage2: 0.9503  loss_mask: 0.2694  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.1571  time: 2.2660  data_time: 0.1088  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:01:20 d2.utils.events]: \u001b[0m eta: 3:48:39  iter: 3919  total_loss: 3.445  loss_cls_stage0: 0.2222  loss_box_reg_stage0: 0.4754  loss_cls_stage1: 0.2421  loss_box_reg_stage1: 0.8637  loss_cls_stage2: 0.246  loss_box_reg_stage2: 0.9526  loss_mask: 0.2718  loss_rpn_cls: 0.05808  loss_rpn_loc: 0.1878  time: 2.2661  data_time: 0.1073  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:02:05 d2.utils.events]: \u001b[0m eta: 3:48:13  iter: 3939  total_loss: 3.227  loss_cls_stage0: 0.1755  loss_box_reg_stage0: 0.4198  loss_cls_stage1: 0.1893  loss_box_reg_stage1: 0.8274  loss_cls_stage2: 0.2144  loss_box_reg_stage2: 0.924  loss_mask: 0.2664  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.1578  time: 2.2661  data_time: 0.0813  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:02:49 d2.utils.events]: \u001b[0m eta: 3:47:09  iter: 3959  total_loss: 3.561  loss_cls_stage0: 0.2169  loss_box_reg_stage0: 0.4677  loss_cls_stage1: 0.2323  loss_box_reg_stage1: 0.8648  loss_cls_stage2: 0.2344  loss_box_reg_stage2: 0.9188  loss_mask: 0.2697  loss_rpn_cls: 0.06712  loss_rpn_loc: 0.1828  time: 2.2658  data_time: 0.0791  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:03:37 d2.utils.events]: \u001b[0m eta: 3:46:54  iter: 3979  total_loss: 3.345  loss_cls_stage0: 0.206  loss_box_reg_stage0: 0.4688  loss_cls_stage1: 0.2293  loss_box_reg_stage1: 0.8201  loss_cls_stage2: 0.2547  loss_box_reg_stage2: 0.8733  loss_mask: 0.2817  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.2236  time: 2.2663  data_time: 0.1680  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:04:19 d2.utils.events]: \u001b[0m eta: 3:45:46  iter: 3999  total_loss: 3.322  loss_cls_stage0: 0.1917  loss_box_reg_stage0: 0.4479  loss_cls_stage1: 0.2055  loss_box_reg_stage1: 0.8211  loss_cls_stage2: 0.2218  loss_box_reg_stage2: 0.9271  loss_mask: 0.2563  loss_rpn_cls: 0.05614  loss_rpn_loc: 0.1615  time: 2.2656  data_time: 0.0805  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:05:04 d2.utils.events]: \u001b[0m eta: 3:45:00  iter: 4019  total_loss: 3.549  loss_cls_stage0: 0.2093  loss_box_reg_stage0: 0.4813  loss_cls_stage1: 0.2299  loss_box_reg_stage1: 0.8555  loss_cls_stage2: 0.2492  loss_box_reg_stage2: 0.8524  loss_mask: 0.2791  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.1805  time: 2.2654  data_time: 0.0841  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:05:49 d2.utils.events]: \u001b[0m eta: 3:44:27  iter: 4039  total_loss: 3.312  loss_cls_stage0: 0.1821  loss_box_reg_stage0: 0.4378  loss_cls_stage1: 0.1863  loss_box_reg_stage1: 0.837  loss_cls_stage2: 0.2272  loss_box_reg_stage2: 0.9952  loss_mask: 0.2499  loss_rpn_cls: 0.03984  loss_rpn_loc: 0.1763  time: 2.2654  data_time: 0.1268  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:06:33 d2.utils.events]: \u001b[0m eta: 3:43:59  iter: 4059  total_loss: 3.461  loss_cls_stage0: 0.2078  loss_box_reg_stage0: 0.4706  loss_cls_stage1: 0.2248  loss_box_reg_stage1: 0.8919  loss_cls_stage2: 0.249  loss_box_reg_stage2: 0.8858  loss_mask: 0.2697  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.1991  time: 2.2652  data_time: 0.0808  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:07:19 d2.utils.events]: \u001b[0m eta: 3:43:33  iter: 4079  total_loss: 3.519  loss_cls_stage0: 0.2175  loss_box_reg_stage0: 0.458  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.853  loss_cls_stage2: 0.2419  loss_box_reg_stage2: 0.9242  loss_mask: 0.2846  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.1854  time: 2.2653  data_time: 0.1162  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:08:04 d2.utils.events]: \u001b[0m eta: 3:42:48  iter: 4099  total_loss: 3.281  loss_cls_stage0: 0.2029  loss_box_reg_stage0: 0.4268  loss_cls_stage1: 0.2089  loss_box_reg_stage1: 0.8033  loss_cls_stage2: 0.239  loss_box_reg_stage2: 0.9179  loss_mask: 0.266  loss_rpn_cls: 0.05351  loss_rpn_loc: 0.1643  time: 2.2651  data_time: 0.0862  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:08:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:08:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:08:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:08:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:08:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:08:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0023 s/iter. Inference: 0.3491 s/iter. Eval: 0.0209 s/iter. Total: 0.3723 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 05:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0024 s/iter. Inference: 0.3529 s/iter. Eval: 0.0490 s/iter. Total: 0.4045 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0025 s/iter. Inference: 0.3463 s/iter. Eval: 0.0528 s/iter. Total: 0.4018 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 05:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0026 s/iter. Inference: 0.3433 s/iter. Eval: 0.0545 s/iter. Total: 0.4005 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 05:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0031 s/iter. Inference: 0.3436 s/iter. Eval: 0.0529 s/iter. Total: 0.3998 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 05:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0030 s/iter. Inference: 0.3435 s/iter. Eval: 0.0549 s/iter. Total: 0.4015 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 05:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0029 s/iter. Inference: 0.3431 s/iter. Eval: 0.0589 s/iter. Total: 0.4051 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 05:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0028 s/iter. Inference: 0.3438 s/iter. Eval: 0.0630 s/iter. Total: 0.4098 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 05:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0028 s/iter. Inference: 0.3423 s/iter. Eval: 0.0602 s/iter. Total: 0.4055 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 05:09:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.879951 (0.404138 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:09:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.340954 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:09:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3032225359285407\n",
      "\u001b[32m[12/29 05:09:26 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30322, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:09:39 d2.utils.events]: \u001b[0m eta: 3:42:09  iter: 4119  total_loss: 3.522  loss_cls_stage0: 0.1814  loss_box_reg_stage0: 0.4756  loss_cls_stage1: 0.1895  loss_box_reg_stage1: 0.9167  loss_cls_stage2: 0.2317  loss_box_reg_stage2: 0.96  loss_mask: 0.2908  loss_rpn_cls: 0.05814  loss_rpn_loc: 0.174  time: 2.2648  data_time: 0.0819  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:10:21 d2.utils.events]: \u001b[0m eta: 3:40:58  iter: 4139  total_loss: 3.39  loss_cls_stage0: 0.1945  loss_box_reg_stage0: 0.4607  loss_cls_stage1: 0.2056  loss_box_reg_stage1: 0.838  loss_cls_stage2: 0.2148  loss_box_reg_stage2: 0.931  loss_mask: 0.2675  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.1956  time: 2.2639  data_time: 0.0659  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:11:08 d2.utils.events]: \u001b[0m eta: 3:40:24  iter: 4159  total_loss: 3.442  loss_cls_stage0: 0.2079  loss_box_reg_stage0: 0.446  loss_cls_stage1: 0.234  loss_box_reg_stage1: 0.8229  loss_cls_stage2: 0.2495  loss_box_reg_stage2: 0.9332  loss_mask: 0.2858  loss_rpn_cls: 0.07826  loss_rpn_loc: 0.1882  time: 2.2644  data_time: 0.2365  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:11:50 d2.utils.events]: \u001b[0m eta: 3:39:16  iter: 4179  total_loss: 3.438  loss_cls_stage0: 0.1882  loss_box_reg_stage0: 0.4514  loss_cls_stage1: 0.1874  loss_box_reg_stage1: 0.8877  loss_cls_stage2: 0.2175  loss_box_reg_stage2: 0.9604  loss_mask: 0.2669  loss_rpn_cls: 0.04625  loss_rpn_loc: 0.1538  time: 2.2637  data_time: 0.0717  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:12:37 d2.utils.events]: \u001b[0m eta: 3:38:39  iter: 4199  total_loss: 3.685  loss_cls_stage0: 0.199  loss_box_reg_stage0: 0.5128  loss_cls_stage1: 0.2436  loss_box_reg_stage1: 0.9443  loss_cls_stage2: 0.2668  loss_box_reg_stage2: 0.9564  loss_mask: 0.2859  loss_rpn_cls: 0.05523  loss_rpn_loc: 0.1938  time: 2.2640  data_time: 0.0710  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:13:23 d2.utils.events]: \u001b[0m eta: 3:38:14  iter: 4219  total_loss: 3.389  loss_cls_stage0: 0.223  loss_box_reg_stage0: 0.4696  loss_cls_stage1: 0.2371  loss_box_reg_stage1: 0.8213  loss_cls_stage2: 0.2503  loss_box_reg_stage2: 0.85  loss_mask: 0.2775  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.1839  time: 2.2642  data_time: 0.1031  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:14:11 d2.utils.events]: \u001b[0m eta: 3:37:34  iter: 4239  total_loss: 3.311  loss_cls_stage0: 0.2015  loss_box_reg_stage0: 0.4273  loss_cls_stage1: 0.2206  loss_box_reg_stage1: 0.7877  loss_cls_stage2: 0.2399  loss_box_reg_stage2: 0.8514  loss_mask: 0.2631  loss_rpn_cls: 0.0865  loss_rpn_loc: 0.2105  time: 2.2648  data_time: 0.1369  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:14:52 d2.utils.events]: \u001b[0m eta: 3:36:15  iter: 4259  total_loss: 3.449  loss_cls_stage0: 0.174  loss_box_reg_stage0: 0.4483  loss_cls_stage1: 0.2072  loss_box_reg_stage1: 0.8471  loss_cls_stage2: 0.2354  loss_box_reg_stage2: 0.9611  loss_mask: 0.2704  loss_rpn_cls: 0.05474  loss_rpn_loc: 0.164  time: 2.2639  data_time: 0.0905  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:15:37 d2.utils.events]: \u001b[0m eta: 3:35:34  iter: 4279  total_loss: 3.425  loss_cls_stage0: 0.218  loss_box_reg_stage0: 0.4686  loss_cls_stage1: 0.2331  loss_box_reg_stage1: 0.8473  loss_cls_stage2: 0.2423  loss_box_reg_stage2: 0.852  loss_mask: 0.2906  loss_rpn_cls: 0.05811  loss_rpn_loc: 0.1862  time: 2.2638  data_time: 0.1179  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:16:22 d2.utils.events]: \u001b[0m eta: 3:34:32  iter: 4299  total_loss: 3.303  loss_cls_stage0: 0.2331  loss_box_reg_stage0: 0.4447  loss_cls_stage1: 0.2425  loss_box_reg_stage1: 0.7879  loss_cls_stage2: 0.2273  loss_box_reg_stage2: 0.837  loss_mask: 0.262  loss_rpn_cls: 0.04738  loss_rpn_loc: 0.2014  time: 2.2636  data_time: 0.0881  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:17:07 d2.utils.events]: \u001b[0m eta: 3:33:41  iter: 4319  total_loss: 3.25  loss_cls_stage0: 0.1898  loss_box_reg_stage0: 0.4304  loss_cls_stage1: 0.1898  loss_box_reg_stage1: 0.8298  loss_cls_stage2: 0.2197  loss_box_reg_stage2: 0.9418  loss_mask: 0.2699  loss_rpn_cls: 0.05144  loss_rpn_loc: 0.1522  time: 2.2637  data_time: 0.1004  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:17:53 d2.utils.events]: \u001b[0m eta: 3:32:56  iter: 4339  total_loss: 3.341  loss_cls_stage0: 0.1695  loss_box_reg_stage0: 0.4426  loss_cls_stage1: 0.1881  loss_box_reg_stage1: 0.8606  loss_cls_stage2: 0.2198  loss_box_reg_stage2: 0.9076  loss_mask: 0.248  loss_rpn_cls: 0.04186  loss_rpn_loc: 0.1684  time: 2.2639  data_time: 0.1045  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:18:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:18:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:18:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:18:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:18:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:18:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0021 s/iter. Inference: 0.3758 s/iter. Eval: 0.0203 s/iter. Total: 0.3981 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/29 05:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0025 s/iter. Inference: 0.3604 s/iter. Eval: 0.0470 s/iter. Total: 0.4101 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:18:46 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0025 s/iter. Inference: 0.3463 s/iter. Eval: 0.0462 s/iter. Total: 0.3952 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 05:18:51 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0026 s/iter. Inference: 0.3428 s/iter. Eval: 0.0479 s/iter. Total: 0.3935 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 05:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0026 s/iter. Inference: 0.3396 s/iter. Eval: 0.0469 s/iter. Total: 0.3893 s/iter. ETA=0:00:21\n",
      "\u001b[32m[12/29 05:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0025 s/iter. Inference: 0.3389 s/iter. Eval: 0.0504 s/iter. Total: 0.3920 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 05:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0025 s/iter. Inference: 0.3371 s/iter. Eval: 0.0527 s/iter. Total: 0.3925 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/29 05:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0025 s/iter. Inference: 0.3372 s/iter. Eval: 0.0535 s/iter. Total: 0.3934 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 05:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0025 s/iter. Inference: 0.3362 s/iter. Eval: 0.0517 s/iter. Total: 0.3905 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 05:19:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.417022 (0.391526 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:19:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.336019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:19:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:19:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.30444921254546264\n",
      "\u001b[32m[12/29 05:19:18 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30445, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:19:28 d2.utils.events]: \u001b[0m eta: 3:32:02  iter: 4359  total_loss: 3.403  loss_cls_stage0: 0.2174  loss_box_reg_stage0: 0.4586  loss_cls_stage1: 0.234  loss_box_reg_stage1: 0.8886  loss_cls_stage2: 0.2576  loss_box_reg_stage2: 0.8799  loss_mask: 0.2765  loss_rpn_cls: 0.08079  loss_rpn_loc: 0.1915  time: 2.2638  data_time: 0.1410  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:20:14 d2.utils.events]: \u001b[0m eta: 3:31:35  iter: 4379  total_loss: 3.375  loss_cls_stage0: 0.1676  loss_box_reg_stage0: 0.4427  loss_cls_stage1: 0.1935  loss_box_reg_stage1: 0.8552  loss_cls_stage2: 0.2147  loss_box_reg_stage2: 0.9107  loss_mask: 0.2663  loss_rpn_cls: 0.05468  loss_rpn_loc: 0.1747  time: 2.2641  data_time: 0.1266  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:21:01 d2.utils.events]: \u001b[0m eta: 3:31:03  iter: 4399  total_loss: 3.197  loss_cls_stage0: 0.1897  loss_box_reg_stage0: 0.4363  loss_cls_stage1: 0.2204  loss_box_reg_stage1: 0.8088  loss_cls_stage2: 0.2295  loss_box_reg_stage2: 0.8332  loss_mask: 0.2763  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.1758  time: 2.2645  data_time: 0.1180  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:21:49 d2.utils.events]: \u001b[0m eta: 3:30:21  iter: 4419  total_loss: 3.327  loss_cls_stage0: 0.1922  loss_box_reg_stage0: 0.4609  loss_cls_stage1: 0.2151  loss_box_reg_stage1: 0.8176  loss_cls_stage2: 0.2405  loss_box_reg_stage2: 0.8785  loss_mask: 0.2705  loss_rpn_cls: 0.05654  loss_rpn_loc: 0.1839  time: 2.2650  data_time: 0.1631  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:22:34 d2.utils.events]: \u001b[0m eta: 3:29:33  iter: 4439  total_loss: 3.35  loss_cls_stage0: 0.204  loss_box_reg_stage0: 0.4621  loss_cls_stage1: 0.2195  loss_box_reg_stage1: 0.8812  loss_cls_stage2: 0.2414  loss_box_reg_stage2: 0.9636  loss_mask: 0.2628  loss_rpn_cls: 0.03858  loss_rpn_loc: 0.178  time: 2.2649  data_time: 0.1178  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:23:19 d2.utils.events]: \u001b[0m eta: 3:28:51  iter: 4459  total_loss: 3.468  loss_cls_stage0: 0.1836  loss_box_reg_stage0: 0.4488  loss_cls_stage1: 0.1948  loss_box_reg_stage1: 0.8608  loss_cls_stage2: 0.2319  loss_box_reg_stage2: 0.9409  loss_mask: 0.2598  loss_rpn_cls: 0.04151  loss_rpn_loc: 0.1532  time: 2.2648  data_time: 0.0825  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:24:05 d2.utils.events]: \u001b[0m eta: 3:28:20  iter: 4479  total_loss: 3.487  loss_cls_stage0: 0.2035  loss_box_reg_stage0: 0.4394  loss_cls_stage1: 0.1959  loss_box_reg_stage1: 0.8686  loss_cls_stage2: 0.2363  loss_box_reg_stage2: 0.9721  loss_mask: 0.2643  loss_rpn_cls: 0.05929  loss_rpn_loc: 0.1941  time: 2.2650  data_time: 0.1108  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:24:51 d2.utils.events]: \u001b[0m eta: 3:27:40  iter: 4499  total_loss: 3.275  loss_cls_stage0: 0.1842  loss_box_reg_stage0: 0.4443  loss_cls_stage1: 0.1967  loss_box_reg_stage1: 0.8293  loss_cls_stage2: 0.2159  loss_box_reg_stage2: 0.8919  loss_mask: 0.2786  loss_rpn_cls: 0.06088  loss_rpn_loc: 0.1706  time: 2.2651  data_time: 0.1215  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:25:36 d2.utils.events]: \u001b[0m eta: 3:26:50  iter: 4519  total_loss: 3.489  loss_cls_stage0: 0.2397  loss_box_reg_stage0: 0.4853  loss_cls_stage1: 0.252  loss_box_reg_stage1: 0.8632  loss_cls_stage2: 0.2616  loss_box_reg_stage2: 0.8686  loss_mask: 0.2871  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.1821  time: 2.2651  data_time: 0.0998  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:26:21 d2.utils.events]: \u001b[0m eta: 3:25:50  iter: 4539  total_loss: 3.587  loss_cls_stage0: 0.1879  loss_box_reg_stage0: 0.4439  loss_cls_stage1: 0.2095  loss_box_reg_stage1: 0.8544  loss_cls_stage2: 0.2456  loss_box_reg_stage2: 0.9668  loss_mask: 0.276  loss_rpn_cls: 0.06528  loss_rpn_loc: 0.2101  time: 2.2650  data_time: 0.0834  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:27:05 d2.utils.events]: \u001b[0m eta: 3:25:10  iter: 4559  total_loss: 3.477  loss_cls_stage0: 0.214  loss_box_reg_stage0: 0.4727  loss_cls_stage1: 0.2109  loss_box_reg_stage1: 0.8878  loss_cls_stage2: 0.2242  loss_box_reg_stage2: 0.9548  loss_mask: 0.2635  loss_rpn_cls: 0.05404  loss_rpn_loc: 0.1875  time: 2.2647  data_time: 0.0715  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:27:50 d2.utils.events]: \u001b[0m eta: 3:24:30  iter: 4579  total_loss: 3.366  loss_cls_stage0: 0.2025  loss_box_reg_stage0: 0.4607  loss_cls_stage1: 0.2125  loss_box_reg_stage1: 0.836  loss_cls_stage2: 0.2272  loss_box_reg_stage2: 0.8885  loss_mask: 0.2758  loss_rpn_cls: 0.05587  loss_rpn_loc: 0.1888  time: 2.2646  data_time: 0.0855  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:28:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:28:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:28:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:28:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:28:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:28:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0017 s/iter. Inference: 0.3270 s/iter. Eval: 0.0214 s/iter. Total: 0.3500 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 05:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0022 s/iter. Inference: 0.3339 s/iter. Eval: 0.0464 s/iter. Total: 0.3831 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 05:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0023 s/iter. Inference: 0.3401 s/iter. Eval: 0.0471 s/iter. Total: 0.3898 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 05:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0022 s/iter. Inference: 0.3391 s/iter. Eval: 0.0495 s/iter. Total: 0.3911 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 05:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0023 s/iter. Inference: 0.3365 s/iter. Eval: 0.0488 s/iter. Total: 0.3879 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 05:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0023 s/iter. Inference: 0.3354 s/iter. Eval: 0.0496 s/iter. Total: 0.3876 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 05:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0023 s/iter. Inference: 0.3352 s/iter. Eval: 0.0526 s/iter. Total: 0.3904 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 05:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0023 s/iter. Inference: 0.3358 s/iter. Eval: 0.0548 s/iter. Total: 0.3932 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 05:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0023 s/iter. Inference: 0.3347 s/iter. Eval: 0.0524 s/iter. Total: 0.3896 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 05:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.222757 (0.389851 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.334088 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:29:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2947613226477745\n",
      "\u001b[32m[12/29 05:29:18 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29476, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:29:22 d2.utils.events]: \u001b[0m eta: 3:23:22  iter: 4599  total_loss: 3.383  loss_cls_stage0: 0.197  loss_box_reg_stage0: 0.4504  loss_cls_stage1: 0.2172  loss_box_reg_stage1: 0.8359  loss_cls_stage2: 0.2306  loss_box_reg_stage2: 0.9276  loss_mask: 0.2563  loss_rpn_cls: 0.04965  loss_rpn_loc: 0.181  time: 2.2642  data_time: 0.0659  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:30:06 d2.utils.events]: \u001b[0m eta: 3:22:37  iter: 4619  total_loss: 3.38  loss_cls_stage0: 0.21  loss_box_reg_stage0: 0.4393  loss_cls_stage1: 0.2043  loss_box_reg_stage1: 0.8388  loss_cls_stage2: 0.2099  loss_box_reg_stage2: 0.9241  loss_mask: 0.2658  loss_rpn_cls: 0.06481  loss_rpn_loc: 0.2044  time: 2.2639  data_time: 0.0826  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:30:53 d2.utils.events]: \u001b[0m eta: 3:21:49  iter: 4639  total_loss: 3.448  loss_cls_stage0: 0.2252  loss_box_reg_stage0: 0.4694  loss_cls_stage1: 0.2418  loss_box_reg_stage1: 0.8488  loss_cls_stage2: 0.2767  loss_box_reg_stage2: 0.8874  loss_mask: 0.2706  loss_rpn_cls: 0.05808  loss_rpn_loc: 0.1711  time: 2.2642  data_time: 0.1058  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:31:39 d2.utils.events]: \u001b[0m eta: 3:21:02  iter: 4659  total_loss: 3.556  loss_cls_stage0: 0.2236  loss_box_reg_stage0: 0.463  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.8259  loss_cls_stage2: 0.2476  loss_box_reg_stage2: 0.902  loss_mask: 0.2766  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.2008  time: 2.2644  data_time: 0.1051  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:32:26 d2.utils.events]: \u001b[0m eta: 3:20:33  iter: 4679  total_loss: 3.391  loss_cls_stage0: 0.1942  loss_box_reg_stage0: 0.4458  loss_cls_stage1: 0.2195  loss_box_reg_stage1: 0.8295  loss_cls_stage2: 0.2489  loss_box_reg_stage2: 0.876  loss_mask: 0.2786  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1781  time: 2.2647  data_time: 0.1163  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:33:10 d2.utils.events]: \u001b[0m eta: 3:19:32  iter: 4699  total_loss: 3.384  loss_cls_stage0: 0.187  loss_box_reg_stage0: 0.4475  loss_cls_stage1: 0.1928  loss_box_reg_stage1: 0.8481  loss_cls_stage2: 0.2253  loss_box_reg_stage2: 0.9692  loss_mask: 0.2707  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.1875  time: 2.2645  data_time: 0.0825  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:33:55 d2.utils.events]: \u001b[0m eta: 3:18:48  iter: 4719  total_loss: 3.404  loss_cls_stage0: 0.1768  loss_box_reg_stage0: 0.4681  loss_cls_stage1: 0.197  loss_box_reg_stage1: 0.8786  loss_cls_stage2: 0.2453  loss_box_reg_stage2: 0.9945  loss_mask: 0.277  loss_rpn_cls: 0.05  loss_rpn_loc: 0.1867  time: 2.2644  data_time: 0.0950  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:34:39 d2.utils.events]: \u001b[0m eta: 3:18:03  iter: 4739  total_loss: 3.42  loss_cls_stage0: 0.1724  loss_box_reg_stage0: 0.4416  loss_cls_stage1: 0.1803  loss_box_reg_stage1: 0.8879  loss_cls_stage2: 0.2204  loss_box_reg_stage2: 0.9697  loss_mask: 0.2511  loss_rpn_cls: 0.05434  loss_rpn_loc: 0.1755  time: 2.2641  data_time: 0.0934  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:35:23 d2.utils.events]: \u001b[0m eta: 3:17:09  iter: 4759  total_loss: 3.242  loss_cls_stage0: 0.1706  loss_box_reg_stage0: 0.4348  loss_cls_stage1: 0.1857  loss_box_reg_stage1: 0.8049  loss_cls_stage2: 0.2189  loss_box_reg_stage2: 0.9369  loss_mask: 0.2607  loss_rpn_cls: 0.04259  loss_rpn_loc: 0.154  time: 2.2638  data_time: 0.0872  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:36:08 d2.utils.events]: \u001b[0m eta: 3:16:20  iter: 4779  total_loss: 3.292  loss_cls_stage0: 0.1846  loss_box_reg_stage0: 0.4387  loss_cls_stage1: 0.2034  loss_box_reg_stage1: 0.7841  loss_cls_stage2: 0.2319  loss_box_reg_stage2: 0.8692  loss_mask: 0.2683  loss_rpn_cls: 0.06073  loss_rpn_loc: 0.177  time: 2.2637  data_time: 0.0889  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:36:53 d2.utils.events]: \u001b[0m eta: 3:15:26  iter: 4799  total_loss: 3.387  loss_cls_stage0: 0.1812  loss_box_reg_stage0: 0.4311  loss_cls_stage1: 0.2022  loss_box_reg_stage1: 0.829  loss_cls_stage2: 0.2249  loss_box_reg_stage2: 0.917  loss_mask: 0.2678  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.1647  time: 2.2638  data_time: 0.1028  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:37:37 d2.utils.events]: \u001b[0m eta: 3:14:34  iter: 4819  total_loss: 3.545  loss_cls_stage0: 0.1992  loss_box_reg_stage0: 0.457  loss_cls_stage1: 0.2151  loss_box_reg_stage1: 0.9055  loss_cls_stage2: 0.2345  loss_box_reg_stage2: 0.9162  loss_mask: 0.2776  loss_rpn_cls: 0.06212  loss_rpn_loc: 0.1906  time: 2.2635  data_time: 0.0703  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:38:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:38:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:38:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:38:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:38:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:38:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0019 s/iter. Inference: 0.3376 s/iter. Eval: 0.0182 s/iter. Total: 0.3577 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0021 s/iter. Inference: 0.3334 s/iter. Eval: 0.0439 s/iter. Total: 0.3795 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/29 05:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0022 s/iter. Inference: 0.3358 s/iter. Eval: 0.0419 s/iter. Total: 0.3800 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 05:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0022 s/iter. Inference: 0.3419 s/iter. Eval: 0.0447 s/iter. Total: 0.3890 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 05:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0023 s/iter. Inference: 0.3452 s/iter. Eval: 0.0459 s/iter. Total: 0.3935 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 05:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0023 s/iter. Inference: 0.3426 s/iter. Eval: 0.0473 s/iter. Total: 0.3923 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 05:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0023 s/iter. Inference: 0.3424 s/iter. Eval: 0.0513 s/iter. Total: 0.3962 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 05:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0026 s/iter. Inference: 0.3429 s/iter. Eval: 0.0536 s/iter. Total: 0.3992 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 05:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0025 s/iter. Inference: 0.3406 s/iter. Eval: 0.0514 s/iter. Total: 0.3946 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 05:39:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.793569 (0.394772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:39:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.339616 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:39:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:39:13 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3005819064434233\n",
      "\u001b[32m[12/29 05:39:13 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30058, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:39:13 d2.utils.events]: \u001b[0m eta: 3:13:56  iter: 4839  total_loss: 3.504  loss_cls_stage0: 0.2097  loss_box_reg_stage0: 0.4568  loss_cls_stage1: 0.2128  loss_box_reg_stage1: 0.8794  loss_cls_stage2: 0.2445  loss_box_reg_stage2: 0.8802  loss_mask: 0.2886  loss_rpn_cls: 0.07796  loss_rpn_loc: 0.195  time: 2.2636  data_time: 0.0950  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:40:00 d2.utils.events]: \u001b[0m eta: 3:13:28  iter: 4859  total_loss: 3.252  loss_cls_stage0: 0.1874  loss_box_reg_stage0: 0.419  loss_cls_stage1: 0.1883  loss_box_reg_stage1: 0.8536  loss_cls_stage2: 0.2117  loss_box_reg_stage2: 0.9387  loss_mask: 0.2659  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1851  time: 2.2641  data_time: 0.1098  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:40:43 d2.utils.events]: \u001b[0m eta: 3:12:34  iter: 4879  total_loss: 3.436  loss_cls_stage0: 0.2115  loss_box_reg_stage0: 0.4647  loss_cls_stage1: 0.2414  loss_box_reg_stage1: 0.8606  loss_cls_stage2: 0.2566  loss_box_reg_stage2: 0.8621  loss_mask: 0.2757  loss_rpn_cls: 0.0479  loss_rpn_loc: 0.1749  time: 2.2636  data_time: 0.0861  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:41:27 d2.utils.events]: \u001b[0m eta: 3:11:53  iter: 4899  total_loss: 3.529  loss_cls_stage0: 0.1703  loss_box_reg_stage0: 0.4449  loss_cls_stage1: 0.1937  loss_box_reg_stage1: 0.8688  loss_cls_stage2: 0.2243  loss_box_reg_stage2: 0.9346  loss_mask: 0.2731  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.1883  time: 2.2632  data_time: 0.1001  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:42:14 d2.utils.events]: \u001b[0m eta: 3:11:13  iter: 4919  total_loss: 3.325  loss_cls_stage0: 0.2047  loss_box_reg_stage0: 0.4573  loss_cls_stage1: 0.2022  loss_box_reg_stage1: 0.8109  loss_cls_stage2: 0.2322  loss_box_reg_stage2: 0.8801  loss_mask: 0.2769  loss_rpn_cls: 0.06203  loss_rpn_loc: 0.1879  time: 2.2636  data_time: 0.0965  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:42:55 d2.utils.events]: \u001b[0m eta: 3:10:13  iter: 4939  total_loss: 3.273  loss_cls_stage0: 0.1669  loss_box_reg_stage0: 0.429  loss_cls_stage1: 0.1949  loss_box_reg_stage1: 0.8137  loss_cls_stage2: 0.2185  loss_box_reg_stage2: 0.9362  loss_mask: 0.2607  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.1672  time: 2.2628  data_time: 0.0542  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:43:38 d2.utils.events]: \u001b[0m eta: 3:09:21  iter: 4959  total_loss: 3.543  loss_cls_stage0: 0.2126  loss_box_reg_stage0: 0.4749  loss_cls_stage1: 0.2229  loss_box_reg_stage1: 0.8415  loss_cls_stage2: 0.2448  loss_box_reg_stage2: 0.8873  loss_mask: 0.2779  loss_rpn_cls: 0.06501  loss_rpn_loc: 0.1997  time: 2.2622  data_time: 0.0950  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:44:23 d2.utils.events]: \u001b[0m eta: 3:08:32  iter: 4979  total_loss: 3.401  loss_cls_stage0: 0.1896  loss_box_reg_stage0: 0.4323  loss_cls_stage1: 0.214  loss_box_reg_stage1: 0.8073  loss_cls_stage2: 0.238  loss_box_reg_stage2: 0.9595  loss_mask: 0.2608  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.1629  time: 2.2622  data_time: 0.1419  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:45:08 d2.utils.events]: \u001b[0m eta: 3:07:48  iter: 4999  total_loss: 3.347  loss_cls_stage0: 0.1831  loss_box_reg_stage0: 0.4523  loss_cls_stage1: 0.1874  loss_box_reg_stage1: 0.8234  loss_cls_stage2: 0.217  loss_box_reg_stage2: 0.8916  loss_mask: 0.27  loss_rpn_cls: 0.04607  loss_rpn_loc: 0.1854  time: 2.2619  data_time: 0.0663  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:45:52 d2.utils.events]: \u001b[0m eta: 3:06:58  iter: 5019  total_loss: 3.399  loss_cls_stage0: 0.177  loss_box_reg_stage0: 0.4432  loss_cls_stage1: 0.2011  loss_box_reg_stage1: 0.8424  loss_cls_stage2: 0.2305  loss_box_reg_stage2: 0.8915  loss_mask: 0.2713  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.1756  time: 2.2616  data_time: 0.0988  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:46:38 d2.utils.events]: \u001b[0m eta: 3:06:13  iter: 5039  total_loss: 3.484  loss_cls_stage0: 0.1851  loss_box_reg_stage0: 0.4567  loss_cls_stage1: 0.2026  loss_box_reg_stage1: 0.8846  loss_cls_stage2: 0.2445  loss_box_reg_stage2: 0.9792  loss_mask: 0.2692  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1983  time: 2.2617  data_time: 0.1066  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:47:23 d2.utils.events]: \u001b[0m eta: 3:05:28  iter: 5059  total_loss: 3.268  loss_cls_stage0: 0.1781  loss_box_reg_stage0: 0.4633  loss_cls_stage1: 0.1979  loss_box_reg_stage1: 0.8064  loss_cls_stage2: 0.232  loss_box_reg_stage2: 0.8892  loss_mask: 0.2836  loss_rpn_cls: 0.07095  loss_rpn_loc: 0.1785  time: 2.2618  data_time: 0.1268  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:48:08 d2.utils.events]: \u001b[0m eta: 3:04:38  iter: 5079  total_loss: 3.362  loss_cls_stage0: 0.1758  loss_box_reg_stage0: 0.4492  loss_cls_stage1: 0.1725  loss_box_reg_stage1: 0.8226  loss_cls_stage2: 0.2143  loss_box_reg_stage2: 0.9353  loss_mask: 0.2663  loss_rpn_cls: 0.04449  loss_rpn_loc: 0.1888  time: 2.2616  data_time: 0.0738  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:48:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:48:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:48:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:48:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:48:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:48:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0019 s/iter. Inference: 0.3432 s/iter. Eval: 0.0199 s/iter. Total: 0.3651 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 05:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0023 s/iter. Inference: 0.3405 s/iter. Eval: 0.0456 s/iter. Total: 0.3885 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 05:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0029 s/iter. Inference: 0.3366 s/iter. Eval: 0.0453 s/iter. Total: 0.3849 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 05:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0028 s/iter. Inference: 0.3368 s/iter. Eval: 0.0486 s/iter. Total: 0.3884 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 05:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0027 s/iter. Inference: 0.3370 s/iter. Eval: 0.0488 s/iter. Total: 0.3889 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 05:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0027 s/iter. Inference: 0.3380 s/iter. Eval: 0.0500 s/iter. Total: 0.3910 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 05:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0026 s/iter. Inference: 0.3371 s/iter. Eval: 0.0530 s/iter. Total: 0.3929 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 05:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0026 s/iter. Inference: 0.3367 s/iter. Eval: 0.0558 s/iter. Total: 0.3953 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 05:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0026 s/iter. Inference: 0.3374 s/iter. Eval: 0.0536 s/iter. Total: 0.3938 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 05:49:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.800444 (0.394831 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:49:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.337160 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:49:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:49:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28961857931050156\n",
      "\u001b[32m[12/29 05:49:02 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.28962, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:49:42 d2.utils.events]: \u001b[0m eta: 3:03:53  iter: 5099  total_loss: 3.473  loss_cls_stage0: 0.194  loss_box_reg_stage0: 0.4297  loss_cls_stage1: 0.1997  loss_box_reg_stage1: 0.8877  loss_cls_stage2: 0.233  loss_box_reg_stage2: 0.9759  loss_mask: 0.252  loss_rpn_cls: 0.04364  loss_rpn_loc: 0.1594  time: 2.2614  data_time: 0.0736  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:50:26 d2.utils.events]: \u001b[0m eta: 3:03:03  iter: 5119  total_loss: 3.363  loss_cls_stage0: 0.1621  loss_box_reg_stage0: 0.4393  loss_cls_stage1: 0.1697  loss_box_reg_stage1: 0.8982  loss_cls_stage2: 0.2209  loss_box_reg_stage2: 0.9326  loss_mask: 0.2663  loss_rpn_cls: 0.03415  loss_rpn_loc: 0.1819  time: 2.2611  data_time: 0.0562  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:51:11 d2.utils.events]: \u001b[0m eta: 3:02:31  iter: 5139  total_loss: 3.482  loss_cls_stage0: 0.1987  loss_box_reg_stage0: 0.4688  loss_cls_stage1: 0.2008  loss_box_reg_stage1: 0.8848  loss_cls_stage2: 0.2376  loss_box_reg_stage2: 0.9615  loss_mask: 0.2778  loss_rpn_cls: 0.05196  loss_rpn_loc: 0.1833  time: 2.2611  data_time: 0.0695  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:51:57 d2.utils.events]: \u001b[0m eta: 3:01:46  iter: 5159  total_loss: 3.404  loss_cls_stage0: 0.1824  loss_box_reg_stage0: 0.4549  loss_cls_stage1: 0.1905  loss_box_reg_stage1: 0.8589  loss_cls_stage2: 0.2228  loss_box_reg_stage2: 0.897  loss_mask: 0.2748  loss_rpn_cls: 0.04686  loss_rpn_loc: 0.1772  time: 2.2613  data_time: 0.1104  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:52:42 d2.utils.events]: \u001b[0m eta: 3:00:57  iter: 5179  total_loss: 3.697  loss_cls_stage0: 0.2253  loss_box_reg_stage0: 0.4598  loss_cls_stage1: 0.2507  loss_box_reg_stage1: 0.9031  loss_cls_stage2: 0.2618  loss_box_reg_stage2: 0.9782  loss_mask: 0.2629  loss_rpn_cls: 0.05279  loss_rpn_loc: 0.1688  time: 2.2612  data_time: 0.0658  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:53:26 d2.utils.events]: \u001b[0m eta: 2:59:52  iter: 5199  total_loss: 3.303  loss_cls_stage0: 0.2061  loss_box_reg_stage0: 0.4663  loss_cls_stage1: 0.2341  loss_box_reg_stage1: 0.8342  loss_cls_stage2: 0.2268  loss_box_reg_stage2: 0.8695  loss_mask: 0.2751  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.1615  time: 2.2610  data_time: 0.1097  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:54:14 d2.utils.events]: \u001b[0m eta: 2:59:14  iter: 5219  total_loss: 3.491  loss_cls_stage0: 0.2079  loss_box_reg_stage0: 0.4517  loss_cls_stage1: 0.2324  loss_box_reg_stage1: 0.8456  loss_cls_stage2: 0.2375  loss_box_reg_stage2: 0.9157  loss_mask: 0.2669  loss_rpn_cls: 0.06785  loss_rpn_loc: 0.1818  time: 2.2615  data_time: 0.1691  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:55:01 d2.utils.events]: \u001b[0m eta: 2:58:38  iter: 5239  total_loss: 3.553  loss_cls_stage0: 0.2257  loss_box_reg_stage0: 0.485  loss_cls_stage1: 0.2409  loss_box_reg_stage1: 0.879  loss_cls_stage2: 0.2607  loss_box_reg_stage2: 0.9617  loss_mask: 0.2747  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1694  time: 2.2619  data_time: 0.1080  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:55:47 d2.utils.events]: \u001b[0m eta: 2:58:02  iter: 5259  total_loss: 3.271  loss_cls_stage0: 0.1706  loss_box_reg_stage0: 0.4392  loss_cls_stage1: 0.1756  loss_box_reg_stage1: 0.8281  loss_cls_stage2: 0.205  loss_box_reg_stage2: 0.9274  loss_mask: 0.2562  loss_rpn_cls: 0.03689  loss_rpn_loc: 0.154  time: 2.2620  data_time: 0.0996  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:56:34 d2.utils.events]: \u001b[0m eta: 2:57:16  iter: 5279  total_loss: 3.313  loss_cls_stage0: 0.1954  loss_box_reg_stage0: 0.4471  loss_cls_stage1: 0.2059  loss_box_reg_stage1: 0.8375  loss_cls_stage2: 0.2239  loss_box_reg_stage2: 0.9478  loss_mask: 0.2828  loss_rpn_cls: 0.06646  loss_rpn_loc: 0.1911  time: 2.2623  data_time: 0.1403  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:57:19 d2.utils.events]: \u001b[0m eta: 2:56:42  iter: 5299  total_loss: 3.311  loss_cls_stage0: 0.1645  loss_box_reg_stage0: 0.4394  loss_cls_stage1: 0.1855  loss_box_reg_stage1: 0.8435  loss_cls_stage2: 0.2116  loss_box_reg_stage2: 0.9213  loss_mask: 0.2617  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.171  time: 2.2622  data_time: 0.0679  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:58:07 d2.utils.events]: \u001b[0m eta: 2:56:03  iter: 5319  total_loss: 3.246  loss_cls_stage0: 0.1729  loss_box_reg_stage0: 0.4358  loss_cls_stage1: 0.1885  loss_box_reg_stage1: 0.8085  loss_cls_stage2: 0.2241  loss_box_reg_stage2: 0.975  loss_mask: 0.2664  loss_rpn_cls: 0.05526  loss_rpn_loc: 0.1786  time: 2.2628  data_time: 0.0965  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 05:58:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:58:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:58:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:58:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:58:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:58:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0018 s/iter. Inference: 0.3303 s/iter. Eval: 0.0218 s/iter. Total: 0.3539 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 05:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0020 s/iter. Inference: 0.3387 s/iter. Eval: 0.0517 s/iter. Total: 0.3926 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 05:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0023 s/iter. Inference: 0.3410 s/iter. Eval: 0.0517 s/iter. Total: 0.3951 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 05:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0024 s/iter. Inference: 0.3526 s/iter. Eval: 0.0538 s/iter. Total: 0.4090 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 05:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0024 s/iter. Inference: 0.3523 s/iter. Eval: 0.0518 s/iter. Total: 0.4068 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/29 05:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0025 s/iter. Inference: 0.3511 s/iter. Eval: 0.0548 s/iter. Total: 0.4086 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 05:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0025 s/iter. Inference: 0.3520 s/iter. Eval: 0.0592 s/iter. Total: 0.4140 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 05:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0025 s/iter. Inference: 0.3498 s/iter. Eval: 0.0621 s/iter. Total: 0.4146 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 05:59:05 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0025 s/iter. Inference: 0.3489 s/iter. Eval: 0.0595 s/iter. Total: 0.4112 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 05:59:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.555302 (0.409960 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:59:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.347350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:59:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.29891951360821034\n",
      "\u001b[32m[12/29 05:59:09 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29892, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:59:46 d2.utils.events]: \u001b[0m eta: 2:55:23  iter: 5339  total_loss: 3.354  loss_cls_stage0: 0.1966  loss_box_reg_stage0: 0.4224  loss_cls_stage1: 0.2268  loss_box_reg_stage1: 0.8635  loss_cls_stage2: 0.2393  loss_box_reg_stage2: 0.8469  loss_mask: 0.2715  loss_rpn_cls: 0.07678  loss_rpn_loc: 0.173  time: 2.2633  data_time: 0.1254  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:00:31 d2.utils.events]: \u001b[0m eta: 2:54:34  iter: 5359  total_loss: 3.393  loss_cls_stage0: 0.1959  loss_box_reg_stage0: 0.4367  loss_cls_stage1: 0.2098  loss_box_reg_stage1: 0.8117  loss_cls_stage2: 0.2328  loss_box_reg_stage2: 0.9218  loss_mask: 0.271  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.2128  time: 2.2631  data_time: 0.0906  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:01:18 d2.utils.events]: \u001b[0m eta: 2:53:49  iter: 5379  total_loss: 3.496  loss_cls_stage0: 0.2065  loss_box_reg_stage0: 0.4723  loss_cls_stage1: 0.215  loss_box_reg_stage1: 0.8957  loss_cls_stage2: 0.2515  loss_box_reg_stage2: 0.9401  loss_mask: 0.2582  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1825  time: 2.2635  data_time: 0.1134  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:02:02 d2.utils.events]: \u001b[0m eta: 2:52:58  iter: 5399  total_loss: 3.302  loss_cls_stage0: 0.1562  loss_box_reg_stage0: 0.4337  loss_cls_stage1: 0.1639  loss_box_reg_stage1: 0.8597  loss_cls_stage2: 0.2111  loss_box_reg_stage2: 0.9076  loss_mask: 0.2612  loss_rpn_cls: 0.05533  loss_rpn_loc: 0.1532  time: 2.2631  data_time: 0.0799  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:02:47 d2.utils.events]: \u001b[0m eta: 2:52:05  iter: 5419  total_loss: 3.2  loss_cls_stage0: 0.1776  loss_box_reg_stage0: 0.4126  loss_cls_stage1: 0.1936  loss_box_reg_stage1: 0.7885  loss_cls_stage2: 0.2164  loss_box_reg_stage2: 0.9422  loss_mask: 0.2603  loss_rpn_cls: 0.05279  loss_rpn_loc: 0.1543  time: 2.2631  data_time: 0.0971  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:03:30 d2.utils.events]: \u001b[0m eta: 2:51:13  iter: 5439  total_loss: 3.377  loss_cls_stage0: 0.193  loss_box_reg_stage0: 0.4548  loss_cls_stage1: 0.2057  loss_box_reg_stage1: 0.8487  loss_cls_stage2: 0.236  loss_box_reg_stage2: 0.9907  loss_mask: 0.2766  loss_rpn_cls: 0.04574  loss_rpn_loc: 0.1817  time: 2.2627  data_time: 0.0780  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:04:14 d2.utils.events]: \u001b[0m eta: 2:50:28  iter: 5459  total_loss: 3.219  loss_cls_stage0: 0.1757  loss_box_reg_stage0: 0.4278  loss_cls_stage1: 0.1925  loss_box_reg_stage1: 0.8465  loss_cls_stage2: 0.2152  loss_box_reg_stage2: 0.8544  loss_mask: 0.2568  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.1758  time: 2.2624  data_time: 0.0796  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:04:58 d2.utils.events]: \u001b[0m eta: 2:49:22  iter: 5479  total_loss: 3.454  loss_cls_stage0: 0.2237  loss_box_reg_stage0: 0.4575  loss_cls_stage1: 0.2388  loss_box_reg_stage1: 0.8584  loss_cls_stage2: 0.2525  loss_box_reg_stage2: 0.9543  loss_mask: 0.2659  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.1814  time: 2.2622  data_time: 0.1065  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:05:40 d2.utils.events]: \u001b[0m eta: 2:48:15  iter: 5499  total_loss: 3.487  loss_cls_stage0: 0.1911  loss_box_reg_stage0: 0.4482  loss_cls_stage1: 0.1976  loss_box_reg_stage1: 0.8938  loss_cls_stage2: 0.2292  loss_box_reg_stage2: 1.007  loss_mask: 0.2507  loss_rpn_cls: 0.04075  loss_rpn_loc: 0.1583  time: 2.2617  data_time: 0.0536  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:06:27 d2.utils.events]: \u001b[0m eta: 2:47:30  iter: 5519  total_loss: 3.611  loss_cls_stage0: 0.2259  loss_box_reg_stage0: 0.469  loss_cls_stage1: 0.2512  loss_box_reg_stage1: 0.8696  loss_cls_stage2: 0.2597  loss_box_reg_stage2: 0.8818  loss_mask: 0.2798  loss_rpn_cls: 0.07764  loss_rpn_loc: 0.1783  time: 2.2620  data_time: 0.0992  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:07:11 d2.utils.events]: \u001b[0m eta: 2:46:45  iter: 5539  total_loss: 3.326  loss_cls_stage0: 0.1933  loss_box_reg_stage0: 0.4419  loss_cls_stage1: 0.2079  loss_box_reg_stage1: 0.828  loss_cls_stage2: 0.2402  loss_box_reg_stage2: 0.9258  loss_mask: 0.2628  loss_rpn_cls: 0.06415  loss_rpn_loc: 0.2077  time: 2.2617  data_time: 0.0825  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:07:54 d2.utils.events]: \u001b[0m eta: 2:45:24  iter: 5559  total_loss: 3.541  loss_cls_stage0: 0.2051  loss_box_reg_stage0: 0.4569  loss_cls_stage1: 0.2241  loss_box_reg_stage1: 0.8527  loss_cls_stage2: 0.241  loss_box_reg_stage2: 0.9437  loss_mask: 0.2661  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.2114  time: 2.2614  data_time: 0.0785  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:08:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:08:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 06:08:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 06:08:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 06:08:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:08:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 06:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0023 s/iter. Inference: 0.3316 s/iter. Eval: 0.0210 s/iter. Total: 0.3549 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 06:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0024 s/iter. Inference: 0.3420 s/iter. Eval: 0.0474 s/iter. Total: 0.3920 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 06:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0027 s/iter. Inference: 0.3427 s/iter. Eval: 0.0488 s/iter. Total: 0.3943 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 06:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0027 s/iter. Inference: 0.3514 s/iter. Eval: 0.0512 s/iter. Total: 0.4055 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 06:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0027 s/iter. Inference: 0.3474 s/iter. Eval: 0.0516 s/iter. Total: 0.4019 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 06:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0026 s/iter. Inference: 0.3505 s/iter. Eval: 0.0521 s/iter. Total: 0.4055 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 06:08:47 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0027 s/iter. Inference: 0.3523 s/iter. Eval: 0.0573 s/iter. Total: 0.4124 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 06:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0027 s/iter. Inference: 0.3508 s/iter. Eval: 0.0602 s/iter. Total: 0.4140 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 06:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0027 s/iter. Inference: 0.3562 s/iter. Eval: 0.0583 s/iter. Total: 0.4174 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 06:09:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.220607 (0.415695 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:09:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.355075 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:09:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 06:09:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2985558952949137\n",
      "\u001b[32m[12/29 06:09:02 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29856, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 06:09:36 d2.utils.events]: \u001b[0m eta: 2:44:39  iter: 5579  total_loss: 3.318  loss_cls_stage0: 0.1884  loss_box_reg_stage0: 0.4397  loss_cls_stage1: 0.1987  loss_box_reg_stage1: 0.8218  loss_cls_stage2: 0.228  loss_box_reg_stage2: 0.9173  loss_mask: 0.2744  loss_rpn_cls: 0.05386  loss_rpn_loc: 0.1958  time: 2.2620  data_time: 0.1429  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:10:20 d2.utils.events]: \u001b[0m eta: 2:44:30  iter: 5599  total_loss: 3.506  loss_cls_stage0: 0.2012  loss_box_reg_stage0: 0.471  loss_cls_stage1: 0.2118  loss_box_reg_stage1: 0.8322  loss_cls_stage2: 0.2434  loss_box_reg_stage2: 0.8696  loss_mask: 0.2815  loss_rpn_cls: 0.07796  loss_rpn_loc: 0.1786  time: 2.2617  data_time: 0.0778  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:11:07 d2.utils.events]: \u001b[0m eta: 2:43:57  iter: 5619  total_loss: 3.507  loss_cls_stage0: 0.2027  loss_box_reg_stage0: 0.4483  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.8567  loss_cls_stage2: 0.2575  loss_box_reg_stage2: 0.9306  loss_mask: 0.2828  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.1893  time: 2.2621  data_time: 0.1311  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:11:52 d2.utils.events]: \u001b[0m eta: 2:43:01  iter: 5639  total_loss: 3.171  loss_cls_stage0: 0.1902  loss_box_reg_stage0: 0.414  loss_cls_stage1: 0.2059  loss_box_reg_stage1: 0.7715  loss_cls_stage2: 0.2227  loss_box_reg_stage2: 0.8939  loss_mask: 0.2622  loss_rpn_cls: 0.0476  loss_rpn_loc: 0.1585  time: 2.2620  data_time: 0.1106  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:12:37 d2.utils.events]: \u001b[0m eta: 2:42:06  iter: 5659  total_loss: 3.327  loss_cls_stage0: 0.2048  loss_box_reg_stage0: 0.4268  loss_cls_stage1: 0.2233  loss_box_reg_stage1: 0.8061  loss_cls_stage2: 0.2349  loss_box_reg_stage2: 0.8912  loss_mask: 0.258  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.1579  time: 2.2620  data_time: 0.1297  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:13:25 d2.utils.events]: \u001b[0m eta: 2:41:21  iter: 5679  total_loss: 3.382  loss_cls_stage0: 0.1924  loss_box_reg_stage0: 0.456  loss_cls_stage1: 0.1906  loss_box_reg_stage1: 0.86  loss_cls_stage2: 0.2196  loss_box_reg_stage2: 0.9663  loss_mask: 0.2683  loss_rpn_cls: 0.06279  loss_rpn_loc: 0.1847  time: 2.2625  data_time: 0.1181  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:14:12 d2.utils.events]: \u001b[0m eta: 2:40:58  iter: 5699  total_loss: 3.371  loss_cls_stage0: 0.1823  loss_box_reg_stage0: 0.4596  loss_cls_stage1: 0.1982  loss_box_reg_stage1: 0.8877  loss_cls_stage2: 0.2293  loss_box_reg_stage2: 0.9303  loss_mask: 0.2771  loss_rpn_cls: 0.03682  loss_rpn_loc: 0.1834  time: 2.2627  data_time: 0.1224  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:14:57 d2.utils.events]: \u001b[0m eta: 2:40:19  iter: 5719  total_loss: 3.435  loss_cls_stage0: 0.2048  loss_box_reg_stage0: 0.4372  loss_cls_stage1: 0.2106  loss_box_reg_stage1: 0.8456  loss_cls_stage2: 0.2311  loss_box_reg_stage2: 0.956  loss_mask: 0.2665  loss_rpn_cls: 0.05037  loss_rpn_loc: 0.2041  time: 2.2628  data_time: 0.0860  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:15:43 d2.utils.events]: \u001b[0m eta: 2:39:38  iter: 5739  total_loss: 3.445  loss_cls_stage0: 0.2083  loss_box_reg_stage0: 0.4686  loss_cls_stage1: 0.2203  loss_box_reg_stage1: 0.8332  loss_cls_stage2: 0.2441  loss_box_reg_stage2: 0.879  loss_mask: 0.264  loss_rpn_cls: 0.05085  loss_rpn_loc: 0.1909  time: 2.2628  data_time: 0.0955  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:16:28 d2.utils.events]: \u001b[0m eta: 2:39:07  iter: 5759  total_loss: 3.365  loss_cls_stage0: 0.1877  loss_box_reg_stage0: 0.447  loss_cls_stage1: 0.2106  loss_box_reg_stage1: 0.8551  loss_cls_stage2: 0.2344  loss_box_reg_stage2: 0.9872  loss_mask: 0.2718  loss_rpn_cls: 0.04392  loss_rpn_loc: 0.1819  time: 2.2627  data_time: 0.0679  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:17:12 d2.utils.events]: \u001b[0m eta: 2:38:22  iter: 5779  total_loss: 3.447  loss_cls_stage0: 0.1677  loss_box_reg_stage0: 0.4404  loss_cls_stage1: 0.1834  loss_box_reg_stage1: 0.8723  loss_cls_stage2: 0.2219  loss_box_reg_stage2: 0.9658  loss_mask: 0.2638  loss_rpn_cls: 0.04376  loss_rpn_loc: 0.1779  time: 2.2625  data_time: 0.0775  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:17:57 d2.utils.events]: \u001b[0m eta: 2:37:42  iter: 5799  total_loss: 3.542  loss_cls_stage0: 0.1857  loss_box_reg_stage0: 0.4606  loss_cls_stage1: 0.1996  loss_box_reg_stage1: 0.8768  loss_cls_stage2: 0.2298  loss_box_reg_stage2: 1.022  loss_mask: 0.2575  loss_rpn_cls: 0.04313  loss_rpn_loc: 0.187  time: 2.2625  data_time: 0.0569  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:18:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:18:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 06:18:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 06:18:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 06:18:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:18:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 06:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0021 s/iter. Inference: 0.3376 s/iter. Eval: 0.0214 s/iter. Total: 0.3611 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 06:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0022 s/iter. Inference: 0.3494 s/iter. Eval: 0.0480 s/iter. Total: 0.3997 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 06:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0024 s/iter. Inference: 0.3457 s/iter. Eval: 0.0478 s/iter. Total: 0.3961 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 06:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0026 s/iter. Inference: 0.3485 s/iter. Eval: 0.0513 s/iter. Total: 0.4027 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 06:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0027 s/iter. Inference: 0.3611 s/iter. Eval: 0.0496 s/iter. Total: 0.4136 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/29 06:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0026 s/iter. Inference: 0.3621 s/iter. Eval: 0.0509 s/iter. Total: 0.4158 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 06:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0027 s/iter. Inference: 0.3617 s/iter. Eval: 0.0582 s/iter. Total: 0.4227 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 06:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0026 s/iter. Inference: 0.3601 s/iter. Eval: 0.0595 s/iter. Total: 0.4224 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 06:19:04 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0028 s/iter. Inference: 0.3582 s/iter. Eval: 0.0598 s/iter. Total: 0.4210 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 06:19:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.424122 (0.417449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:19:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.355374 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:19:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 06:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.3023043968667104\n",
      "\u001b[32m[12/29 06:19:09 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30230, not better than best score 0.30490 @ iteration 3871.\n",
      "\u001b[32m[12/29 06:19:35 d2.utils.events]: \u001b[0m eta: 2:37:02  iter: 5819  total_loss: 3.383  loss_cls_stage0: 0.192  loss_box_reg_stage0: 0.4536  loss_cls_stage1: 0.2019  loss_box_reg_stage1: 0.8173  loss_cls_stage2: 0.2368  loss_box_reg_stage2: 0.9396  loss_mask: 0.2799  loss_rpn_cls: 0.05509  loss_rpn_loc: 0.2115  time: 2.2625  data_time: 0.0773  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:20:21 d2.utils.events]: \u001b[0m eta: 2:36:23  iter: 5839  total_loss: 3.232  loss_cls_stage0: 0.1831  loss_box_reg_stage0: 0.4093  loss_cls_stage1: 0.1886  loss_box_reg_stage1: 0.7736  loss_cls_stage2: 0.2138  loss_box_reg_stage2: 0.9323  loss_mask: 0.2586  loss_rpn_cls: 0.04489  loss_rpn_loc: 0.1924  time: 2.2626  data_time: 0.0998  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:21:06 d2.utils.events]: \u001b[0m eta: 2:35:22  iter: 5859  total_loss: 3.258  loss_cls_stage0: 0.1995  loss_box_reg_stage0: 0.4392  loss_cls_stage1: 0.21  loss_box_reg_stage1: 0.7995  loss_cls_stage2: 0.2192  loss_box_reg_stage2: 0.851  loss_mask: 0.2657  loss_rpn_cls: 0.06213  loss_rpn_loc: 0.1914  time: 2.2625  data_time: 0.0989  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:21:54 d2.utils.events]: \u001b[0m eta: 2:34:57  iter: 5879  total_loss: 3.367  loss_cls_stage0: 0.1829  loss_box_reg_stage0: 0.4615  loss_cls_stage1: 0.2109  loss_box_reg_stage1: 0.854  loss_cls_stage2: 0.2281  loss_box_reg_stage2: 0.9495  loss_mask: 0.2714  loss_rpn_cls: 0.05355  loss_rpn_loc: 0.1609  time: 2.2630  data_time: 0.0920  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:22:38 d2.utils.events]: \u001b[0m eta: 2:34:12  iter: 5899  total_loss: 3.123  loss_cls_stage0: 0.1706  loss_box_reg_stage0: 0.4387  loss_cls_stage1: 0.1946  loss_box_reg_stage1: 0.7945  loss_cls_stage2: 0.2163  loss_box_reg_stage2: 0.8357  loss_mask: 0.2662  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.1728  time: 2.2628  data_time: 0.0986  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:23:23 d2.utils.events]: \u001b[0m eta: 2:33:24  iter: 5919  total_loss: 3.492  loss_cls_stage0: 0.1833  loss_box_reg_stage0: 0.444  loss_cls_stage1: 0.1952  loss_box_reg_stage1: 0.8642  loss_cls_stage2: 0.2265  loss_box_reg_stage2: 1.004  loss_mask: 0.2593  loss_rpn_cls: 0.04043  loss_rpn_loc: 0.1542  time: 2.2627  data_time: 0.0722  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:24:09 d2.utils.events]: \u001b[0m eta: 2:32:56  iter: 5939  total_loss: 3.376  loss_cls_stage0: 0.1906  loss_box_reg_stage0: 0.4381  loss_cls_stage1: 0.2047  loss_box_reg_stage1: 0.8556  loss_cls_stage2: 0.2265  loss_box_reg_stage2: 0.9753  loss_mask: 0.2838  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.1682  time: 2.2630  data_time: 0.0949  lr: 0.001  max_mem: 30573M\n",
      "\u001b[32m[12/29 06:24:55 d2.utils.events]: \u001b[0m eta: 2:32:18  iter: 5959  total_loss: 3.382  loss_cls_stage0: 0.1653  loss_box_reg_stage0: 0.449  loss_cls_stage1: 0.1788  loss_box_reg_stage1: 0.8762  loss_cls_stage2: 0.2069  loss_box_reg_stage2: 1.011  loss_mask: 0.2542  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.1691  time: 2.2630  data_time: 0.0781  lr: 0.001  max_mem: 30573M\n"
     ]
    }
   ],
   "source": [
    "# 2 的理论score最高\n",
    "for fold in range(1,2):\n",
    "  run()\n",
    "\n",
    "#run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cascade_finetune.ipynb",
   "provenance": [
    {
     "file_id": "1oh61M2NOWV8WgXX74dQV4br7Uja5-0hm",
     "timestamp": 1639284132292
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
