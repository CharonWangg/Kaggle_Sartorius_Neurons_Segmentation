{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_Swin_T.ipynb","provenance":[],"collapsed_sections":[],"background_execution":"on","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","!pip install \"git+https://github.com/albumentations-team/albumentations.git\""],"metadata":{"id":"rp6zNsGT2pNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"id":"6kLXzl-Kengc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"hcGNw_k42Qze","executionInfo":{"status":"ok","timestamp":1639716994877,"user_tz":300,"elapsed":239,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}}},"outputs":[],"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/Kaggle/Sartorius\")\n","sys.path.append(\"/content/drive/MyDrive/Kaggle/Sartorius/model/pretrained/swin_L\")"]},{"cell_type":"code","source":["import detectron2\n","from pathlib import Path\n","import random, cv2, os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pycocotools.mask as mask_util\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor, DefaultTrainer\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer, ColorMode\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.utils.logger import setup_logger\n","from detectron2.evaluation.evaluator import DatasetEvaluator\n","from detectron2.engine import BestCheckpointer\n","from detectron2.checkpoint import DetectionCheckpointer\n","from albumentations import *\n","import torch\n","import os\n","from detectron2.data import detection_utils\n","from utils.aug import MyMapper\n","from utils.add_swint_config import add_swint_config\n","from detectron2.solver.build import *\n","from detectron2.data import build_detection_test_loader, build_detection_train_loader\n","import warnings\n","import swint\n","warnings.filterwarnings(\"ignore\")\n","\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"Z4V1vYfH2Z-c","executionInfo":{"status":"ok","timestamp":1639716996776,"user_tz":300,"elapsed":1748,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class Config:\n","  pixel_mean = [128,128,128]\n","  pixel_std = [13.235,13.235,13.235]\n","  anchor_generators_sizes = [[8], [16], [32], [64],[128]]\n","  anchor_generators_aspect_ratios = [[0.5, 1.0, 2.0]]\n","  model_config = \"/content/drive/MyDrive/Kaggle/Sartorius/model/pretrained/swin_L/detectron2/configs/SwinT/mask_rcnn_swint_T_FPN_3x.yaml\"\n","  model_weights = \"/content/drive/MyDrive/Kaggle/Sartorius/model/pretrained/swin_L/swin_L_384_22k.pth\""],"metadata":{"id":"VRDktYjz2b8p","executionInfo":{"status":"ok","timestamp":1639716996776,"user_tz":300,"elapsed":6,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\n","def precision_at(threshold, iou):\n","    matches = iou > threshold\n","    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n","    false_positives = np.sum(matches, axis=1) == 0  # Extra objects\n","    false_negatives = np.sum(matches, axis=0) == 0  # Missed objects\n","    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n","\n","def score(pred, targ):\n","    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n","    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n","    enc_targs = list(map(lambda x:x['segmentation'], targ))\n","    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n","    prec = []\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tp, fp, fn = precision_at(t, ious)\n","        p = tp / (tp + fp + fn)\n","        prec.append(p)\n","    return np.mean(prec)\n","\n","class MAPIOUEvaluator(DatasetEvaluator):\n","    def __init__(self, dataset_name):\n","        dataset_dicts = DatasetCatalog.get(dataset_name)\n","        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n","            \n","    def reset(self):\n","        self.scores = []\n","\n","    def process(self, inputs, outputs):\n","        for inp, out in zip(inputs, outputs):\n","            if len(out['instances']) == 0:\n","                self.scores.append(0)    \n","            else:\n","                targ = self.annotations_cache[inp['image_id']]\n","                self.scores.append(score(out, targ))\n","\n","    def evaluate(self):\n","        return {\"MaP IoU\": np.mean(self.scores)}\n","\n","class Trainer(DefaultTrainer):\n"," \n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","        return MAPIOUEvaluator(dataset_name)\n","\n","    @classmethod\n","    def build_optimizer(cls, cfg, model):\n","        params = get_default_optimizer_params(\n","            model,\n","            base_lr=cfg.SOLVER.BASE_LR,\n","            weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n","            weight_decay_norm=cfg.SOLVER.WEIGHT_DECAY_NORM,\n","            bias_lr_factor=cfg.SOLVER.BIAS_LR_FACTOR,\n","            weight_decay_bias=cfg.SOLVER.WEIGHT_DECAY_BIAS,\n","        )\n","\n","        def maybe_add_full_model_gradient_clipping(optim):  # optim: the optimizer class\n","            # detectron2 doesn't have full model gradient clipping now\n","            clip_norm_val = cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE\n","            enable = (\n","                cfg.SOLVER.CLIP_GRADIENTS.ENABLED\n","                and cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\"\n","                and clip_norm_val > 0.0\n","            )\n","\n","            class FullModelGradientClippingOptimizer(optim):\n","                def step(self, closure=None):\n","                    all_params = itertools.chain(*[x[\"params\"] for x in self.param_groups])\n","                    torch.nn.utils.clip_grad_norm_(all_params, clip_norm_val)\n","                    super().step(closure=closure)\n","\n","            return FullModelGradientClippingOptimizer if enable else optim\n","\n","        optimizer_type = cfg.SOLVER.OPTIMIZER\n","        if optimizer_type == \"SGD\":\n","            optimizer = maybe_add_gradient_clipping(torch.optim.SGD)(\n","                params, cfg.SOLVER.BASE_LR, momentum=cfg.SOLVER.MOMENTUM,\n","                nesterov=cfg.SOLVER.NESTEROV,\n","                weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n","            )\n","        elif optimizer_type == \"AdamW\":\n","              optimizer = maybe_add_full_model_gradient_clipping(torch.optim.AdamW)(\n","                params, cfg.SOLVER.BASE_LR, betas=(0.9, 0.999),\n","                weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n","            )\n","        else:\n","            raise NotImplementedError(f\"no optimizer type {optimizer_type}\")\n","        return optimizer\n","\n","     # @classmethod\n","    # def build_train_loader(cls, cfg, sampler=None):\n","    #     return build_detection_train_loader(\n","    #         cfg, mapper=MyMapper(cfg), sampler=sampler\n","    #     )\n","\n","    # def build_hooks(self):\n","    #   # copy of cfg\n","    #   cfg = self.cfg.clone()\n","\n","    #   # build the original model hooks\n","    #   hooks = super().build_hooks()\n","\n","    #   # add the best checkpointer hook\n","    #   hooks.insert(-1, BestCheckpointer(cfg.TEST.EVAL_PERIOD, \n","    #                                     DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n","    #                                     \"MaP IoU\",\n","    #                                     \"max\",\n","    #                                     ))\n","      \n","def setup():\n","  cfg = get_cfg()\n","  add_swint_config(cfg)\n","  cfg.merge_from_file(Config.model_config)\n","  #cfg.MODEL.WEIGHTS = Config.model_weights\n","  #cfg.merge_from_list(args.opts)\n","  #cfg.freeze()\n","  #default_setup(cfg, args)\n","  return cfg\n"],"metadata":{"cellView":"code","id":"_6zszqUG2b0n","executionInfo":{"status":"ok","timestamp":1639716996973,"user_tz":300,"elapsed":202,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def run():\n","  dataDir = \"/content/drive/MyDrive/Kaggle/Sartorius/input/sartorius-cell-instance-segmentation\"\n","  DatasetCatalog.clear()\n","  MetadataCatalog.clear()\n","  register_coco_instances(f'sartorius_train',{}, '/content/drive/MyDrive/Kaggle/Sartorius/input/fixed_fold/coco_cell_train_fold{}.json'.format(fold), dataDir)\n","  register_coco_instances(f'sartorius_val',{},'/content/drive/MyDrive/Kaggle/Sartorius/input/fixed_fold/coco_cell_valid_fold{}.json'.format(fold), dataDir)\n","\n","  #cfg = get_cfg()\n","  #cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"))\n","  cfg = setup()\n","  cfg.INPUT.MIN_SIZE_TRAIN = (220, 240, 260)\n","  cfg.SOLVER.BASE_LR = 5e-4\n","  cfg.DATASETS.TRAIN = (f\"sartorius_train\",)\n","  cfg.DATASETS.TEST = (f\"sartorius_val\",)\n","  #cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n","  cfg.SOLVER.MAX_ITER = len(DatasetCatalog.get(f\"sartorius_train\")) // cfg.SOLVER.IMS_PER_BATCH * 20 #尝试20ep 用lr调整\n","  #cfg.SOLVER.STEPS = (cfg.SOLVER.MAX_ITER//3,cfg.SOLVER.MAX_ITER*2//3)\n","  cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get(f\"sartorius_train\")) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n","\n","  #cfg.MODEL.BACKBONE.FREEZE_AT = 2\n","  #cfg.MODEL.RESNETS.DEPTH = 101\n","  # cfg.MODEL.RESNETS.OUT_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n","  # cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n","  # cfg.MODEL.FPN.NORM = \"GN\"\n","  # cfg.MODEL.ROI_HEADS.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\",\"p6\"]\n","  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n","\n","  # cfg.MODEL.RESNETS.DEFORM_ON_PER_STAGE = [False, True, True, True] # on Res3,Res4,Res5\n","  # cfg.MODEL.RESNETS.DEFORM_MODULATED = True\n","  # cfg.MODEL.RESNETS.DEFORM_NUM_GROUPS = 2\n","  # cfg.MODEL.RESNETS.NORM = \"GN\"\n","  # cfg.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n","  # cfg.MODEL.ROI_BOX_HEAD.NUM_CONV = 4\n","  # cfg.MODEL.ROI_BOX_HEAD.NUM_FC = 1\n","  # cfg.MODEL.ROI_BOX_HEAD.NORM = \"GN\"  \n","  # cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 7\n","  # cfg.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG = True  \n","  # cfg.MODEL.ROI_MASK_HEAD.NUM_CONV = 8\n","  # cfg.MODEL.ROI_MASK_HEAD.NORM = \"GN\"\n","  # cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5]\n","  # cfg.MODEL.ROI_BOX_CASCADE_HEAD.IOUS = (0.5, 0.6, 0.7)\n","  \n","\n","  cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Kaggle/Sartorius/model/swinT/fold_{}#\".format(fold)\n","\n","  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","  trainer = Trainer(cfg) \n","  trainer.resume_or_load(resume=False)\n","  trainer.train()"],"metadata":{"id":"eLJhhBAt2gQZ","executionInfo":{"status":"ok","timestamp":1639718367651,"user_tz":300,"elapsed":167,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 2 的理论score最高\n","for fold in range(1,6):\n","  run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NFwqtkpo2hxE","executionInfo":{"status":"error","timestamp":1639718395525,"user_tz":300,"elapsed":27311,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}},"outputId":"63d5e246-7c8a-424e-919e-6dcd8839bb92"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[12/17 05:19:38 d2.data.datasets.coco]: \u001b[0mLoading /content/drive/MyDrive/Kaggle/Sartorius/input/fixed_fold/coco_cell_train_fold1.json takes 10.71 seconds.\n","\u001b[32m[12/17 05:19:38 d2.data.datasets.coco]: \u001b[0mLoaded 484 images in COCO format from /content/drive/MyDrive/Kaggle/Sartorius/input/fixed_fold/coco_cell_train_fold1.json\n","\u001b[32m[12/17 05:19:39 d2.data.datasets.coco]: \u001b[0mLoaded 484 images in COCO format from /content/drive/MyDrive/Kaggle/Sartorius/input/fixed_fold/coco_cell_train_fold1.json\n","\u001b[32m[12/17 05:19:41 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): SwinTransformer(\n","      (patch_embed): PatchEmbed(\n","        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n","        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (pos_drop): Dropout(p=0.0, inplace=False)\n","      (layers): ModuleList(\n","        (0): BasicLayer(\n","          (blocks): ModuleList(\n","            (0): SwinTransformerBlock(\n","              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=128, out_features=384, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=128, out_features=128, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): Identity()\n","              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=128, out_features=512, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=512, out_features=128, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SwinTransformerBlock(\n","              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=128, out_features=384, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=128, out_features=128, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=128, out_features=512, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=512, out_features=128, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","          (downsample): PatchMerging(\n","            (reduction): Linear(in_features=512, out_features=256, bias=False)\n","            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (1): BasicLayer(\n","          (blocks): ModuleList(\n","            (0): SwinTransformerBlock(\n","              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=256, out_features=768, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=256, out_features=256, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SwinTransformerBlock(\n","              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=256, out_features=768, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=256, out_features=256, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","          (downsample): PatchMerging(\n","            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n","            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (2): BasicLayer(\n","          (blocks): ModuleList(\n","            (0): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (2): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (3): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (4): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (5): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (6): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (7): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (8): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (9): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (10): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (11): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (12): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (13): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (14): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (15): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (16): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (17): SwinTransformerBlock(\n","              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=512, out_features=512, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","          (downsample): PatchMerging(\n","            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n","            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (3): BasicLayer(\n","          (blocks): ModuleList(\n","            (0): SwinTransformerBlock(\n","              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SwinTransformerBlock(\n","              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (attn): WindowAttention(\n","                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","                (attn_drop): Dropout(p=0.0, inplace=False)\n","                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","                (proj_drop): Dropout(p=0.0, inplace=False)\n","                (softmax): Softmax(dim=-1)\n","              )\n","              (drop_path): DropPath()\n","              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (mlp): Mlp(\n","                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","                (act): GELU()\n","                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","                (drop): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[12/17 05:19:41 d2.data.datasets.coco]: \u001b[0mLoaded 484 images in COCO format from /content/drive/MyDrive/Kaggle/Sartorius/input/fixed_fold/coco_cell_train_fold1.json\n","\u001b[32m[12/17 05:19:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 484 images left.\n","\u001b[32m[12/17 05:19:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(220, 240, 260), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[12/17 05:19:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[12/17 05:19:41 d2.data.common]: \u001b[0mSerializing 484 elements to byte tensors and concatenating them all ...\n","\u001b[32m[12/17 05:19:41 d2.data.common]: \u001b[0mSerialized dataset takes 6.64 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/17 05:19:41 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"]},{"output_type":"stream","name":"stderr","text":["Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mbackbone.bottom_up.norm0.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.bottom_up.norm1.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.bottom_up.norm2.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.bottom_up.norm3.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_output2.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_output3.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_output4.{bias, weight}\u001b[0m\n","\u001b[34mbackbone.fpn_output5.{bias, weight}\u001b[0m\n","\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n","\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n","\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n","The checkpoint state_dict contains keys that are not used by the model:\n","  \u001b[35mbackbone.bottom_up.norm.{bias, weight}\u001b[0m\n","  \u001b[35mbackbone.bottom_up.head.{bias, weight}\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.0.blocks.1.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.1.blocks.1.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.1.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.3.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.5.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.7.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.9.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.11.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.13.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.15.attn_mask\u001b[0m\n","  \u001b[35mbackbone.bottom_up.layers.2.blocks.17.attn_mask\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[12/17 05:19:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[12/17 05:19:55 d2.engine.train_loop]: \u001b[0mException during training:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\", line 149, in train\n","    self.run_step()\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\", line 494, in run_step\n","    self._trainer.run_step()\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\", line 395, in run_step\n","    loss_dict = self.model(data)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/modeling/meta_arch/rcnn.py\", line 163, in forward\n","    _, detector_losses = self.roi_heads(images, features, proposals, gt_instances)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/roi_heads.py\", line 743, in forward\n","    losses.update(self._forward_mask(features, proposals))\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/roi_heads.py\", line 846, in _forward_mask\n","    return self.mask_head(features, instances)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/mask_head.py\", line 191, in forward\n","    x = self.layers(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/mask_head.py\", line 283, in layers\n","    x = layer(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\", line 98, in forward\n","    return F.relu(input, inplace=self.inplace)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1299, in relu\n","    result = torch.relu(input)\n","RuntimeError: CUDA out of memory. Tried to allocate 466.00 MiB (GPU 0; 15.90 GiB total capacity; 13.99 GiB already allocated; 171.75 MiB free; 14.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","\u001b[32m[12/17 05:19:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:04 (0:00:00 on hooks)\n","\u001b[32m[12/17 05:19:55 d2.utils.events]: \u001b[0m iter: 2  total_loss: 4.079  loss_cls: 1.335  loss_box_reg: 0.06921  loss_mask: 0.6921  loss_rpn_cls: 0.6981  loss_rpn_loc: 1.285  data_time: 1.6307  lr: 1.3325e-06  max_mem: 15108M\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-8456b8320f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2 的理论score最高\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-28e5acc4a1ae>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \"\"\"\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             assert hasattr(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_period\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_event_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;31m# heads. But when `self.train_on_pred_boxes is True`, proposals will contain boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;31m# predicted by the box head.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_keypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/roi_heads.py\u001b[0m in \u001b[0;36m_forward_mask\u001b[0;34m(self, features, instances)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_in_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_keypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/mask_head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, instances)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m\"instances\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmask_rcnn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_period\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/roi_heads/mask_head.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 466.00 MiB (GPU 0; 15.90 GiB total capacity; 13.99 GiB already allocated; 171.75 MiB free; 14.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["!git clone https://github.com/xiaohu2015/SwinT_detectron2.git"],"metadata":{"id":"GkkIa3WwYEu5","executionInfo":{"status":"aborted","timestamp":1639717010820,"user_tz":300,"elapsed":6,"user":{"displayName":"Charon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03716910765810413163"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"1VwTMpezcEKX"},"execution_count":null,"outputs":[]}]}