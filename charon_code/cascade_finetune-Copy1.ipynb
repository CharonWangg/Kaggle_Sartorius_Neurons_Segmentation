{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "GS-wk4MOLgU7",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-u4kiogyc\n",
      "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-u4kiogyc\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (8.3.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (3.4.2)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.3.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.8.9)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (4.53.0)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (2.5.0)\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.18.2)\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (1.4.2)\n",
      "Collecting omegaconf>=2.1\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting black==21.4b2\n",
      "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex>=2020.1.8 in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (2021.4.4)\n",
      "Collecting pathspec<1,>=0.8.1\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n",
      "Requirement already satisfied: toml>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (0.10.2)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.4.1)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.8/site-packages (from pycocotools>=2.0.2->detectron2==0.6) (49.6.0.post20210108)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.8/site-packages (from pycocotools>=2.0.2->detectron2==0.6) (0.28.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.38.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (3.17.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.30.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.36.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.13.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.1.1)\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, pycocotools, termcolor\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=7338214 sha256=cd21645f934dfebeb2c8b38216ec544d6e02531400c602ec436a0ca26837f46a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xi72arzr/wheels/19/ac/65/e48e5e4ec2702274d927c5a6efb75709b24014371d3bb778f2\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60943 sha256=5f87647841266a5c0a4ddd439f5949391ce3de895788475441036ab6030b2a96\n",
      "  Stored in directory: /home/.cache/pip/wheels/2e/af/94/f7fe3caa2a9b593e13e495d93c43c3245e3b01ee7b069010bc\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=c906714b5affcfa60153f7c16cabed55cc9df080e5b01e372aa3af9ff104b477\n",
      "  Stored in directory: /home/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.3-cp38-cp38-linux_x86_64.whl size=422828 sha256=c052691fba3c55e179c266d4180fdf108f6665487217c861ad4ec3d3d7268ea6\n",
      "  Stored in directory: /home/.cache/pip/wheels/59/5b/26/04441bc1820bf3622e0ea8616bef01b02cad3415ad880b834a\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=fdde3d78f94d6d7318da5b0d8a408ec2c5ca6c7e88dd50952bc81235ab9da500\n",
      "  Stored in directory: /home/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime pycocotools termcolor\n",
      "Installing collected packages: portalocker, antlr4-python3-runtime, termcolor, pathspec, omegaconf, mypy-extensions, iopath, importlib-resources, pycocotools, hydra-core, fvcore, cloudpickle, black, detectron2\n",
      "  Attempting uninstall: pycocotools\n",
      "    Found existing installation: pycocotools 2.0+nv0.5.1\n",
      "    Uninstalling pycocotools-2.0+nv0.5.1:\n",
      "      Successfully uninstalled pycocotools-2.0+nv0.5.1\n",
      "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 cloudpickle-2.0.0 detectron2-0.6 fvcore-0.1.5.post20211023 hydra-core-1.1.1 importlib-resources-5.4.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 pycocotools-2.0.3 termcolor-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting git+https://github.com/albumentations-team/albumentations.git\n",
      "  Cloning https://github.com/albumentations-team/albumentations.git to /tmp/pip-req-build-w0iry53a\n",
      "  Running command git clone -q https://github.com/albumentations-team/albumentations.git /tmp/pip-req-build-w0iry53a\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (1.20.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (1.6.3)\n",
      "Requirement already satisfied: scikit-image<0.19,>=0.16.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (0.18.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.1.0) (4.5.3.56)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations==1.1.0) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations==1.1.0) (3.10.0.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (3.4.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (8.3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2021.7.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.16.0)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.8/site-packages (from networkx>=2.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (5.0.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (2.1.0)\n",
      "Building wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for albumentations: filename=albumentations-1.1.0-py3-none-any.whl size=105142 sha256=3ee4008ca0b5d65ac2bb86287140580ff02f5daf1b3aef2a8a336902be66b9d9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-paje3460/wheels/bf/89/e3/323a3ae2345101d172eadac18193e5c6d1d2111201a624620a\n",
      "Successfully built albumentations\n",
      "Installing collected packages: qudida, albumentations\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 1.0.2\n",
      "    Uninstalling albumentations-1.0.2:\n",
      "      Successfully uninstalled albumentations-1.0.2\n",
      "Successfully installed albumentations-1.1.0 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install \"git+https://github.com/albumentations-team/albumentations.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1639767323377,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "y3aYkCLn_OP_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1639767327266,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "OKuetLmaKrFq"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.engine import BestCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from albumentations import *\n",
    "import torch\n",
    "import os\n",
    "from detectron2.data import detection_utils\n",
    "from utils.aug import MyMapper\n",
    "from detectron2.solver.build import *\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import opendatasets as od\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1639767327267,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "m7lpIyvHKw4R"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "  pixel_mean = [128,128,128]\n",
    "  pixel_std = [13.235,13.235,13.235]\n",
    "  anchor_generators_sizes = [[8], [16], [32], [64],[128]]\n",
    "  anchor_generators_aspect_ratios = [[0.5, 1.0, 2.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1639767327267,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "VPliT5cXKyei"
   },
   "outputs": [],
   "source": [
    "# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    false_negatives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "\n",
    "#     @classmethod\n",
    "#     def build_train_loader(cls, cfg, sampler=None):\n",
    "#         return build_detection_train_loader(\n",
    "#             cfg, mapper=MyMapper(cfg), sampler=sampler\n",
    "#         )\n",
    "\n",
    "    def build_hooks(self):\n",
    "      # copy of cfg\n",
    "      cfg = self.cfg.clone()\n",
    "\n",
    "      # build the original model hooks\n",
    "      hooks = super().build_hooks()\n",
    "\n",
    "      # add the best checkpointer hook\n",
    "      hooks.insert(-1, BestCheckpointer(cfg.TEST.EVAL_PERIOD, \n",
    "                                        DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                                        \"MaP IoU\",\n",
    "                                        \"max\",\n",
    "                                        ))\n",
    "      return hooks\n",
    "\n",
    "    # @classmethod\n",
    "    # def build_optimizer(cls,cfg,model) -> torch.optim.Optimizer:\n",
    "    #   \"\"\"\n",
    "    #   Build an optimizer from config.\n",
    "    #   \"\"\"\n",
    "    #   params = get_default_optimizer_params(\n",
    "    #       model,\n",
    "    #       base_lr=cfg.SOLVER.BASE_LR,\n",
    "    #       weight_decay_norm=cfg.SOLVER.WEIGHT_DECAY_NORM,\n",
    "    #       bias_lr_factor=cfg.SOLVER.BIAS_LR_FACTOR,\n",
    "    #       weight_decay_bias=cfg.SOLVER.WEIGHT_DECAY_BIAS,\n",
    "    #   )\n",
    "    #   return maybe_add_gradient_clipping(cfg, torch.optim.SGD)(\n",
    "    #       params,\n",
    "    #       lr=cfg.SOLVER.BASE_LR,\n",
    "    #       momentum=cfg.SOLVER.MOMENTUM,\n",
    "    #       nesterov=cfg.SOLVER.NESTEROV,\n",
    "    #       weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n",
    "    #   )\n",
    "\n",
    "    # @classmethod\n",
    "    # def build_lr_scheduler(cls,cfg, optimizer) -> torch.optim.lr_scheduler._LRScheduler:\n",
    "    #   \"\"\"\n",
    "    #   Build a LR scheduler from config.\n",
    "    #   \"\"\"\n",
    "    #   name = cfg.SOLVER.LR_SCHEDULER_NAME\n",
    "\n",
    "    #   if name == \"WarmupMultiStepLR\":\n",
    "    #       steps = [x for x in cfg.SOLVER.STEPS if x <= cfg.SOLVER.MAX_ITER]\n",
    "    #       if len(steps) != len(cfg.SOLVER.STEPS):\n",
    "    #           logger = logging.getLogger(__name__)\n",
    "    #           logger.warning(\n",
    "    #               \"SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. \"\n",
    "    #               \"These values will be ignored.\"\n",
    "    #           )\n",
    "    #       sched = MultiStepParamScheduler(\n",
    "    #           values=[cfg.SOLVER.GAMMA ** k for k in range(len(steps) + 1)],\n",
    "    #           milestones=steps,\n",
    "    #           num_updates=cfg.SOLVER.MAX_ITER,\n",
    "    #       )\n",
    "    #   elif name == \"WarmupCosineLR\":\n",
    "    #       sched = CosineParamScheduler(1, 1/40)\n",
    "    #   elif name == \"CyclicLR\":\n",
    "    #       sched = torch.optim.lr_scheduler.CyclicLR(optimizer,\n",
    "    #                                                 base_lr=cfg.SOLVER.BASE_LR, max_lr=5*cfg.SOLVER.BASE_LR,\n",
    "    #                                                 base_momentum=0.85, max_momentum=0.95)\n",
    "\n",
    "    #   else:\n",
    "    #       raise ValueError(\"Unknown LR scheduler: {}\".format(name))\n",
    "\n",
    "    #   sched = WarmupParamScheduler(\n",
    "    #       sched,\n",
    "    #       cfg.SOLVER.WARMUP_FACTOR,\n",
    "    #       min(cfg.SOLVER.WARMUP_ITERS / cfg.SOLVER.MAX_ITER, 1.0),\n",
    "    #       cfg.SOLVER.WARMUP_METHOD,\n",
    "    #   )\n",
    "    #   return LRMultiplier(optimizer, multiplier=sched, max_iter=cfg.SOLVER.MAX_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1639767327268,
     "user": {
      "displayName": "Charon",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03716910765810413163"
     },
     "user_tz": 300
    },
    "id": "dv3P0E4fK0DR"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "  dataDir = \"data\"\n",
    "  DatasetCatalog.clear()\n",
    "  MetadataCatalog.clear()\n",
    "  register_coco_instances(f'sartorius_train',{}, 'input/all/annotations_train.json'.format(fold), dataDir)\n",
    "  register_coco_instances(f'sartorius_val',{},'input/all/annotations_val.json'.format(fold), dataDir)\n",
    "\n",
    "  cfg = get_cfg()\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n",
    "  cfg.DATASETS.TRAIN = (f\"sartorius_train\",)\n",
    "  cfg.DATASETS.TEST = (f\"sartorius_val\",)\n",
    "  # cfg.MODEL.PIXEL_MEAN = Config.pixel_mean\n",
    "  # cfg.MODEL.PIXEL_STD = Config.pixel_std\n",
    "\n",
    "  cfg.DATALOADER.NUM_WORKERS = 14\n",
    "  cfg.MODEL.WEIGHTS = \"pretrained/final_weapon/model_0021999.pth\"#\"/content/drive/MyDrive/Kaggle/Sartorius/model/pretrained/LIVECell_anchor_based_model.pth\"\n",
    "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "  cfg.SOLVER.BASE_LR = 5e-4\n",
    "  cfg.SOLVER.WEIGHT_DECAY = 5e-5\n",
    "  cfg.SOLVER.WARMUP_ITERS = 200\n",
    "  #cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "  cfg.SOLVER.MAX_ITER = 10000 #len(DatasetCatalog.get(f\"sartorius_train\")) // cfg.SOLVER.IMS_PER_BATCH * 20 #尝试20ep 用lr调整\n",
    "  cfg.SOLVER.STEPS = (7000,9000,9500)\n",
    "  #cfg.SOLVER.GAMMA = 0.2\n",
    "  cfg.INPUT.MIN_SIZE_TRAIN = (1000,1100,1200,1300)\n",
    "  cfg.INPUT.MAX_SIZE_TRAIN = 2000\n",
    "  cfg.INPUT.CROP.ENABLE = False\n",
    "  cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
    "  cfg.INPUT.MIN_SIZE_TEST = 1300\n",
    "  cfg.INPUT.MAX_SIZE_TEST = 2000\n",
    "  cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 256\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "  #cfg.TEST.EVAL_PERIOD = \n",
    "  cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get(f\"sartorius_train\")) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "\n",
    "  cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "  cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "  cfg.SOLVER.AMP.ENABLED  = False\n",
    "  cfg.SEED = 42\n",
    "\n",
    "#   cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = Config.anchor_generators_aspect_ratios\n",
    "#   cfg.MODEL.ANCHOR_GENERATOR.SIZES = Config.anchor_generators_sizes\n",
    "  # cfg.MODEL.RESNETS.OUT_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "  # cfg.MODEL.ROI_HEADS.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "  # cfg.MODEL.RESNETS.OUT_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
    "  # #cfg.MODEL.FPN.NORM = \"GN\"\n",
    "  # cfg.MODEL.ROI_HEADS.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\",\"p6\"]\n",
    "  # cfg.MODEL.RPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "\n",
    "  # cfg.MODEL.RESNETS.DEFORM_ON_PER_STAGE = [False, True, True, True] # on Res3,Res4,Res5\n",
    "  # cfg.MODEL.RESNETS.DEFORM_MODULATED = True\n",
    "  # cfg.MODEL.RESNETS.DEFORM_NUM_GROUPS = 2\n",
    "  # cfg.MODEL.RESNETS.NORM = \"GN\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NUM_CONV = 4\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NUM_FC = 1\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.NORM = \"GN\"  \n",
    "  # cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 7\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG = True  \n",
    "  # cfg.MODEL.ROI_MASK_HEAD.NUM_CONV = 8\n",
    "  # cfg.MODEL.ROI_MASK_HEAD.NORM = \"GN\"\n",
    "  # cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5]\n",
    "  # cfg.MODEL.ROI_BOX_CASCADE_HEAD.IOUS = (0.5, 0.6, 0.7)\n",
    "\n",
    "  cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "  cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 3000\n",
    "  \n",
    "    \n",
    "  # cfg.MODEL.RPN.BBOX_REG_LOSS_TYPE = \"ciou\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"ciou\"\n",
    "  # cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 10.0\n",
    "  #cfg.SOLVER.AMP.ENABLED = True\n",
    "\n",
    "  cfg.OUTPUT_DIR = \"pretrained/final_weapon/finetuned/\".format(fold)\n",
    "\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "  trainer = Trainer(cfg) \n",
    "  trainer.resume_or_load(resume=False)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apzlCYlQK1m2",
    "outputId": "445d1533-13e5-410a-db1a-1cf5a78c0ea7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 02:18:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): DeformBottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): DeformBottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (23): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (24): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (25): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (26): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (27): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (28): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (29): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (30): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (31): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (32): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (33): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (34): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (35): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): DeformBottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): DeformBottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): DeformConv(\n",
      "            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn5): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn6): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn7): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn8): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/29 02:18:40 d2.data.datasets.coco]: \u001b[0mLoading input/all/annotations_train.json takes 1.06 seconds.\n",
      "\u001b[32m[12/29 02:18:40 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from input/all/annotations_train.json\n",
      "\u001b[32m[12/29 02:18:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[12/29 02:18:41 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/29 02:18:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(1000, 1100, 1200, 1300), max_size=2000, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/29 02:18:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/29 02:18:41 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:18:41 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (11, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (11,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (11, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (11,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (11, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (11,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (10, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (10,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.0.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.1.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.2.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 02:18:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W LegacyTypeDispatch.h:74] Warning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 02:19:36 d2.utils.events]: \u001b[0m eta: 6:21:27  iter: 19  total_loss: 6.658  loss_cls_stage0: 1.372  loss_box_reg_stage0: 0.3825  loss_cls_stage1: 1.294  loss_box_reg_stage1: 0.5224  loss_cls_stage2: 1.385  loss_box_reg_stage2: 0.4484  loss_mask: 0.69  loss_rpn_cls: 0.307  loss_rpn_loc: 0.2904  time: 2.3061  data_time: 0.3756  lr: 4.7953e-05  max_mem: 25234M\n",
      "\u001b[32m[12/29 02:20:21 d2.utils.events]: \u001b[0m eta: 6:20:42  iter: 39  total_loss: 5.41  loss_cls_stage0: 0.9437  loss_box_reg_stage0: 0.3385  loss_cls_stage1: 0.9145  loss_box_reg_stage1: 0.4644  loss_cls_stage2: 0.844  loss_box_reg_stage2: 0.4119  loss_mask: 0.6408  loss_rpn_cls: 0.2754  loss_rpn_loc: 0.2539  time: 2.2669  data_time: 0.0717  lr: 9.7902e-05  max_mem: 25234M\n",
      "\u001b[32m[12/29 02:21:06 d2.utils.events]: \u001b[0m eta: 6:17:53  iter: 59  total_loss: 4.7  loss_cls_stage0: 0.6922  loss_box_reg_stage0: 0.4674  loss_cls_stage1: 0.6644  loss_box_reg_stage1: 0.661  loss_cls_stage2: 0.575  loss_box_reg_stage2: 0.5568  loss_mask: 0.5521  loss_rpn_cls: 0.2562  loss_rpn_loc: 0.2501  time: 2.2618  data_time: 0.0839  lr: 0.00014785  max_mem: 25234M\n",
      "\u001b[32m[12/29 02:21:48 d2.utils.events]: \u001b[0m eta: 6:05:04  iter: 79  total_loss: 4.857  loss_cls_stage0: 0.6617  loss_box_reg_stage0: 0.5302  loss_cls_stage1: 0.6381  loss_box_reg_stage1: 0.793  loss_cls_stage2: 0.5558  loss_box_reg_stage2: 0.6371  loss_mask: 0.461  loss_rpn_cls: 0.1895  loss_rpn_loc: 0.2136  time: 2.2239  data_time: 0.0587  lr: 0.0001978  max_mem: 25234M\n",
      "\u001b[32m[12/29 02:22:34 d2.utils.events]: \u001b[0m eta: 6:06:38  iter: 99  total_loss: 4.45  loss_cls_stage0: 0.6054  loss_box_reg_stage0: 0.5288  loss_cls_stage1: 0.5773  loss_box_reg_stage1: 0.7749  loss_cls_stage2: 0.4819  loss_box_reg_stage2: 0.6074  loss_mask: 0.3914  loss_rpn_cls: 0.171  loss_rpn_loc: 0.2415  time: 2.2332  data_time: 0.0728  lr: 0.00024775  max_mem: 25234M\n",
      "\u001b[32m[12/29 02:23:18 d2.utils.events]: \u001b[0m eta: 6:08:12  iter: 119  total_loss: 4.635  loss_cls_stage0: 0.5699  loss_box_reg_stage0: 0.5526  loss_cls_stage1: 0.5651  loss_box_reg_stage1: 0.8492  loss_cls_stage2: 0.4731  loss_box_reg_stage2: 0.7062  loss_mask: 0.3527  loss_rpn_cls: 0.1501  loss_rpn_loc: 0.2144  time: 2.2335  data_time: 0.0662  lr: 0.0002977  max_mem: 25327M\n",
      "\u001b[32m[12/29 02:24:03 d2.utils.events]: \u001b[0m eta: 6:06:34  iter: 139  total_loss: 4.53  loss_cls_stage0: 0.526  loss_box_reg_stage0: 0.529  loss_cls_stage1: 0.5375  loss_box_reg_stage1: 0.8604  loss_cls_stage2: 0.5082  loss_box_reg_stage2: 0.7832  loss_mask: 0.3248  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.245  time: 2.2354  data_time: 0.0912  lr: 0.00034765  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:24:50 d2.utils.events]: \u001b[0m eta: 6:05:49  iter: 159  total_loss: 4.049  loss_cls_stage0: 0.4531  loss_box_reg_stage0: 0.4871  loss_cls_stage1: 0.4357  loss_box_reg_stage1: 0.8012  loss_cls_stage2: 0.4264  loss_box_reg_stage2: 0.7675  loss_mask: 0.3199  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.2117  time: 2.2463  data_time: 0.1073  lr: 0.0003976  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:25:32 d2.utils.events]: \u001b[0m eta: 6:02:14  iter: 179  total_loss: 4.138  loss_cls_stage0: 0.3777  loss_box_reg_stage0: 0.5115  loss_cls_stage1: 0.4009  loss_box_reg_stage1: 0.8964  loss_cls_stage2: 0.4076  loss_box_reg_stage2: 0.8666  loss_mask: 0.307  loss_rpn_cls: 0.1182  loss_rpn_loc: 0.2191  time: 2.2292  data_time: 0.0608  lr: 0.00044755  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:26:15 d2.utils.events]: \u001b[0m eta: 6:01:37  iter: 199  total_loss: 4.014  loss_cls_stage0: 0.3596  loss_box_reg_stage0: 0.538  loss_cls_stage1: 0.3875  loss_box_reg_stage1: 0.8796  loss_cls_stage2: 0.3863  loss_box_reg_stage2: 0.8375  loss_mask: 0.3039  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2096  time: 2.2252  data_time: 0.0812  lr: 0.0004975  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:27:00 d2.utils.events]: \u001b[0m eta: 6:00:53  iter: 219  total_loss: 3.785  loss_cls_stage0: 0.3077  loss_box_reg_stage0: 0.5213  loss_cls_stage1: 0.3236  loss_box_reg_stage1: 0.8905  loss_cls_stage2: 0.3333  loss_box_reg_stage2: 0.8797  loss_mask: 0.283  loss_rpn_cls: 0.0946  loss_rpn_loc: 0.2018  time: 2.2238  data_time: 0.0706  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:27:45 d2.utils.events]: \u001b[0m eta: 6:01:03  iter: 239  total_loss: 3.731  loss_cls_stage0: 0.2915  loss_box_reg_stage0: 0.4862  loss_cls_stage1: 0.307  loss_box_reg_stage1: 0.946  loss_cls_stage2: 0.3207  loss_box_reg_stage2: 0.8392  loss_mask: 0.3184  loss_rpn_cls: 0.09354  loss_rpn_loc: 0.2485  time: 2.2293  data_time: 0.0749  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:27:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:27:51 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/29 02:27:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:27:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:27:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:27:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:27:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0045 s/iter. Inference: 0.3831 s/iter. Eval: 0.0138 s/iter. Total: 0.4014 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/29 02:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0026 s/iter. Inference: 0.3699 s/iter. Eval: 0.0137 s/iter. Total: 0.3864 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 02:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0025 s/iter. Inference: 0.3673 s/iter. Eval: 0.0144 s/iter. Total: 0.3845 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 02:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0029 s/iter. Inference: 0.3790 s/iter. Eval: 0.0158 s/iter. Total: 0.3979 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 02:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0028 s/iter. Inference: 0.3853 s/iter. Eval: 0.0167 s/iter. Total: 0.4050 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 02:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0028 s/iter. Inference: 0.3853 s/iter. Eval: 0.0167 s/iter. Total: 0.4049 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 02:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0027 s/iter. Inference: 0.3837 s/iter. Eval: 0.0163 s/iter. Total: 0.4030 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 02:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0027 s/iter. Inference: 0.3865 s/iter. Eval: 0.0171 s/iter. Total: 0.4064 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 02:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0027 s/iter. Inference: 0.3796 s/iter. Eval: 0.0168 s/iter. Total: 0.3993 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 02:28:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.310812 (0.399231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:28:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.377766 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:28:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:28:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.1749123668690512\n",
      "\u001b[32m[12/29 02:28:45 d2.engine.hooks]: \u001b[0mSaved first model at 0.17491 @ 241 steps\n",
      "\u001b[32m[12/29 02:29:27 d2.utils.events]: \u001b[0m eta: 6:02:06  iter: 259  total_loss: 3.898  loss_cls_stage0: 0.3388  loss_box_reg_stage0: 0.5559  loss_cls_stage1: 0.3466  loss_box_reg_stage1: 0.8424  loss_cls_stage2: 0.3454  loss_box_reg_stage2: 0.8013  loss_mask: 0.3177  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2061  time: 2.2369  data_time: 0.1063  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:30:12 d2.utils.events]: \u001b[0m eta: 6:01:38  iter: 279  total_loss: 3.847  loss_cls_stage0: 0.3332  loss_box_reg_stage0: 0.5463  loss_cls_stage1: 0.3387  loss_box_reg_stage1: 0.8484  loss_cls_stage2: 0.3383  loss_box_reg_stage2: 0.7741  loss_mask: 0.3111  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.2047  time: 2.2382  data_time: 0.1011  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:30:57 d2.utils.events]: \u001b[0m eta: 6:00:41  iter: 299  total_loss: 3.647  loss_cls_stage0: 0.2275  loss_box_reg_stage0: 0.508  loss_cls_stage1: 0.27  loss_box_reg_stage1: 0.8908  loss_cls_stage2: 0.2778  loss_box_reg_stage2: 0.9235  loss_mask: 0.2962  loss_rpn_cls: 0.09095  loss_rpn_loc: 0.1867  time: 2.2386  data_time: 0.0587  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:31:41 d2.utils.events]: \u001b[0m eta: 5:59:56  iter: 319  total_loss: 3.762  loss_cls_stage0: 0.2489  loss_box_reg_stage0: 0.5136  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.9304  loss_cls_stage2: 0.2993  loss_box_reg_stage2: 0.9188  loss_mask: 0.2789  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.1925  time: 2.2365  data_time: 0.0838  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:32:24 d2.utils.events]: \u001b[0m eta: 5:58:51  iter: 339  total_loss: 3.825  loss_cls_stage0: 0.2614  loss_box_reg_stage0: 0.5096  loss_cls_stage1: 0.2812  loss_box_reg_stage1: 0.8831  loss_cls_stage2: 0.2865  loss_box_reg_stage2: 0.904  loss_mask: 0.2908  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1809  time: 2.2309  data_time: 0.0638  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:33:07 d2.utils.events]: \u001b[0m eta: 5:57:55  iter: 359  total_loss: 3.953  loss_cls_stage0: 0.2758  loss_box_reg_stage0: 0.5432  loss_cls_stage1: 0.2973  loss_box_reg_stage1: 0.9327  loss_cls_stage2: 0.3091  loss_box_reg_stage2: 0.875  loss_mask: 0.2864  loss_rpn_cls: 0.08229  loss_rpn_loc: 0.2262  time: 2.2279  data_time: 0.0657  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:33:51 d2.utils.events]: \u001b[0m eta: 5:56:30  iter: 379  total_loss: 3.603  loss_cls_stage0: 0.2341  loss_box_reg_stage0: 0.5198  loss_cls_stage1: 0.2502  loss_box_reg_stage1: 0.9006  loss_cls_stage2: 0.2711  loss_box_reg_stage2: 0.8912  loss_mask: 0.2967  loss_rpn_cls: 0.08215  loss_rpn_loc: 0.2057  time: 2.2263  data_time: 0.0680  lr: 0.0005  max_mem: 26858M\n",
      "\u001b[32m[12/29 02:34:37 d2.utils.events]: \u001b[0m eta: 5:56:22  iter: 399  total_loss: 3.733  loss_cls_stage0: 0.2514  loss_box_reg_stage0: 0.5221  loss_cls_stage1: 0.2718  loss_box_reg_stage1: 0.8668  loss_cls_stage2: 0.2861  loss_box_reg_stage2: 0.8223  loss_mask: 0.3044  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.2029  time: 2.2301  data_time: 0.0998  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:35:24 d2.utils.events]: \u001b[0m eta: 5:56:13  iter: 419  total_loss: 3.728  loss_cls_stage0: 0.2682  loss_box_reg_stage0: 0.5163  loss_cls_stage1: 0.2875  loss_box_reg_stage1: 0.8985  loss_cls_stage2: 0.2908  loss_box_reg_stage2: 0.8359  loss_mask: 0.2926  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.2069  time: 2.2344  data_time: 0.1012  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:36:08 d2.utils.events]: \u001b[0m eta: 5:55:55  iter: 439  total_loss: 3.884  loss_cls_stage0: 0.2576  loss_box_reg_stage0: 0.5374  loss_cls_stage1: 0.28  loss_box_reg_stage1: 0.9492  loss_cls_stage2: 0.2952  loss_box_reg_stage2: 0.8818  loss_mask: 0.3046  loss_rpn_cls: 0.07642  loss_rpn_loc: 0.2212  time: 2.2346  data_time: 0.0713  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:36:52 d2.utils.events]: \u001b[0m eta: 5:54:56  iter: 459  total_loss: 3.577  loss_cls_stage0: 0.2436  loss_box_reg_stage0: 0.5096  loss_cls_stage1: 0.2585  loss_box_reg_stage1: 0.8015  loss_cls_stage2: 0.2789  loss_box_reg_stage2: 0.7887  loss_mask: 0.2938  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2145  time: 2.2332  data_time: 0.0943  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:37:37 d2.utils.events]: \u001b[0m eta: 5:54:11  iter: 479  total_loss: 3.67  loss_cls_stage0: 0.2551  loss_box_reg_stage0: 0.5267  loss_cls_stage1: 0.2666  loss_box_reg_stage1: 0.9048  loss_cls_stage2: 0.2903  loss_box_reg_stage2: 0.8177  loss_mask: 0.2821  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.2041  time: 2.2332  data_time: 0.0817  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:37:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:37:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:37:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:37:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:37:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:37:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0027 s/iter. Inference: 0.3955 s/iter. Eval: 0.0272 s/iter. Total: 0.4254 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/29 02:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 21/121. Dataloading: 0.0020 s/iter. Inference: 0.4177 s/iter. Eval: 0.0552 s/iter. Total: 0.4757 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/29 02:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 33/121. Dataloading: 0.0021 s/iter. Inference: 0.3978 s/iter. Eval: 0.0541 s/iter. Total: 0.4545 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 02:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0023 s/iter. Inference: 0.3933 s/iter. Eval: 0.0533 s/iter. Total: 0.4494 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 02:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 57/121. Dataloading: 0.0023 s/iter. Inference: 0.3977 s/iter. Eval: 0.0461 s/iter. Total: 0.4466 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 02:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0027 s/iter. Inference: 0.3914 s/iter. Eval: 0.0460 s/iter. Total: 0.4404 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 02:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0027 s/iter. Inference: 0.3914 s/iter. Eval: 0.0534 s/iter. Total: 0.4478 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 02:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0029 s/iter. Inference: 0.3910 s/iter. Eval: 0.0553 s/iter. Total: 0.4495 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 02:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0029 s/iter. Inference: 0.3907 s/iter. Eval: 0.0539 s/iter. Total: 0.4477 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 02:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0028 s/iter. Inference: 0.3874 s/iter. Eval: 0.0520 s/iter. Total: 0.4425 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 02:38:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.531663 (0.444238 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:38:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:44 (0.386689 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:38:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:38:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25797406065122735\n",
      "\u001b[32m[12/29 02:38:48 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.25797, better than last best score 0.17491 @ iteration 241.\n",
      "\u001b[32m[12/29 02:39:23 d2.utils.events]: \u001b[0m eta: 5:53:27  iter: 499  total_loss: 3.77  loss_cls_stage0: 0.2773  loss_box_reg_stage0: 0.5456  loss_cls_stage1: 0.2988  loss_box_reg_stage1: 0.8788  loss_cls_stage2: 0.3043  loss_box_reg_stage2: 0.8088  loss_mask: 0.2966  loss_rpn_cls: 0.0751  loss_rpn_loc: 0.2078  time: 2.2324  data_time: 0.0937  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:40:09 d2.utils.events]: \u001b[0m eta: 5:53:26  iter: 519  total_loss: 3.697  loss_cls_stage0: 0.2291  loss_box_reg_stage0: 0.5058  loss_cls_stage1: 0.2515  loss_box_reg_stage1: 0.8898  loss_cls_stage2: 0.2678  loss_box_reg_stage2: 0.8762  loss_mask: 0.296  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.2079  time: 2.2340  data_time: 0.0832  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:40:53 d2.utils.events]: \u001b[0m eta: 5:52:49  iter: 539  total_loss: 3.714  loss_cls_stage0: 0.2494  loss_box_reg_stage0: 0.5474  loss_cls_stage1: 0.2624  loss_box_reg_stage1: 0.9193  loss_cls_stage2: 0.2827  loss_box_reg_stage2: 0.8551  loss_mask: 0.2964  loss_rpn_cls: 0.06656  loss_rpn_loc: 0.1825  time: 2.2334  data_time: 0.0696  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:41:38 d2.utils.events]: \u001b[0m eta: 5:51:13  iter: 559  total_loss: 3.757  loss_cls_stage0: 0.2525  loss_box_reg_stage0: 0.5355  loss_cls_stage1: 0.2556  loss_box_reg_stage1: 0.8702  loss_cls_stage2: 0.2849  loss_box_reg_stage2: 0.8312  loss_mask: 0.3016  loss_rpn_cls: 0.07573  loss_rpn_loc: 0.2301  time: 2.2329  data_time: 0.0786  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:42:21 d2.utils.events]: \u001b[0m eta: 5:50:10  iter: 579  total_loss: 3.585  loss_cls_stage0: 0.231  loss_box_reg_stage0: 0.5014  loss_cls_stage1: 0.249  loss_box_reg_stage1: 0.8478  loss_cls_stage2: 0.2616  loss_box_reg_stage2: 0.8999  loss_mask: 0.2756  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.2064  time: 2.2309  data_time: 0.0718  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:43:06 d2.utils.events]: \u001b[0m eta: 5:49:25  iter: 599  total_loss: 3.684  loss_cls_stage0: 0.2175  loss_box_reg_stage0: 0.5253  loss_cls_stage1: 0.2308  loss_box_reg_stage1: 0.9061  loss_cls_stage2: 0.2572  loss_box_reg_stage2: 0.8935  loss_mask: 0.2843  loss_rpn_cls: 0.07832  loss_rpn_loc: 0.203  time: 2.2315  data_time: 0.0814  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:43:49 d2.utils.events]: \u001b[0m eta: 5:48:41  iter: 619  total_loss: 3.627  loss_cls_stage0: 0.225  loss_box_reg_stage0: 0.5023  loss_cls_stage1: 0.2334  loss_box_reg_stage1: 0.9047  loss_cls_stage2: 0.2469  loss_box_reg_stage2: 0.9515  loss_mask: 0.2788  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.2087  time: 2.2296  data_time: 0.0684  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:44:35 d2.utils.events]: \u001b[0m eta: 5:47:42  iter: 639  total_loss: 3.604  loss_cls_stage0: 0.2808  loss_box_reg_stage0: 0.5142  loss_cls_stage1: 0.2839  loss_box_reg_stage1: 0.8835  loss_cls_stage2: 0.2918  loss_box_reg_stage2: 0.8623  loss_mask: 0.2993  loss_rpn_cls: 0.08471  loss_rpn_loc: 0.1933  time: 2.2303  data_time: 0.0948  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:45:19 d2.utils.events]: \u001b[0m eta: 5:46:58  iter: 659  total_loss: 3.458  loss_cls_stage0: 0.2092  loss_box_reg_stage0: 0.4562  loss_cls_stage1: 0.2136  loss_box_reg_stage1: 0.8113  loss_cls_stage2: 0.2328  loss_box_reg_stage2: 0.776  loss_mask: 0.2897  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.2097  time: 2.2307  data_time: 0.1135  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:46:05 d2.utils.events]: \u001b[0m eta: 5:46:27  iter: 679  total_loss: 3.77  loss_cls_stage0: 0.2316  loss_box_reg_stage0: 0.5009  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.873  loss_cls_stage2: 0.277  loss_box_reg_stage2: 0.9042  loss_mask: 0.2889  loss_rpn_cls: 0.08296  loss_rpn_loc: 0.2385  time: 2.2324  data_time: 0.0743  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:46:49 d2.utils.events]: \u001b[0m eta: 5:45:42  iter: 699  total_loss: 3.686  loss_cls_stage0: 0.2668  loss_box_reg_stage0: 0.5106  loss_cls_stage1: 0.2801  loss_box_reg_stage1: 0.871  loss_cls_stage2: 0.2874  loss_box_reg_stage2: 0.8507  loss_mask: 0.2859  loss_rpn_cls: 0.08967  loss_rpn_loc: 0.2011  time: 2.2314  data_time: 0.1217  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:47:35 d2.utils.events]: \u001b[0m eta: 5:45:16  iter: 719  total_loss: 3.638  loss_cls_stage0: 0.2662  loss_box_reg_stage0: 0.5194  loss_cls_stage1: 0.2887  loss_box_reg_stage1: 0.8453  loss_cls_stage2: 0.2874  loss_box_reg_stage2: 0.7969  loss_mask: 0.296  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.241  time: 2.2328  data_time: 0.0990  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:47:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:47:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:47:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:47:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:47:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:47:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0012 s/iter. Inference: 0.3433 s/iter. Eval: 0.0193 s/iter. Total: 0.3637 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 02:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 22/121. Dataloading: 0.0022 s/iter. Inference: 0.3867 s/iter. Eval: 0.0502 s/iter. Total: 0.4392 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/29 02:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 33/121. Dataloading: 0.0023 s/iter. Inference: 0.3885 s/iter. Eval: 0.0566 s/iter. Total: 0.4476 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 02:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0024 s/iter. Inference: 0.3822 s/iter. Eval: 0.0573 s/iter. Total: 0.4421 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 02:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 57/121. Dataloading: 0.0028 s/iter. Inference: 0.3841 s/iter. Eval: 0.0497 s/iter. Total: 0.4367 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 02:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0027 s/iter. Inference: 0.3760 s/iter. Eval: 0.0503 s/iter. Total: 0.4293 s/iter. ETA=0:00:21\n",
      "\u001b[32m[12/29 02:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0027 s/iter. Inference: 0.3716 s/iter. Eval: 0.0597 s/iter. Total: 0.4343 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 02:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0026 s/iter. Inference: 0.3670 s/iter. Eval: 0.0597 s/iter. Total: 0.4296 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/29 02:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0026 s/iter. Inference: 0.3661 s/iter. Eval: 0.0607 s/iter. Total: 0.4297 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 02:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0026 s/iter. Inference: 0.3617 s/iter. Eval: 0.0592 s/iter. Total: 0.4237 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/29 02:48:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.378552 (0.425677 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:48:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.361683 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:48:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:48:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26589444818672664\n",
      "\u001b[32m[12/29 02:48:45 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.26589, better than last best score 0.25797 @ iteration 483.\n",
      "\u001b[32m[12/29 02:49:15 d2.utils.events]: \u001b[0m eta: 5:43:49  iter: 739  total_loss: 3.695  loss_cls_stage0: 0.2596  loss_box_reg_stage0: 0.5362  loss_cls_stage1: 0.2778  loss_box_reg_stage1: 0.9059  loss_cls_stage2: 0.2878  loss_box_reg_stage2: 0.8669  loss_mask: 0.2803  loss_rpn_cls: 0.07761  loss_rpn_loc: 0.177  time: 2.2292  data_time: 0.0683  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:50:00 d2.utils.events]: \u001b[0m eta: 5:43:04  iter: 759  total_loss: 3.599  loss_cls_stage0: 0.2511  loss_box_reg_stage0: 0.5066  loss_cls_stage1: 0.2566  loss_box_reg_stage1: 0.8929  loss_cls_stage2: 0.2752  loss_box_reg_stage2: 0.8715  loss_mask: 0.2945  loss_rpn_cls: 0.08834  loss_rpn_loc: 0.197  time: 2.2307  data_time: 0.0890  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:50:48 d2.utils.events]: \u001b[0m eta: 5:43:02  iter: 779  total_loss: 3.636  loss_cls_stage0: 0.2318  loss_box_reg_stage0: 0.5084  loss_cls_stage1: 0.2701  loss_box_reg_stage1: 0.8716  loss_cls_stage2: 0.2725  loss_box_reg_stage2: 0.8297  loss_mask: 0.3024  loss_rpn_cls: 0.07954  loss_rpn_loc: 0.1877  time: 2.2348  data_time: 0.1085  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:51:33 d2.utils.events]: \u001b[0m eta: 5:42:05  iter: 799  total_loss: 3.668  loss_cls_stage0: 0.2511  loss_box_reg_stage0: 0.5205  loss_cls_stage1: 0.2724  loss_box_reg_stage1: 0.9077  loss_cls_stage2: 0.2835  loss_box_reg_stage2: 0.8193  loss_mask: 0.3007  loss_rpn_cls: 0.08115  loss_rpn_loc: 0.1898  time: 2.2344  data_time: 0.0993  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:52:16 d2.utils.events]: \u001b[0m eta: 5:41:09  iter: 819  total_loss: 3.692  loss_cls_stage0: 0.2134  loss_box_reg_stage0: 0.5407  loss_cls_stage1: 0.2309  loss_box_reg_stage1: 0.9038  loss_cls_stage2: 0.2537  loss_box_reg_stage2: 0.8906  loss_mask: 0.2944  loss_rpn_cls: 0.07365  loss_rpn_loc: 0.194  time: 2.2329  data_time: 0.0723  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:53:01 d2.utils.events]: \u001b[0m eta: 5:40:15  iter: 839  total_loss: 3.66  loss_cls_stage0: 0.2283  loss_box_reg_stage0: 0.4915  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.9456  loss_cls_stage2: 0.2637  loss_box_reg_stage2: 0.9947  loss_mask: 0.2863  loss_rpn_cls: 0.06068  loss_rpn_loc: 0.2115  time: 2.2326  data_time: 0.0743  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:53:46 d2.utils.events]: \u001b[0m eta: 5:39:30  iter: 859  total_loss: 3.85  loss_cls_stage0: 0.2439  loss_box_reg_stage0: 0.5256  loss_cls_stage1: 0.2746  loss_box_reg_stage1: 0.9448  loss_cls_stage2: 0.2837  loss_box_reg_stage2: 0.9409  loss_mask: 0.2865  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1854  time: 2.2331  data_time: 0.1144  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:54:29 d2.utils.events]: \u001b[0m eta: 5:38:35  iter: 879  total_loss: 3.717  loss_cls_stage0: 0.2677  loss_box_reg_stage0: 0.5483  loss_cls_stage1: 0.2683  loss_box_reg_stage1: 0.9545  loss_cls_stage2: 0.2706  loss_box_reg_stage2: 0.8142  loss_mask: 0.2935  loss_rpn_cls: 0.08902  loss_rpn_loc: 0.2033  time: 2.2315  data_time: 0.0631  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:55:12 d2.utils.events]: \u001b[0m eta: 5:37:41  iter: 899  total_loss: 3.656  loss_cls_stage0: 0.2409  loss_box_reg_stage0: 0.4972  loss_cls_stage1: 0.2593  loss_box_reg_stage1: 0.9303  loss_cls_stage2: 0.2649  loss_box_reg_stage2: 0.9117  loss_mask: 0.281  loss_rpn_cls: 0.07273  loss_rpn_loc: 0.2106  time: 2.2294  data_time: 0.0883  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:55:56 d2.utils.events]: \u001b[0m eta: 5:36:57  iter: 919  total_loss: 3.637  loss_cls_stage0: 0.2396  loss_box_reg_stage0: 0.4933  loss_cls_stage1: 0.2485  loss_box_reg_stage1: 0.896  loss_cls_stage2: 0.2705  loss_box_reg_stage2: 0.915  loss_mask: 0.2865  loss_rpn_cls: 0.0384  loss_rpn_loc: 0.1871  time: 2.2286  data_time: 0.0851  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:56:40 d2.utils.events]: \u001b[0m eta: 5:36:17  iter: 939  total_loss: 3.585  loss_cls_stage0: 0.261  loss_box_reg_stage0: 0.4924  loss_cls_stage1: 0.2656  loss_box_reg_stage1: 0.8858  loss_cls_stage2: 0.2841  loss_box_reg_stage2: 0.827  loss_mask: 0.2987  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.199  time: 2.2288  data_time: 0.0832  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:57:24 d2.utils.events]: \u001b[0m eta: 5:35:23  iter: 959  total_loss: 3.387  loss_cls_stage0: 0.1997  loss_box_reg_stage0: 0.474  loss_cls_stage1: 0.2126  loss_box_reg_stage1: 0.8352  loss_cls_stage2: 0.2357  loss_box_reg_stage2: 0.8441  loss_mask: 0.2768  loss_rpn_cls: 0.04965  loss_rpn_loc: 0.1638  time: 2.2281  data_time: 0.0770  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:57:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:57:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 02:57:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 02:57:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 02:57:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 02:57:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 02:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.3311 s/iter. Eval: 0.0183 s/iter. Total: 0.3511 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 02:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0017 s/iter. Inference: 0.3323 s/iter. Eval: 0.0537 s/iter. Total: 0.3879 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 02:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0019 s/iter. Inference: 0.3394 s/iter. Eval: 0.0511 s/iter. Total: 0.3926 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 02:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0022 s/iter. Inference: 0.3391 s/iter. Eval: 0.0545 s/iter. Total: 0.3960 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 02:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0022 s/iter. Inference: 0.3383 s/iter. Eval: 0.0558 s/iter. Total: 0.3965 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 02:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0026 s/iter. Inference: 0.3426 s/iter. Eval: 0.0572 s/iter. Total: 0.4028 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 02:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0026 s/iter. Inference: 0.3439 s/iter. Eval: 0.0639 s/iter. Total: 0.4108 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 02:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0028 s/iter. Inference: 0.3491 s/iter. Eval: 0.0646 s/iter. Total: 0.4168 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 02:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0027 s/iter. Inference: 0.3471 s/iter. Eval: 0.0644 s/iter. Total: 0.4146 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 02:58:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.242022 (0.415880 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:58:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.348337 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 02:58:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2657291464980697\n",
      "\u001b[32m[12/29 02:58:36 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.26573, not better than best score 0.26589 @ iteration 725.\n",
      "\u001b[32m[12/29 02:59:02 d2.utils.events]: \u001b[0m eta: 5:34:16  iter: 979  total_loss: 3.5  loss_cls_stage0: 0.2362  loss_box_reg_stage0: 0.5002  loss_cls_stage1: 0.2588  loss_box_reg_stage1: 0.8647  loss_cls_stage2: 0.268  loss_box_reg_stage2: 0.8558  loss_mask: 0.2949  loss_rpn_cls: 0.07263  loss_rpn_loc: 0.1893  time: 2.2276  data_time: 0.0983  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 02:59:46 d2.utils.events]: \u001b[0m eta: 5:33:28  iter: 999  total_loss: 3.771  loss_cls_stage0: 0.2645  loss_box_reg_stage0: 0.5128  loss_cls_stage1: 0.266  loss_box_reg_stage1: 0.9039  loss_cls_stage2: 0.2753  loss_box_reg_stage2: 0.9155  loss_mask: 0.2887  loss_rpn_cls: 0.06996  loss_rpn_loc: 0.2033  time: 2.2267  data_time: 0.0881  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 03:00:29 d2.utils.events]: \u001b[0m eta: 5:32:15  iter: 1019  total_loss: 3.621  loss_cls_stage0: 0.2369  loss_box_reg_stage0: 0.5091  loss_cls_stage1: 0.2356  loss_box_reg_stage1: 0.8872  loss_cls_stage2: 0.2612  loss_box_reg_stage2: 0.9299  loss_mask: 0.2997  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1923  time: 2.2259  data_time: 0.0849  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 03:01:14 d2.utils.events]: \u001b[0m eta: 5:31:21  iter: 1039  total_loss: 3.596  loss_cls_stage0: 0.2284  loss_box_reg_stage0: 0.5104  loss_cls_stage1: 0.2486  loss_box_reg_stage1: 0.9154  loss_cls_stage2: 0.269  loss_box_reg_stage2: 0.8878  loss_mask: 0.2775  loss_rpn_cls: 0.07525  loss_rpn_loc: 0.2  time: 2.2257  data_time: 0.0693  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 03:01:57 d2.utils.events]: \u001b[0m eta: 5:30:29  iter: 1059  total_loss: 3.594  loss_cls_stage0: 0.2075  loss_box_reg_stage0: 0.4958  loss_cls_stage1: 0.2231  loss_box_reg_stage1: 0.8918  loss_cls_stage2: 0.2427  loss_box_reg_stage2: 0.8993  loss_mask: 0.2837  loss_rpn_cls: 0.08602  loss_rpn_loc: 0.2035  time: 2.2245  data_time: 0.0757  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 03:02:41 d2.utils.events]: \u001b[0m eta: 5:30:02  iter: 1079  total_loss: 3.614  loss_cls_stage0: 0.251  loss_box_reg_stage0: 0.5423  loss_cls_stage1: 0.2659  loss_box_reg_stage1: 0.8936  loss_cls_stage2: 0.2754  loss_box_reg_stage2: 0.8479  loss_mask: 0.2912  loss_rpn_cls: 0.06483  loss_rpn_loc: 0.2131  time: 2.2244  data_time: 0.1026  lr: 0.0005  max_mem: 27188M\n",
      "\u001b[32m[12/29 03:03:28 d2.utils.events]: \u001b[0m eta: 5:29:13  iter: 1099  total_loss: 3.494  loss_cls_stage0: 0.2172  loss_box_reg_stage0: 0.479  loss_cls_stage1: 0.2481  loss_box_reg_stage1: 0.8551  loss_cls_stage2: 0.269  loss_box_reg_stage2: 0.8208  loss_mask: 0.2921  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.2166  time: 2.2259  data_time: 0.1166  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:04:12 d2.utils.events]: \u001b[0m eta: 5:28:33  iter: 1119  total_loss: 3.755  loss_cls_stage0: 0.2422  loss_box_reg_stage0: 0.5377  loss_cls_stage1: 0.2648  loss_box_reg_stage1: 0.9725  loss_cls_stage2: 0.2779  loss_box_reg_stage2: 0.8272  loss_mask: 0.2963  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.1903  time: 2.2260  data_time: 0.0844  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:04:55 d2.utils.events]: \u001b[0m eta: 5:27:39  iter: 1139  total_loss: 3.617  loss_cls_stage0: 0.2457  loss_box_reg_stage0: 0.5076  loss_cls_stage1: 0.2506  loss_box_reg_stage1: 0.9449  loss_cls_stage2: 0.2716  loss_box_reg_stage2: 1.012  loss_mask: 0.2763  loss_rpn_cls: 0.04837  loss_rpn_loc: 0.1604  time: 2.2242  data_time: 0.0614  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:05:37 d2.utils.events]: \u001b[0m eta: 5:26:47  iter: 1159  total_loss: 3.724  loss_cls_stage0: 0.2447  loss_box_reg_stage0: 0.4979  loss_cls_stage1: 0.2392  loss_box_reg_stage1: 0.9406  loss_cls_stage2: 0.2562  loss_box_reg_stage2: 1.007  loss_mask: 0.272  loss_rpn_cls: 0.06425  loss_rpn_loc: 0.1798  time: 2.2227  data_time: 0.0733  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:06:22 d2.utils.events]: \u001b[0m eta: 5:26:13  iter: 1179  total_loss: 3.519  loss_cls_stage0: 0.2404  loss_box_reg_stage0: 0.513  loss_cls_stage1: 0.2594  loss_box_reg_stage1: 0.8433  loss_cls_stage2: 0.2734  loss_box_reg_stage2: 0.7745  loss_mask: 0.3006  loss_rpn_cls: 0.08725  loss_rpn_loc: 0.1968  time: 2.2225  data_time: 0.0972  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:07:05 d2.utils.events]: \u001b[0m eta: 5:25:23  iter: 1199  total_loss: 3.412  loss_cls_stage0: 0.2106  loss_box_reg_stage0: 0.4843  loss_cls_stage1: 0.2385  loss_box_reg_stage1: 0.8489  loss_cls_stage2: 0.2387  loss_box_reg_stage2: 0.9177  loss_mask: 0.2875  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.1891  time: 2.2219  data_time: 0.0772  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:07:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:07:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:07:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:07:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:07:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:07:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.3336 s/iter. Eval: 0.0182 s/iter. Total: 0.3535 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0016 s/iter. Inference: 0.3532 s/iter. Eval: 0.0436 s/iter. Total: 0.3986 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 03:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0018 s/iter. Inference: 0.3487 s/iter. Eval: 0.0481 s/iter. Total: 0.3987 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 03:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0021 s/iter. Inference: 0.3452 s/iter. Eval: 0.0509 s/iter. Total: 0.3984 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 03:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0022 s/iter. Inference: 0.3442 s/iter. Eval: 0.0491 s/iter. Total: 0.3957 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0022 s/iter. Inference: 0.3448 s/iter. Eval: 0.0526 s/iter. Total: 0.3998 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 03:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0023 s/iter. Inference: 0.3451 s/iter. Eval: 0.0580 s/iter. Total: 0.4055 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0023 s/iter. Inference: 0.3445 s/iter. Eval: 0.0614 s/iter. Total: 0.4083 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 03:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0023 s/iter. Inference: 0.3451 s/iter. Eval: 0.0601 s/iter. Total: 0.4077 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 03:08:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.266725 (0.407472 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:08:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.344040 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:08:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:08:21 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28278458150501334\n",
      "\u001b[32m[12/29 03:08:24 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.28278, better than last best score 0.26589 @ iteration 725.\n",
      "\u001b[32m[12/29 03:08:47 d2.utils.events]: \u001b[0m eta: 5:24:47  iter: 1219  total_loss: 3.616  loss_cls_stage0: 0.2177  loss_box_reg_stage0: 0.5026  loss_cls_stage1: 0.2225  loss_box_reg_stage1: 0.8713  loss_cls_stage2: 0.2614  loss_box_reg_stage2: 0.8406  loss_mask: 0.2886  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1848  time: 2.2225  data_time: 0.1028  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:09:30 d2.utils.events]: \u001b[0m eta: 5:23:58  iter: 1239  total_loss: 3.706  loss_cls_stage0: 0.2294  loss_box_reg_stage0: 0.4997  loss_cls_stage1: 0.2509  loss_box_reg_stage1: 0.9055  loss_cls_stage2: 0.264  loss_box_reg_stage2: 0.8773  loss_mask: 0.2786  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.2051  time: 2.2219  data_time: 0.0637  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:10:14 d2.utils.events]: \u001b[0m eta: 5:23:00  iter: 1259  total_loss: 3.542  loss_cls_stage0: 0.262  loss_box_reg_stage0: 0.5023  loss_cls_stage1: 0.277  loss_box_reg_stage1: 0.891  loss_cls_stage2: 0.2797  loss_box_reg_stage2: 0.8828  loss_mask: 0.2757  loss_rpn_cls: 0.09044  loss_rpn_loc: 0.1901  time: 2.2216  data_time: 0.0817  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:11:01 d2.utils.events]: \u001b[0m eta: 5:22:21  iter: 1279  total_loss: 3.648  loss_cls_stage0: 0.2368  loss_box_reg_stage0: 0.5216  loss_cls_stage1: 0.2485  loss_box_reg_stage1: 0.9483  loss_cls_stage2: 0.2648  loss_box_reg_stage2: 0.8755  loss_mask: 0.2892  loss_rpn_cls: 0.06528  loss_rpn_loc: 0.2001  time: 2.2231  data_time: 0.1079  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:11:43 d2.utils.events]: \u001b[0m eta: 5:21:13  iter: 1299  total_loss: 3.56  loss_cls_stage0: 0.2079  loss_box_reg_stage0: 0.5205  loss_cls_stage1: 0.2252  loss_box_reg_stage1: 0.9225  loss_cls_stage2: 0.2443  loss_box_reg_stage2: 0.8683  loss_mask: 0.296  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.2012  time: 2.2215  data_time: 0.0612  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:12:29 d2.utils.events]: \u001b[0m eta: 5:20:33  iter: 1319  total_loss: 3.599  loss_cls_stage0: 0.1976  loss_box_reg_stage0: 0.4961  loss_cls_stage1: 0.2103  loss_box_reg_stage1: 0.9074  loss_cls_stage2: 0.2568  loss_box_reg_stage2: 0.965  loss_mask: 0.2809  loss_rpn_cls: 0.05413  loss_rpn_loc: 0.1764  time: 2.2223  data_time: 0.0755  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:13:15 d2.utils.events]: \u001b[0m eta: 5:20:12  iter: 1339  total_loss: 3.69  loss_cls_stage0: 0.2329  loss_box_reg_stage0: 0.5122  loss_cls_stage1: 0.251  loss_box_reg_stage1: 0.8997  loss_cls_stage2: 0.2741  loss_box_reg_stage2: 0.8839  loss_mask: 0.2842  loss_rpn_cls: 0.07406  loss_rpn_loc: 0.216  time: 2.2238  data_time: 0.1067  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:13:59 d2.utils.events]: \u001b[0m eta: 5:19:28  iter: 1359  total_loss: 3.667  loss_cls_stage0: 0.2389  loss_box_reg_stage0: 0.519  loss_cls_stage1: 0.2529  loss_box_reg_stage1: 0.8871  loss_cls_stage2: 0.2646  loss_box_reg_stage2: 0.8857  loss_mask: 0.2909  loss_rpn_cls: 0.07622  loss_rpn_loc: 0.2093  time: 2.2235  data_time: 0.0817  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:14:43 d2.utils.events]: \u001b[0m eta: 5:18:47  iter: 1379  total_loss: 3.6  loss_cls_stage0: 0.2251  loss_box_reg_stage0: 0.5047  loss_cls_stage1: 0.2471  loss_box_reg_stage1: 0.9664  loss_cls_stage2: 0.2622  loss_box_reg_stage2: 0.8693  loss_mask: 0.2981  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.1937  time: 2.2229  data_time: 0.0835  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:15:26 d2.utils.events]: \u001b[0m eta: 5:17:55  iter: 1399  total_loss: 3.708  loss_cls_stage0: 0.2607  loss_box_reg_stage0: 0.5119  loss_cls_stage1: 0.2744  loss_box_reg_stage1: 0.9121  loss_cls_stage2: 0.2728  loss_box_reg_stage2: 0.904  loss_mask: 0.284  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.1859  time: 2.2223  data_time: 0.0692  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:16:09 d2.utils.events]: \u001b[0m eta: 5:16:24  iter: 1419  total_loss: 3.519  loss_cls_stage0: 0.2315  loss_box_reg_stage0: 0.4836  loss_cls_stage1: 0.25  loss_box_reg_stage1: 0.8661  loss_cls_stage2: 0.2513  loss_box_reg_stage2: 0.8503  loss_mask: 0.2767  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.1878  time: 2.2209  data_time: 0.0813  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:16:55 d2.utils.events]: \u001b[0m eta: 5:16:07  iter: 1439  total_loss: 3.652  loss_cls_stage0: 0.2174  loss_box_reg_stage0: 0.4936  loss_cls_stage1: 0.2609  loss_box_reg_stage1: 0.8611  loss_cls_stage2: 0.2656  loss_box_reg_stage2: 0.8631  loss_mask: 0.2866  loss_rpn_cls: 0.09748  loss_rpn_loc: 0.1985  time: 2.2221  data_time: 0.1243  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:17:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:17:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:17:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:17:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:17:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:17:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.3306 s/iter. Eval: 0.0190 s/iter. Total: 0.3511 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0017 s/iter. Inference: 0.3456 s/iter. Eval: 0.0526 s/iter. Total: 0.4000 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0019 s/iter. Inference: 0.3403 s/iter. Eval: 0.0499 s/iter. Total: 0.3922 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 03:17:46 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0021 s/iter. Inference: 0.3488 s/iter. Eval: 0.0532 s/iter. Total: 0.4043 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 03:17:51 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0022 s/iter. Inference: 0.3448 s/iter. Eval: 0.0537 s/iter. Total: 0.4010 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:17:56 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0024 s/iter. Inference: 0.3446 s/iter. Eval: 0.0563 s/iter. Total: 0.4035 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 03:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0024 s/iter. Inference: 0.3428 s/iter. Eval: 0.0608 s/iter. Total: 0.4061 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0024 s/iter. Inference: 0.3407 s/iter. Eval: 0.0642 s/iter. Total: 0.4075 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 03:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0024 s/iter. Inference: 0.3388 s/iter. Eval: 0.0615 s/iter. Total: 0.4028 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 03:18:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.758984 (0.403095 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:18:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.337794 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:18:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:18:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2808640065961663\n",
      "\u001b[32m[12/29 03:18:14 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.28086, not better than best score 0.28278 @ iteration 1209.\n",
      "\u001b[32m[12/29 03:18:33 d2.utils.events]: \u001b[0m eta: 5:15:28  iter: 1459  total_loss: 3.659  loss_cls_stage0: 0.2484  loss_box_reg_stage0: 0.5066  loss_cls_stage1: 0.2567  loss_box_reg_stage1: 0.9051  loss_cls_stage2: 0.2748  loss_box_reg_stage2: 0.879  loss_mask: 0.2879  loss_rpn_cls: 0.08575  loss_rpn_loc: 0.2213  time: 2.2229  data_time: 0.0848  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:19:19 d2.utils.events]: \u001b[0m eta: 5:14:52  iter: 1479  total_loss: 3.433  loss_cls_stage0: 0.2003  loss_box_reg_stage0: 0.483  loss_cls_stage1: 0.2261  loss_box_reg_stage1: 0.8467  loss_cls_stage2: 0.2547  loss_box_reg_stage2: 0.8455  loss_mask: 0.2823  loss_rpn_cls: 0.06223  loss_rpn_loc: 0.2155  time: 2.2237  data_time: 0.0950  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:20:02 d2.utils.events]: \u001b[0m eta: 5:13:46  iter: 1499  total_loss: 3.548  loss_cls_stage0: 0.2367  loss_box_reg_stage0: 0.5072  loss_cls_stage1: 0.248  loss_box_reg_stage1: 0.8692  loss_cls_stage2: 0.2713  loss_box_reg_stage2: 0.8518  loss_mask: 0.2862  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.2087  time: 2.2232  data_time: 0.0874  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:20:47 d2.utils.events]: \u001b[0m eta: 5:12:30  iter: 1519  total_loss: 3.406  loss_cls_stage0: 0.183  loss_box_reg_stage0: 0.4496  loss_cls_stage1: 0.2036  loss_box_reg_stage1: 0.8882  loss_cls_stage2: 0.2359  loss_box_reg_stage2: 0.8532  loss_mask: 0.281  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.1911  time: 2.2232  data_time: 0.0935  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:21:33 d2.utils.events]: \u001b[0m eta: 5:11:59  iter: 1539  total_loss: 3.494  loss_cls_stage0: 0.2154  loss_box_reg_stage0: 0.4927  loss_cls_stage1: 0.222  loss_box_reg_stage1: 0.9046  loss_cls_stage2: 0.2583  loss_box_reg_stage2: 0.9718  loss_mask: 0.2716  loss_rpn_cls: 0.05623  loss_rpn_loc: 0.1543  time: 2.2239  data_time: 0.0742  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:22:17 d2.utils.events]: \u001b[0m eta: 5:11:54  iter: 1559  total_loss: 3.422  loss_cls_stage0: 0.2007  loss_box_reg_stage0: 0.4901  loss_cls_stage1: 0.2174  loss_box_reg_stage1: 0.8576  loss_cls_stage2: 0.2355  loss_box_reg_stage2: 0.8807  loss_mask: 0.2857  loss_rpn_cls: 0.08703  loss_rpn_loc: 0.1834  time: 2.2239  data_time: 0.0765  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:23:00 d2.utils.events]: \u001b[0m eta: 5:11:18  iter: 1579  total_loss: 3.544  loss_cls_stage0: 0.2198  loss_box_reg_stage0: 0.4639  loss_cls_stage1: 0.2438  loss_box_reg_stage1: 0.9111  loss_cls_stage2: 0.25  loss_box_reg_stage2: 0.9208  loss_mask: 0.2788  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.1778  time: 2.2230  data_time: 0.0690  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:23:44 d2.utils.events]: \u001b[0m eta: 5:10:26  iter: 1599  total_loss: 3.632  loss_cls_stage0: 0.2386  loss_box_reg_stage0: 0.4884  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.8697  loss_cls_stage2: 0.2685  loss_box_reg_stage2: 0.8896  loss_mask: 0.2806  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.2105  time: 2.2225  data_time: 0.0850  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:24:27 d2.utils.events]: \u001b[0m eta: 5:09:33  iter: 1619  total_loss: 3.603  loss_cls_stage0: 0.2359  loss_box_reg_stage0: 0.5279  loss_cls_stage1: 0.2635  loss_box_reg_stage1: 0.8831  loss_cls_stage2: 0.2742  loss_box_reg_stage2: 0.8873  loss_mask: 0.2905  loss_rpn_cls: 0.08574  loss_rpn_loc: 0.203  time: 2.2220  data_time: 0.0898  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:25:10 d2.utils.events]: \u001b[0m eta: 5:08:44  iter: 1639  total_loss: 3.648  loss_cls_stage0: 0.2311  loss_box_reg_stage0: 0.516  loss_cls_stage1: 0.2368  loss_box_reg_stage1: 0.908  loss_cls_stage2: 0.256  loss_box_reg_stage2: 0.908  loss_mask: 0.2891  loss_rpn_cls: 0.07466  loss_rpn_loc: 0.1928  time: 2.2209  data_time: 0.0693  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:25:55 d2.utils.events]: \u001b[0m eta: 5:08:18  iter: 1659  total_loss: 3.507  loss_cls_stage0: 0.2003  loss_box_reg_stage0: 0.4811  loss_cls_stage1: 0.2161  loss_box_reg_stage1: 0.8803  loss_cls_stage2: 0.2523  loss_box_reg_stage2: 0.8559  loss_mask: 0.2856  loss_rpn_cls: 0.07058  loss_rpn_loc: 0.1867  time: 2.2211  data_time: 0.0938  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:26:39 d2.utils.events]: \u001b[0m eta: 5:07:15  iter: 1679  total_loss: 3.437  loss_cls_stage0: 0.2131  loss_box_reg_stage0: 0.4927  loss_cls_stage1: 0.2179  loss_box_reg_stage1: 0.8789  loss_cls_stage2: 0.2464  loss_box_reg_stage2: 0.8604  loss_mask: 0.2931  loss_rpn_cls: 0.08574  loss_rpn_loc: 0.1884  time: 2.2209  data_time: 0.0872  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:27:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:27:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:27:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:27:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:27:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:27:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.3224 s/iter. Eval: 0.0178 s/iter. Total: 0.3416 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 03:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0015 s/iter. Inference: 0.3376 s/iter. Eval: 0.0472 s/iter. Total: 0.3865 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 03:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0018 s/iter. Inference: 0.3357 s/iter. Eval: 0.0463 s/iter. Total: 0.3840 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 03:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0020 s/iter. Inference: 0.3360 s/iter. Eval: 0.0494 s/iter. Total: 0.3876 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 03:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0022 s/iter. Inference: 0.3375 s/iter. Eval: 0.0498 s/iter. Total: 0.3898 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 03:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0023 s/iter. Inference: 0.3431 s/iter. Eval: 0.0526 s/iter. Total: 0.3982 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 03:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0024 s/iter. Inference: 0.3451 s/iter. Eval: 0.0572 s/iter. Total: 0.4049 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0024 s/iter. Inference: 0.3438 s/iter. Eval: 0.0603 s/iter. Total: 0.4067 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 03:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0024 s/iter. Inference: 0.3419 s/iter. Eval: 0.0577 s/iter. Total: 0.4022 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 03:28:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.944255 (0.404692 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:28:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.342049 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:28:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:28:03 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27905181227554116\n",
      "\u001b[32m[12/29 03:28:03 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.27905, not better than best score 0.28278 @ iteration 1209.\n",
      "\u001b[32m[12/29 03:28:18 d2.utils.events]: \u001b[0m eta: 5:06:46  iter: 1699  total_loss: 3.727  loss_cls_stage0: 0.2572  loss_box_reg_stage0: 0.542  loss_cls_stage1: 0.2825  loss_box_reg_stage1: 0.883  loss_cls_stage2: 0.2931  loss_box_reg_stage2: 0.7855  loss_mask: 0.2975  loss_rpn_cls: 0.09725  loss_rpn_loc: 0.2255  time: 2.2219  data_time: 0.1161  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:29:03 d2.utils.events]: \u001b[0m eta: 5:05:52  iter: 1719  total_loss: 3.694  loss_cls_stage0: 0.2497  loss_box_reg_stage0: 0.5057  loss_cls_stage1: 0.2648  loss_box_reg_stage1: 0.8894  loss_cls_stage2: 0.2766  loss_box_reg_stage2: 0.8934  loss_mask: 0.2736  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.1835  time: 2.2224  data_time: 0.0858  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:29:49 d2.utils.events]: \u001b[0m eta: 5:05:42  iter: 1739  total_loss: 3.498  loss_cls_stage0: 0.2185  loss_box_reg_stage0: 0.5022  loss_cls_stage1: 0.2555  loss_box_reg_stage1: 0.8859  loss_cls_stage2: 0.2726  loss_box_reg_stage2: 0.8782  loss_mask: 0.3  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.2003  time: 2.2236  data_time: 0.1347  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:30:35 d2.utils.events]: \u001b[0m eta: 5:04:58  iter: 1759  total_loss: 3.452  loss_cls_stage0: 0.1912  loss_box_reg_stage0: 0.4726  loss_cls_stage1: 0.2099  loss_box_reg_stage1: 0.8686  loss_cls_stage2: 0.2447  loss_box_reg_stage2: 0.8903  loss_mask: 0.2723  loss_rpn_cls: 0.05782  loss_rpn_loc: 0.189  time: 2.2240  data_time: 0.0873  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:31:20 d2.utils.events]: \u001b[0m eta: 5:03:59  iter: 1779  total_loss: 3.605  loss_cls_stage0: 0.2186  loss_box_reg_stage0: 0.5143  loss_cls_stage1: 0.2354  loss_box_reg_stage1: 0.8763  loss_cls_stage2: 0.2625  loss_box_reg_stage2: 0.8969  loss_mask: 0.2855  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.1988  time: 2.2247  data_time: 0.0854  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:32:03 d2.utils.events]: \u001b[0m eta: 5:02:54  iter: 1799  total_loss: 3.44  loss_cls_stage0: 0.2221  loss_box_reg_stage0: 0.4912  loss_cls_stage1: 0.2343  loss_box_reg_stage1: 0.8507  loss_cls_stage2: 0.2623  loss_box_reg_stage2: 0.8456  loss_mask: 0.3036  loss_rpn_cls: 0.08464  loss_rpn_loc: 0.2033  time: 2.2237  data_time: 0.1003  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:32:47 d2.utils.events]: \u001b[0m eta: 5:02:27  iter: 1819  total_loss: 3.402  loss_cls_stage0: 0.221  loss_box_reg_stage0: 0.4994  loss_cls_stage1: 0.2418  loss_box_reg_stage1: 0.8433  loss_cls_stage2: 0.2532  loss_box_reg_stage2: 0.834  loss_mask: 0.2856  loss_rpn_cls: 0.06106  loss_rpn_loc: 0.1716  time: 2.2237  data_time: 0.0913  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:33:32 d2.utils.events]: \u001b[0m eta: 5:01:43  iter: 1839  total_loss: 3.636  loss_cls_stage0: 0.2214  loss_box_reg_stage0: 0.5107  loss_cls_stage1: 0.2487  loss_box_reg_stage1: 0.8846  loss_cls_stage2: 0.2697  loss_box_reg_stage2: 0.9378  loss_mask: 0.2853  loss_rpn_cls: 0.0645  loss_rpn_loc: 0.2023  time: 2.2240  data_time: 0.0744  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:34:18 d2.utils.events]: \u001b[0m eta: 5:01:02  iter: 1859  total_loss: 3.633  loss_cls_stage0: 0.2426  loss_box_reg_stage0: 0.5134  loss_cls_stage1: 0.257  loss_box_reg_stage1: 0.9008  loss_cls_stage2: 0.2682  loss_box_reg_stage2: 0.8852  loss_mask: 0.2868  loss_rpn_cls: 0.06986  loss_rpn_loc: 0.2065  time: 2.2245  data_time: 0.0979  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:35:02 d2.utils.events]: \u001b[0m eta: 5:00:40  iter: 1879  total_loss: 3.55  loss_cls_stage0: 0.2237  loss_box_reg_stage0: 0.504  loss_cls_stage1: 0.2291  loss_box_reg_stage1: 0.9321  loss_cls_stage2: 0.2545  loss_box_reg_stage2: 0.9492  loss_mask: 0.2723  loss_rpn_cls: 0.06242  loss_rpn_loc: 0.152  time: 2.2245  data_time: 0.0675  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:35:49 d2.utils.events]: \u001b[0m eta: 5:00:30  iter: 1899  total_loss: 3.536  loss_cls_stage0: 0.2372  loss_box_reg_stage0: 0.5071  loss_cls_stage1: 0.2383  loss_box_reg_stage1: 0.8883  loss_cls_stage2: 0.2689  loss_box_reg_stage2: 0.9011  loss_mask: 0.2694  loss_rpn_cls: 0.05496  loss_rpn_loc: 0.1791  time: 2.2255  data_time: 0.1156  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:36:34 d2.utils.events]: \u001b[0m eta: 4:59:46  iter: 1919  total_loss: 3.71  loss_cls_stage0: 0.2551  loss_box_reg_stage0: 0.4992  loss_cls_stage1: 0.2641  loss_box_reg_stage1: 0.9506  loss_cls_stage2: 0.2768  loss_box_reg_stage2: 0.9627  loss_mask: 0.2635  loss_rpn_cls: 0.06836  loss_rpn_loc: 0.1957  time: 2.2258  data_time: 0.0729  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:37:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:37:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:37:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:37:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:37:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:37:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.3809 s/iter. Eval: 0.0186 s/iter. Total: 0.4010 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/29 03:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0015 s/iter. Inference: 0.3470 s/iter. Eval: 0.0486 s/iter. Total: 0.3973 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0018 s/iter. Inference: 0.3462 s/iter. Eval: 0.0480 s/iter. Total: 0.3962 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 03:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0020 s/iter. Inference: 0.3459 s/iter. Eval: 0.0507 s/iter. Total: 0.3988 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 03:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0023 s/iter. Inference: 0.3444 s/iter. Eval: 0.0516 s/iter. Total: 0.3985 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:37:43 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0024 s/iter. Inference: 0.3434 s/iter. Eval: 0.0541 s/iter. Total: 0.4001 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 03:37:48 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0025 s/iter. Inference: 0.3454 s/iter. Eval: 0.0584 s/iter. Total: 0.4064 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:37:53 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0025 s/iter. Inference: 0.3462 s/iter. Eval: 0.0607 s/iter. Total: 0.4095 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 03:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0025 s/iter. Inference: 0.3450 s/iter. Eval: 0.0584 s/iter. Total: 0.4061 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 03:38:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.301637 (0.407773 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:38:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.344906 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:38:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:38:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2881114579428136\n",
      "\u001b[32m[12/29 03:38:05 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.28811, better than last best score 0.28278 @ iteration 1209.\n",
      "\u001b[32m[12/29 03:38:13 d2.utils.events]: \u001b[0m eta: 4:58:31  iter: 1939  total_loss: 3.521  loss_cls_stage0: 0.2214  loss_box_reg_stage0: 0.5065  loss_cls_stage1: 0.2142  loss_box_reg_stage1: 0.9163  loss_cls_stage2: 0.2385  loss_box_reg_stage2: 0.976  loss_mask: 0.2714  loss_rpn_cls: 0.04949  loss_rpn_loc: 0.1779  time: 2.2249  data_time: 0.0567  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:38:57 d2.utils.events]: \u001b[0m eta: 4:57:48  iter: 1959  total_loss: 3.495  loss_cls_stage0: 0.2235  loss_box_reg_stage0: 0.4807  loss_cls_stage1: 0.2286  loss_box_reg_stage1: 0.8848  loss_cls_stage2: 0.2649  loss_box_reg_stage2: 0.9508  loss_mask: 0.2734  loss_rpn_cls: 0.05464  loss_rpn_loc: 0.183  time: 2.2245  data_time: 0.0636  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:39:43 d2.utils.events]: \u001b[0m eta: 4:57:21  iter: 1979  total_loss: 3.491  loss_cls_stage0: 0.2075  loss_box_reg_stage0: 0.4762  loss_cls_stage1: 0.2242  loss_box_reg_stage1: 0.8508  loss_cls_stage2: 0.2549  loss_box_reg_stage2: 0.8789  loss_mask: 0.2725  loss_rpn_cls: 0.07225  loss_rpn_loc: 0.1905  time: 2.2250  data_time: 0.1022  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:40:29 d2.utils.events]: \u001b[0m eta: 4:56:52  iter: 1999  total_loss: 3.717  loss_cls_stage0: 0.2404  loss_box_reg_stage0: 0.5079  loss_cls_stage1: 0.2668  loss_box_reg_stage1: 0.8892  loss_cls_stage2: 0.2816  loss_box_reg_stage2: 0.8766  loss_mask: 0.2723  loss_rpn_cls: 0.0695  loss_rpn_loc: 0.1987  time: 2.2260  data_time: 0.0949  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:41:15 d2.utils.events]: \u001b[0m eta: 4:56:47  iter: 2019  total_loss: 3.503  loss_cls_stage0: 0.2143  loss_box_reg_stage0: 0.4695  loss_cls_stage1: 0.2485  loss_box_reg_stage1: 0.8862  loss_cls_stage2: 0.2621  loss_box_reg_stage2: 0.8875  loss_mask: 0.2778  loss_rpn_cls: 0.06249  loss_rpn_loc: 0.1736  time: 2.2268  data_time: 0.1055  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:41:59 d2.utils.events]: \u001b[0m eta: 4:56:03  iter: 2039  total_loss: 3.556  loss_cls_stage0: 0.2327  loss_box_reg_stage0: 0.4968  loss_cls_stage1: 0.2387  loss_box_reg_stage1: 0.9054  loss_cls_stage2: 0.2481  loss_box_reg_stage2: 0.8976  loss_mask: 0.2968  loss_rpn_cls: 0.09106  loss_rpn_loc: 0.2309  time: 2.2263  data_time: 0.0891  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:42:44 d2.utils.events]: \u001b[0m eta: 4:55:30  iter: 2059  total_loss: 3.443  loss_cls_stage0: 0.2106  loss_box_reg_stage0: 0.4934  loss_cls_stage1: 0.2231  loss_box_reg_stage1: 0.8797  loss_cls_stage2: 0.2403  loss_box_reg_stage2: 0.8953  loss_mask: 0.2743  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.191  time: 2.2265  data_time: 0.0703  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:43:29 d2.utils.events]: \u001b[0m eta: 4:54:45  iter: 2079  total_loss: 3.614  loss_cls_stage0: 0.2163  loss_box_reg_stage0: 0.487  loss_cls_stage1: 0.252  loss_box_reg_stage1: 0.8963  loss_cls_stage2: 0.2574  loss_box_reg_stage2: 0.8922  loss_mask: 0.2903  loss_rpn_cls: 0.06434  loss_rpn_loc: 0.1736  time: 2.2271  data_time: 0.0824  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:44:15 d2.utils.events]: \u001b[0m eta: 4:54:01  iter: 2099  total_loss: 3.62  loss_cls_stage0: 0.2192  loss_box_reg_stage0: 0.5013  loss_cls_stage1: 0.238  loss_box_reg_stage1: 0.9285  loss_cls_stage2: 0.263  loss_box_reg_stage2: 0.964  loss_mask: 0.2795  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.1835  time: 2.2277  data_time: 0.0739  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:44:59 d2.utils.events]: \u001b[0m eta: 4:53:16  iter: 2119  total_loss: 3.636  loss_cls_stage0: 0.2277  loss_box_reg_stage0: 0.5016  loss_cls_stage1: 0.2354  loss_box_reg_stage1: 0.8762  loss_cls_stage2: 0.2462  loss_box_reg_stage2: 0.9109  loss_mask: 0.2864  loss_rpn_cls: 0.05889  loss_rpn_loc: 0.1954  time: 2.2273  data_time: 0.0798  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:45:44 d2.utils.events]: \u001b[0m eta: 4:52:37  iter: 2139  total_loss: 3.724  loss_cls_stage0: 0.2359  loss_box_reg_stage0: 0.5095  loss_cls_stage1: 0.2616  loss_box_reg_stage1: 0.8968  loss_cls_stage2: 0.292  loss_box_reg_stage2: 0.8603  loss_mask: 0.2744  loss_rpn_cls: 0.07401  loss_rpn_loc: 0.1929  time: 2.2277  data_time: 0.0812  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:46:28 d2.utils.events]: \u001b[0m eta: 4:51:49  iter: 2159  total_loss: 3.525  loss_cls_stage0: 0.23  loss_box_reg_stage0: 0.5198  loss_cls_stage1: 0.2567  loss_box_reg_stage1: 0.8696  loss_cls_stage2: 0.2475  loss_box_reg_stage2: 0.9057  loss_mask: 0.3029  loss_rpn_cls: 0.05906  loss_rpn_loc: 0.1943  time: 2.2270  data_time: 0.0798  lr: 0.0005  max_mem: 28837M\n",
      "\u001b[32m[12/29 03:47:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:47:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:47:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:47:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:47:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:47:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0011 s/iter. Inference: 0.3478 s/iter. Eval: 0.0195 s/iter. Total: 0.3684 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 03:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0015 s/iter. Inference: 0.3461 s/iter. Eval: 0.0430 s/iter. Total: 0.3908 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 03:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0018 s/iter. Inference: 0.3535 s/iter. Eval: 0.0475 s/iter. Total: 0.4030 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 03:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0022 s/iter. Inference: 0.3492 s/iter. Eval: 0.0500 s/iter. Total: 0.4015 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 03:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0023 s/iter. Inference: 0.3509 s/iter. Eval: 0.0482 s/iter. Total: 0.4017 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0024 s/iter. Inference: 0.3471 s/iter. Eval: 0.0515 s/iter. Total: 0.4012 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 03:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0024 s/iter. Inference: 0.3459 s/iter. Eval: 0.0566 s/iter. Total: 0.4052 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 03:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0024 s/iter. Inference: 0.3450 s/iter. Eval: 0.0600 s/iter. Total: 0.4076 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 03:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0024 s/iter. Inference: 0.3433 s/iter. Eval: 0.0574 s/iter. Total: 0.4034 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 03:48:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.782486 (0.403297 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:48:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.342356 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:48:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:48:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2855578685070699\n",
      "\u001b[32m[12/29 03:48:02 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.28556, not better than best score 0.28811 @ iteration 1935.\n",
      "\u001b[32m[12/29 03:48:06 d2.utils.events]: \u001b[0m eta: 4:51:05  iter: 2179  total_loss: 3.594  loss_cls_stage0: 0.2254  loss_box_reg_stage0: 0.4925  loss_cls_stage1: 0.2571  loss_box_reg_stage1: 0.9113  loss_cls_stage2: 0.2702  loss_box_reg_stage2: 0.8886  loss_mask: 0.2899  loss_rpn_cls: 0.06488  loss_rpn_loc: 0.2073  time: 2.2274  data_time: 0.0918  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:48:50 d2.utils.events]: \u001b[0m eta: 4:50:46  iter: 2199  total_loss: 3.486  loss_cls_stage0: 0.2185  loss_box_reg_stage0: 0.4832  loss_cls_stage1: 0.2434  loss_box_reg_stage1: 0.8751  loss_cls_stage2: 0.2673  loss_box_reg_stage2: 0.9051  loss_mask: 0.2759  loss_rpn_cls: 0.04464  loss_rpn_loc: 0.1685  time: 2.2273  data_time: 0.0684  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:49:34 d2.utils.events]: \u001b[0m eta: 4:49:45  iter: 2219  total_loss: 3.56  loss_cls_stage0: 0.2153  loss_box_reg_stage0: 0.4873  loss_cls_stage1: 0.2326  loss_box_reg_stage1: 0.9203  loss_cls_stage2: 0.2625  loss_box_reg_stage2: 0.929  loss_mask: 0.2907  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1891  time: 2.2269  data_time: 0.0835  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:50:16 d2.utils.events]: \u001b[0m eta: 4:48:48  iter: 2239  total_loss: 3.573  loss_cls_stage0: 0.2065  loss_box_reg_stage0: 0.4924  loss_cls_stage1: 0.2286  loss_box_reg_stage1: 0.9002  loss_cls_stage2: 0.2565  loss_box_reg_stage2: 0.9189  loss_mask: 0.2844  loss_rpn_cls: 0.07705  loss_rpn_loc: 0.1885  time: 2.2258  data_time: 0.0689  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:50:56 d2.utils.events]: \u001b[0m eta: 4:47:36  iter: 2259  total_loss: 3.477  loss_cls_stage0: 0.2048  loss_box_reg_stage0: 0.4754  loss_cls_stage1: 0.2127  loss_box_reg_stage1: 0.8993  loss_cls_stage2: 0.2248  loss_box_reg_stage2: 1.006  loss_mask: 0.2777  loss_rpn_cls: 0.0711  loss_rpn_loc: 0.1537  time: 2.2241  data_time: 0.0490  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:51:39 d2.utils.events]: \u001b[0m eta: 4:46:24  iter: 2279  total_loss: 3.612  loss_cls_stage0: 0.2078  loss_box_reg_stage0: 0.4928  loss_cls_stage1: 0.218  loss_box_reg_stage1: 0.8885  loss_cls_stage2: 0.2558  loss_box_reg_stage2: 0.8713  loss_mask: 0.2819  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.1916  time: 2.2233  data_time: 0.0883  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:52:23 d2.utils.events]: \u001b[0m eta: 4:45:50  iter: 2299  total_loss: 3.54  loss_cls_stage0: 0.2334  loss_box_reg_stage0: 0.4814  loss_cls_stage1: 0.2435  loss_box_reg_stage1: 0.8359  loss_cls_stage2: 0.2573  loss_box_reg_stage2: 0.9055  loss_mask: 0.2773  loss_rpn_cls: 0.08197  loss_rpn_loc: 0.1989  time: 2.2230  data_time: 0.0805  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:53:07 d2.utils.events]: \u001b[0m eta: 4:44:59  iter: 2319  total_loss: 3.488  loss_cls_stage0: 0.2201  loss_box_reg_stage0: 0.4818  loss_cls_stage1: 0.2217  loss_box_reg_stage1: 0.8322  loss_cls_stage2: 0.2451  loss_box_reg_stage2: 0.9075  loss_mask: 0.2831  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.2066  time: 2.2227  data_time: 0.1019  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:53:52 d2.utils.events]: \u001b[0m eta: 4:43:57  iter: 2339  total_loss: 3.609  loss_cls_stage0: 0.1979  loss_box_reg_stage0: 0.5001  loss_cls_stage1: 0.2278  loss_box_reg_stage1: 0.8896  loss_cls_stage2: 0.2707  loss_box_reg_stage2: 0.9193  loss_mask: 0.2817  loss_rpn_cls: 0.08703  loss_rpn_loc: 0.1851  time: 2.2229  data_time: 0.0814  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:54:39 d2.utils.events]: \u001b[0m eta: 4:43:54  iter: 2359  total_loss: 3.557  loss_cls_stage0: 0.2223  loss_box_reg_stage0: 0.506  loss_cls_stage1: 0.2563  loss_box_reg_stage1: 0.8475  loss_cls_stage2: 0.2654  loss_box_reg_stage2: 0.8481  loss_mask: 0.296  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.1914  time: 2.2243  data_time: 0.1282  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:55:23 d2.utils.events]: \u001b[0m eta: 4:43:09  iter: 2379  total_loss: 3.534  loss_cls_stage0: 0.1907  loss_box_reg_stage0: 0.4853  loss_cls_stage1: 0.2117  loss_box_reg_stage1: 0.9401  loss_cls_stage2: 0.2502  loss_box_reg_stage2: 0.9285  loss_mask: 0.2823  loss_rpn_cls: 0.05813  loss_rpn_loc: 0.1633  time: 2.2239  data_time: 0.0816  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:56:09 d2.utils.events]: \u001b[0m eta: 4:42:47  iter: 2399  total_loss: 3.645  loss_cls_stage0: 0.2192  loss_box_reg_stage0: 0.5142  loss_cls_stage1: 0.2475  loss_box_reg_stage1: 0.8869  loss_cls_stage2: 0.2651  loss_box_reg_stage2: 0.8715  loss_mask: 0.2913  loss_rpn_cls: 0.08891  loss_rpn_loc: 0.202  time: 2.2247  data_time: 0.1291  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:56:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:56:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 03:56:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 03:56:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 03:56:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 03:56:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 03:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0019 s/iter. Inference: 0.3543 s/iter. Eval: 0.0200 s/iter. Total: 0.3761 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 03:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0016 s/iter. Inference: 0.3397 s/iter. Eval: 0.0521 s/iter. Total: 0.3936 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 03:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0019 s/iter. Inference: 0.3422 s/iter. Eval: 0.0505 s/iter. Total: 0.3948 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 03:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0022 s/iter. Inference: 0.3489 s/iter. Eval: 0.0526 s/iter. Total: 0.4039 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 03:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0023 s/iter. Inference: 0.3475 s/iter. Eval: 0.0506 s/iter. Total: 0.4006 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 03:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0024 s/iter. Inference: 0.3494 s/iter. Eval: 0.0526 s/iter. Total: 0.4046 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 03:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0025 s/iter. Inference: 0.3477 s/iter. Eval: 0.0599 s/iter. Total: 0.4103 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 03:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0025 s/iter. Inference: 0.3447 s/iter. Eval: 0.0629 s/iter. Total: 0.4103 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 03:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0025 s/iter. Inference: 0.3421 s/iter. Eval: 0.0601 s/iter. Total: 0.4048 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 03:57:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.968997 (0.404905 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:57:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.341249 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 03:57:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 03:57:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2796784782813482\n",
      "\u001b[32m[12/29 03:57:46 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.27968, not better than best score 0.28811 @ iteration 1935.\n",
      "\u001b[32m[12/29 03:57:46 d2.utils.events]: \u001b[0m eta: 4:42:02  iter: 2419  total_loss: 3.682  loss_cls_stage0: 0.2437  loss_box_reg_stage0: 0.5052  loss_cls_stage1: 0.2693  loss_box_reg_stage1: 0.8974  loss_cls_stage2: 0.2739  loss_box_reg_stage2: 0.8532  loss_mask: 0.2854  loss_rpn_cls: 0.07175  loss_rpn_loc: 0.1816  time: 2.2244  data_time: 0.0930  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:58:33 d2.utils.events]: \u001b[0m eta: 4:41:24  iter: 2439  total_loss: 3.457  loss_cls_stage0: 0.2276  loss_box_reg_stage0: 0.4829  loss_cls_stage1: 0.2302  loss_box_reg_stage1: 0.8501  loss_cls_stage2: 0.257  loss_box_reg_stage2: 0.9106  loss_mask: 0.2831  loss_rpn_cls: 0.05289  loss_rpn_loc: 0.1943  time: 2.2253  data_time: 0.1000  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 03:59:17 d2.utils.events]: \u001b[0m eta: 4:40:28  iter: 2459  total_loss: 3.542  loss_cls_stage0: 0.2218  loss_box_reg_stage0: 0.476  loss_cls_stage1: 0.2405  loss_box_reg_stage1: 0.8772  loss_cls_stage2: 0.2608  loss_box_reg_stage2: 0.864  loss_mask: 0.2611  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.1867  time: 2.2251  data_time: 0.0780  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:00:01 d2.utils.events]: \u001b[0m eta: 4:39:26  iter: 2479  total_loss: 3.363  loss_cls_stage0: 0.2079  loss_box_reg_stage0: 0.4591  loss_cls_stage1: 0.2177  loss_box_reg_stage1: 0.8525  loss_cls_stage2: 0.2304  loss_box_reg_stage2: 1.014  loss_mask: 0.2651  loss_rpn_cls: 0.0579  loss_rpn_loc: 0.165  time: 2.2247  data_time: 0.0679  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:00:44 d2.utils.events]: \u001b[0m eta: 4:38:48  iter: 2499  total_loss: 3.469  loss_cls_stage0: 0.223  loss_box_reg_stage0: 0.4803  loss_cls_stage1: 0.2376  loss_box_reg_stage1: 0.8771  loss_cls_stage2: 0.2551  loss_box_reg_stage2: 0.8561  loss_mask: 0.2897  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.1872  time: 2.2243  data_time: 0.0820  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:01:28 d2.utils.events]: \u001b[0m eta: 4:37:57  iter: 2519  total_loss: 3.561  loss_cls_stage0: 0.1927  loss_box_reg_stage0: 0.4721  loss_cls_stage1: 0.2047  loss_box_reg_stage1: 0.9246  loss_cls_stage2: 0.2421  loss_box_reg_stage2: 0.9364  loss_mask: 0.276  loss_rpn_cls: 0.04935  loss_rpn_loc: 0.1503  time: 2.2241  data_time: 0.0666  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:02:14 d2.utils.events]: \u001b[0m eta: 4:37:04  iter: 2539  total_loss: 3.503  loss_cls_stage0: 0.2097  loss_box_reg_stage0: 0.473  loss_cls_stage1: 0.2282  loss_box_reg_stage1: 0.8766  loss_cls_stage2: 0.2439  loss_box_reg_stage2: 0.894  loss_mask: 0.2801  loss_rpn_cls: 0.07285  loss_rpn_loc: 0.1966  time: 2.2247  data_time: 0.1418  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:02:58 d2.utils.events]: \u001b[0m eta: 4:36:07  iter: 2559  total_loss: 3.589  loss_cls_stage0: 0.2078  loss_box_reg_stage0: 0.494  loss_cls_stage1: 0.2246  loss_box_reg_stage1: 0.9105  loss_cls_stage2: 0.2499  loss_box_reg_stage2: 0.9439  loss_mask: 0.2835  loss_rpn_cls: 0.05238  loss_rpn_loc: 0.1578  time: 2.2244  data_time: 0.0645  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:03:43 d2.utils.events]: \u001b[0m eta: 4:35:22  iter: 2579  total_loss: 3.622  loss_cls_stage0: 0.2187  loss_box_reg_stage0: 0.4986  loss_cls_stage1: 0.2332  loss_box_reg_stage1: 0.8851  loss_cls_stage2: 0.2477  loss_box_reg_stage2: 0.9302  loss_mask: 0.2783  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.1861  time: 2.2246  data_time: 0.0904  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:04:26 d2.utils.events]: \u001b[0m eta: 4:34:42  iter: 2599  total_loss: 3.598  loss_cls_stage0: 0.2095  loss_box_reg_stage0: 0.4911  loss_cls_stage1: 0.2378  loss_box_reg_stage1: 0.8567  loss_cls_stage2: 0.2476  loss_box_reg_stage2: 0.8436  loss_mask: 0.3008  loss_rpn_cls: 0.07716  loss_rpn_loc: 0.1868  time: 2.2243  data_time: 0.0978  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:05:10 d2.utils.events]: \u001b[0m eta: 4:33:48  iter: 2619  total_loss: 3.675  loss_cls_stage0: 0.2295  loss_box_reg_stage0: 0.5065  loss_cls_stage1: 0.2417  loss_box_reg_stage1: 0.9189  loss_cls_stage2: 0.267  loss_box_reg_stage2: 0.9595  loss_mask: 0.2689  loss_rpn_cls: 0.07246  loss_rpn_loc: 0.1728  time: 2.2237  data_time: 0.0758  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:05:54 d2.utils.events]: \u001b[0m eta: 4:33:00  iter: 2639  total_loss: 3.616  loss_cls_stage0: 0.1932  loss_box_reg_stage0: 0.4989  loss_cls_stage1: 0.2194  loss_box_reg_stage1: 0.8948  loss_cls_stage2: 0.2451  loss_box_reg_stage2: 0.9169  loss_mask: 0.2815  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.1897  time: 2.2237  data_time: 0.0754  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:06:38 d2.utils.events]: \u001b[0m eta: 4:31:55  iter: 2659  total_loss: 3.838  loss_cls_stage0: 0.2471  loss_box_reg_stage0: 0.5312  loss_cls_stage1: 0.2657  loss_box_reg_stage1: 0.9546  loss_cls_stage2: 0.2787  loss_box_reg_stage2: 0.8713  loss_mask: 0.292  loss_rpn_cls: 0.08431  loss_rpn_loc: 0.2287  time: 2.2237  data_time: 0.0968  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:06:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:06:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:06:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:06:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:06:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:06:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0039 s/iter. Inference: 0.3397 s/iter. Eval: 0.0233 s/iter. Total: 0.3669 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 04:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0026 s/iter. Inference: 0.3412 s/iter. Eval: 0.0524 s/iter. Total: 0.3965 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0027 s/iter. Inference: 0.3437 s/iter. Eval: 0.0514 s/iter. Total: 0.3980 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 04:07:07 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0028 s/iter. Inference: 0.3459 s/iter. Eval: 0.0546 s/iter. Total: 0.4035 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 04:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0028 s/iter. Inference: 0.3467 s/iter. Eval: 0.0521 s/iter. Total: 0.4019 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 04:07:17 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0028 s/iter. Inference: 0.3479 s/iter. Eval: 0.0538 s/iter. Total: 0.4047 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 04:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0028 s/iter. Inference: 0.3470 s/iter. Eval: 0.0636 s/iter. Total: 0.4137 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 04:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0028 s/iter. Inference: 0.3457 s/iter. Eval: 0.0665 s/iter. Total: 0.4152 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 04:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0027 s/iter. Inference: 0.3436 s/iter. Eval: 0.0628 s/iter. Total: 0.4094 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 04:07:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.716870 (0.411352 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:07:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.345068 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:07:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:07:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.293602280588684\n",
      "\u001b[32m[12/29 04:07:39 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.29360, better than last best score 0.28811 @ iteration 1935.\n",
      "\u001b[32m[12/29 04:08:20 d2.utils.events]: \u001b[0m eta: 4:31:36  iter: 2679  total_loss: 3.493  loss_cls_stage0: 0.1938  loss_box_reg_stage0: 0.4842  loss_cls_stage1: 0.2134  loss_box_reg_stage1: 0.8797  loss_cls_stage2: 0.2524  loss_box_reg_stage2: 0.9293  loss_mask: 0.289  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.1798  time: 2.2240  data_time: 0.0905  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:09:07 d2.utils.events]: \u001b[0m eta: 4:30:59  iter: 2699  total_loss: 3.387  loss_cls_stage0: 0.2004  loss_box_reg_stage0: 0.4527  loss_cls_stage1: 0.203  loss_box_reg_stage1: 0.8626  loss_cls_stage2: 0.2257  loss_box_reg_stage2: 0.9207  loss_mask: 0.2674  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.1993  time: 2.2248  data_time: 0.0982  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:09:53 d2.utils.events]: \u001b[0m eta: 4:30:07  iter: 2719  total_loss: 3.649  loss_cls_stage0: 0.2133  loss_box_reg_stage0: 0.4721  loss_cls_stage1: 0.2344  loss_box_reg_stage1: 0.9139  loss_cls_stage2: 0.2683  loss_box_reg_stage2: 0.9569  loss_mask: 0.2755  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.1951  time: 2.2256  data_time: 0.0682  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:10:37 d2.utils.events]: \u001b[0m eta: 4:29:14  iter: 2739  total_loss: 3.477  loss_cls_stage0: 0.2443  loss_box_reg_stage0: 0.4805  loss_cls_stage1: 0.2611  loss_box_reg_stage1: 0.8795  loss_cls_stage2: 0.2696  loss_box_reg_stage2: 0.8791  loss_mask: 0.2642  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.2122  time: 2.2254  data_time: 0.0704  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:11:22 d2.utils.events]: \u001b[0m eta: 4:28:46  iter: 2759  total_loss: 3.647  loss_cls_stage0: 0.2362  loss_box_reg_stage0: 0.511  loss_cls_stage1: 0.247  loss_box_reg_stage1: 0.9154  loss_cls_stage2: 0.265  loss_box_reg_stage2: 0.9515  loss_mask: 0.299  loss_rpn_cls: 0.07117  loss_rpn_loc: 0.1867  time: 2.2256  data_time: 0.0845  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:12:07 d2.utils.events]: \u001b[0m eta: 4:27:50  iter: 2779  total_loss: 3.559  loss_cls_stage0: 0.2051  loss_box_reg_stage0: 0.4833  loss_cls_stage1: 0.2146  loss_box_reg_stage1: 0.8952  loss_cls_stage2: 0.252  loss_box_reg_stage2: 0.8953  loss_mask: 0.2853  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.2379  time: 2.2254  data_time: 0.0818  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:12:53 d2.utils.events]: \u001b[0m eta: 4:27:36  iter: 2799  total_loss: 3.356  loss_cls_stage0: 0.2307  loss_box_reg_stage0: 0.4777  loss_cls_stage1: 0.2368  loss_box_reg_stage1: 0.8395  loss_cls_stage2: 0.2466  loss_box_reg_stage2: 0.9022  loss_mask: 0.2895  loss_rpn_cls: 0.06977  loss_rpn_loc: 0.1961  time: 2.2260  data_time: 0.1124  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:13:35 d2.utils.events]: \u001b[0m eta: 4:26:26  iter: 2819  total_loss: 3.621  loss_cls_stage0: 0.2082  loss_box_reg_stage0: 0.4819  loss_cls_stage1: 0.2366  loss_box_reg_stage1: 0.91  loss_cls_stage2: 0.2717  loss_box_reg_stage2: 0.9149  loss_mask: 0.2778  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.196  time: 2.2253  data_time: 0.0742  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:14:19 d2.utils.events]: \u001b[0m eta: 4:25:55  iter: 2839  total_loss: 3.694  loss_cls_stage0: 0.2275  loss_box_reg_stage0: 0.4875  loss_cls_stage1: 0.2584  loss_box_reg_stage1: 0.9274  loss_cls_stage2: 0.2792  loss_box_reg_stage2: 0.8535  loss_mask: 0.2828  loss_rpn_cls: 0.08107  loss_rpn_loc: 0.2038  time: 2.2252  data_time: 0.0788  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:15:04 d2.utils.events]: \u001b[0m eta: 4:25:16  iter: 2859  total_loss: 3.468  loss_cls_stage0: 0.2133  loss_box_reg_stage0: 0.484  loss_cls_stage1: 0.2373  loss_box_reg_stage1: 0.875  loss_cls_stage2: 0.2626  loss_box_reg_stage2: 0.8903  loss_mask: 0.2825  loss_rpn_cls: 0.07179  loss_rpn_loc: 0.1701  time: 2.2253  data_time: 0.0956  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:15:48 d2.utils.events]: \u001b[0m eta: 4:24:15  iter: 2879  total_loss: 3.377  loss_cls_stage0: 0.1891  loss_box_reg_stage0: 0.4663  loss_cls_stage1: 0.2093  loss_box_reg_stage1: 0.8877  loss_cls_stage2: 0.2306  loss_box_reg_stage2: 0.8856  loss_mask: 0.2769  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.1783  time: 2.2250  data_time: 0.0690  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:16:31 d2.utils.events]: \u001b[0m eta: 4:22:59  iter: 2899  total_loss: 3.619  loss_cls_stage0: 0.2144  loss_box_reg_stage0: 0.5026  loss_cls_stage1: 0.2285  loss_box_reg_stage1: 0.951  loss_cls_stage2: 0.2593  loss_box_reg_stage2: 0.993  loss_mask: 0.2732  loss_rpn_cls: 0.04802  loss_rpn_loc: 0.1821  time: 2.2245  data_time: 0.0661  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:16:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:16:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:16:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:16:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:16:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:16:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0018 s/iter. Inference: 0.3293 s/iter. Eval: 0.0202 s/iter. Total: 0.3513 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0017 s/iter. Inference: 0.3431 s/iter. Eval: 0.0480 s/iter. Total: 0.3930 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0020 s/iter. Inference: 0.3553 s/iter. Eval: 0.0493 s/iter. Total: 0.4067 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 04:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0026 s/iter. Inference: 0.3543 s/iter. Eval: 0.0504 s/iter. Total: 0.4076 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 04:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0026 s/iter. Inference: 0.3498 s/iter. Eval: 0.0506 s/iter. Total: 0.4032 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 04:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0026 s/iter. Inference: 0.3484 s/iter. Eval: 0.0532 s/iter. Total: 0.4044 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 04:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0026 s/iter. Inference: 0.3494 s/iter. Eval: 0.0571 s/iter. Total: 0.4093 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 04:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0029 s/iter. Inference: 0.3495 s/iter. Eval: 0.0596 s/iter. Total: 0.4122 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 04:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0029 s/iter. Inference: 0.3480 s/iter. Eval: 0.0580 s/iter. Total: 0.4091 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 04:17:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.621871 (0.410533 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:17:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.348128 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:17:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:17:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28837529067898265\n",
      "\u001b[32m[12/29 04:17:32 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.28838, not better than best score 0.29360 @ iteration 2661.\n",
      "\u001b[32m[12/29 04:18:09 d2.utils.events]: \u001b[0m eta: 4:22:14  iter: 2919  total_loss: 3.523  loss_cls_stage0: 0.2126  loss_box_reg_stage0: 0.4951  loss_cls_stage1: 0.2329  loss_box_reg_stage1: 0.8565  loss_cls_stage2: 0.2558  loss_box_reg_stage2: 0.8487  loss_mask: 0.3063  loss_rpn_cls: 0.08293  loss_rpn_loc: 0.1982  time: 2.2247  data_time: 0.0982  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:18:55 d2.utils.events]: \u001b[0m eta: 4:21:51  iter: 2939  total_loss: 3.612  loss_cls_stage0: 0.2245  loss_box_reg_stage0: 0.5123  loss_cls_stage1: 0.2347  loss_box_reg_stage1: 0.8917  loss_cls_stage2: 0.2705  loss_box_reg_stage2: 0.8933  loss_mask: 0.2671  loss_rpn_cls: 0.05576  loss_rpn_loc: 0.1954  time: 2.2251  data_time: 0.0810  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:19:41 d2.utils.events]: \u001b[0m eta: 4:21:28  iter: 2959  total_loss: 3.507  loss_cls_stage0: 0.2089  loss_box_reg_stage0: 0.469  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.8884  loss_cls_stage2: 0.2626  loss_box_reg_stage2: 0.9716  loss_mask: 0.2755  loss_rpn_cls: 0.06489  loss_rpn_loc: 0.1802  time: 2.2255  data_time: 0.0865  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:20:27 d2.utils.events]: \u001b[0m eta: 4:20:43  iter: 2979  total_loss: 3.677  loss_cls_stage0: 0.2242  loss_box_reg_stage0: 0.4892  loss_cls_stage1: 0.2482  loss_box_reg_stage1: 0.8901  loss_cls_stage2: 0.2615  loss_box_reg_stage2: 0.9553  loss_mask: 0.2781  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.193  time: 2.2260  data_time: 0.0829  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:21:11 d2.utils.events]: \u001b[0m eta: 4:19:40  iter: 2999  total_loss: 3.514  loss_cls_stage0: 0.2197  loss_box_reg_stage0: 0.4729  loss_cls_stage1: 0.2539  loss_box_reg_stage1: 0.8597  loss_cls_stage2: 0.2686  loss_box_reg_stage2: 0.9067  loss_mask: 0.2811  loss_rpn_cls: 0.08084  loss_rpn_loc: 0.2291  time: 2.2261  data_time: 0.0873  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:21:56 d2.utils.events]: \u001b[0m eta: 4:18:53  iter: 3019  total_loss: 3.462  loss_cls_stage0: 0.1923  loss_box_reg_stage0: 0.4739  loss_cls_stage1: 0.2137  loss_box_reg_stage1: 0.8902  loss_cls_stage2: 0.2349  loss_box_reg_stage2: 0.914  loss_mask: 0.2712  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1841  time: 2.2262  data_time: 0.0863  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:22:41 d2.utils.events]: \u001b[0m eta: 4:18:35  iter: 3039  total_loss: 3.56  loss_cls_stage0: 0.2431  loss_box_reg_stage0: 0.4756  loss_cls_stage1: 0.2554  loss_box_reg_stage1: 0.8471  loss_cls_stage2: 0.2611  loss_box_reg_stage2: 0.9254  loss_mask: 0.2616  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.17  time: 2.2262  data_time: 0.0979  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:23:24 d2.utils.events]: \u001b[0m eta: 4:17:34  iter: 3059  total_loss: 3.665  loss_cls_stage0: 0.2054  loss_box_reg_stage0: 0.4829  loss_cls_stage1: 0.2179  loss_box_reg_stage1: 0.9055  loss_cls_stage2: 0.2467  loss_box_reg_stage2: 0.9433  loss_mask: 0.2704  loss_rpn_cls: 0.05218  loss_rpn_loc: 0.1597  time: 2.2257  data_time: 0.0595  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:24:09 d2.utils.events]: \u001b[0m eta: 4:16:42  iter: 3079  total_loss: 3.635  loss_cls_stage0: 0.2152  loss_box_reg_stage0: 0.5053  loss_cls_stage1: 0.2296  loss_box_reg_stage1: 0.9274  loss_cls_stage2: 0.2546  loss_box_reg_stage2: 0.9264  loss_mask: 0.2862  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.1921  time: 2.2260  data_time: 0.0789  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:24:57 d2.utils.events]: \u001b[0m eta: 4:16:33  iter: 3099  total_loss: 3.557  loss_cls_stage0: 0.2258  loss_box_reg_stage0: 0.4846  loss_cls_stage1: 0.2431  loss_box_reg_stage1: 0.8984  loss_cls_stage2: 0.2733  loss_box_reg_stage2: 0.8983  loss_mask: 0.2877  loss_rpn_cls: 0.0823  loss_rpn_loc: 0.1996  time: 2.2271  data_time: 0.1445  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:25:42 d2.utils.events]: \u001b[0m eta: 4:15:49  iter: 3119  total_loss: 3.581  loss_cls_stage0: 0.2189  loss_box_reg_stage0: 0.4932  loss_cls_stage1: 0.2622  loss_box_reg_stage1: 0.9018  loss_cls_stage2: 0.2733  loss_box_reg_stage2: 0.9493  loss_mask: 0.3014  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.2012  time: 2.2272  data_time: 0.1025  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:26:26 d2.utils.events]: \u001b[0m eta: 4:15:04  iter: 3139  total_loss: 3.555  loss_cls_stage0: 0.2157  loss_box_reg_stage0: 0.4858  loss_cls_stage1: 0.2337  loss_box_reg_stage1: 0.8917  loss_cls_stage2: 0.2445  loss_box_reg_stage2: 0.9541  loss_mask: 0.2781  loss_rpn_cls: 0.06675  loss_rpn_loc: 0.1816  time: 2.2269  data_time: 0.0721  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:26:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:26:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:26:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:26:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:26:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:26:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0023 s/iter. Inference: 0.3224 s/iter. Eval: 0.0221 s/iter. Total: 0.3468 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:26:52 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0019 s/iter. Inference: 0.3316 s/iter. Eval: 0.0520 s/iter. Total: 0.3857 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0021 s/iter. Inference: 0.3401 s/iter. Eval: 0.0526 s/iter. Total: 0.3951 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 04:27:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0023 s/iter. Inference: 0.3443 s/iter. Eval: 0.0549 s/iter. Total: 0.4017 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 04:27:07 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0023 s/iter. Inference: 0.3473 s/iter. Eval: 0.0528 s/iter. Total: 0.4026 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 04:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0025 s/iter. Inference: 0.3471 s/iter. Eval: 0.0563 s/iter. Total: 0.4061 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 04:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0025 s/iter. Inference: 0.3480 s/iter. Eval: 0.0624 s/iter. Total: 0.4131 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/29 04:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0025 s/iter. Inference: 0.3493 s/iter. Eval: 0.0653 s/iter. Total: 0.4173 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/29 04:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0025 s/iter. Inference: 0.3477 s/iter. Eval: 0.0630 s/iter. Total: 0.4134 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/29 04:27:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.915289 (0.413063 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:27:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.346882 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:27:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:27:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.29360025093239644\n",
      "\u001b[32m[12/29 04:27:32 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29360, not better than best score 0.29360 @ iteration 2661.\n",
      "\u001b[32m[12/29 04:28:03 d2.utils.events]: \u001b[0m eta: 4:14:33  iter: 3159  total_loss: 3.497  loss_cls_stage0: 0.2117  loss_box_reg_stage0: 0.4867  loss_cls_stage1: 0.2376  loss_box_reg_stage1: 0.8685  loss_cls_stage2: 0.2552  loss_box_reg_stage2: 0.919  loss_mask: 0.2782  loss_rpn_cls: 0.05911  loss_rpn_loc: 0.1832  time: 2.2266  data_time: 0.0813  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:28:47 d2.utils.events]: \u001b[0m eta: 4:13:48  iter: 3179  total_loss: 3.706  loss_cls_stage0: 0.2369  loss_box_reg_stage0: 0.4871  loss_cls_stage1: 0.2626  loss_box_reg_stage1: 0.9214  loss_cls_stage2: 0.2734  loss_box_reg_stage2: 0.9265  loss_mask: 0.2829  loss_rpn_cls: 0.05728  loss_rpn_loc: 0.1987  time: 2.2266  data_time: 0.0935  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:29:33 d2.utils.events]: \u001b[0m eta: 4:13:04  iter: 3199  total_loss: 3.319  loss_cls_stage0: 0.2062  loss_box_reg_stage0: 0.4705  loss_cls_stage1: 0.2344  loss_box_reg_stage1: 0.8377  loss_cls_stage2: 0.2448  loss_box_reg_stage2: 0.9347  loss_mask: 0.2802  loss_rpn_cls: 0.05365  loss_rpn_loc: 0.1551  time: 2.2268  data_time: 0.0742  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:30:18 d2.utils.events]: \u001b[0m eta: 4:12:19  iter: 3219  total_loss: 3.425  loss_cls_stage0: 0.2115  loss_box_reg_stage0: 0.5102  loss_cls_stage1: 0.2302  loss_box_reg_stage1: 0.8621  loss_cls_stage2: 0.2517  loss_box_reg_stage2: 0.8112  loss_mask: 0.2864  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1731  time: 2.2271  data_time: 0.1039  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:31:02 d2.utils.events]: \u001b[0m eta: 4:11:47  iter: 3239  total_loss: 3.596  loss_cls_stage0: 0.2331  loss_box_reg_stage0: 0.4812  loss_cls_stage1: 0.2441  loss_box_reg_stage1: 0.8995  loss_cls_stage2: 0.2635  loss_box_reg_stage2: 0.9101  loss_mask: 0.2694  loss_rpn_cls: 0.07324  loss_rpn_loc: 0.1974  time: 2.2269  data_time: 0.0972  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:31:48 d2.utils.events]: \u001b[0m eta: 4:11:53  iter: 3259  total_loss: 3.536  loss_cls_stage0: 0.2183  loss_box_reg_stage0: 0.496  loss_cls_stage1: 0.233  loss_box_reg_stage1: 0.8622  loss_cls_stage2: 0.2618  loss_box_reg_stage2: 0.9285  loss_mask: 0.2929  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.206  time: 2.2274  data_time: 0.1087  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:32:32 d2.utils.events]: \u001b[0m eta: 4:11:19  iter: 3279  total_loss: 3.513  loss_cls_stage0: 0.2095  loss_box_reg_stage0: 0.4858  loss_cls_stage1: 0.2196  loss_box_reg_stage1: 0.8887  loss_cls_stage2: 0.2553  loss_box_reg_stage2: 0.9232  loss_mask: 0.2769  loss_rpn_cls: 0.05006  loss_rpn_loc: 0.1557  time: 2.2272  data_time: 0.0639  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:33:16 d2.utils.events]: \u001b[0m eta: 4:10:39  iter: 3299  total_loss: 3.447  loss_cls_stage0: 0.1979  loss_box_reg_stage0: 0.4525  loss_cls_stage1: 0.2032  loss_box_reg_stage1: 0.9149  loss_cls_stage2: 0.2188  loss_box_reg_stage2: 1.035  loss_mask: 0.2731  loss_rpn_cls: 0.05663  loss_rpn_loc: 0.1574  time: 2.2269  data_time: 0.0774  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:34:00 d2.utils.events]: \u001b[0m eta: 4:10:00  iter: 3319  total_loss: 3.512  loss_cls_stage0: 0.2199  loss_box_reg_stage0: 0.4785  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.8596  loss_cls_stage2: 0.2628  loss_box_reg_stage2: 0.9231  loss_mask: 0.2841  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.2077  time: 2.2267  data_time: 0.0780  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:34:46 d2.utils.events]: \u001b[0m eta: 4:09:23  iter: 3339  total_loss: 3.647  loss_cls_stage0: 0.2207  loss_box_reg_stage0: 0.5078  loss_cls_stage1: 0.252  loss_box_reg_stage1: 0.8903  loss_cls_stage2: 0.2678  loss_box_reg_stage2: 0.9527  loss_mask: 0.2704  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1873  time: 2.2273  data_time: 0.0950  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:35:30 d2.utils.events]: \u001b[0m eta: 4:08:25  iter: 3359  total_loss: 3.491  loss_cls_stage0: 0.2086  loss_box_reg_stage0: 0.461  loss_cls_stage1: 0.2218  loss_box_reg_stage1: 0.8754  loss_cls_stage2: 0.2496  loss_box_reg_stage2: 0.8873  loss_mask: 0.2882  loss_rpn_cls: 0.05429  loss_rpn_loc: 0.1622  time: 2.2271  data_time: 0.0790  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:36:15 d2.utils.events]: \u001b[0m eta: 4:07:48  iter: 3379  total_loss: 3.539  loss_cls_stage0: 0.2116  loss_box_reg_stage0: 0.475  loss_cls_stage1: 0.2335  loss_box_reg_stage1: 0.8334  loss_cls_stage2: 0.2483  loss_box_reg_stage2: 0.8916  loss_mask: 0.2833  loss_rpn_cls: 0.08417  loss_rpn_loc: 0.213  time: 2.2272  data_time: 0.0834  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:36:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:36:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:36:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:36:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:36:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:36:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0014 s/iter. Inference: 0.3253 s/iter. Eval: 0.0203 s/iter. Total: 0.3470 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 04:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0020 s/iter. Inference: 0.3409 s/iter. Eval: 0.0458 s/iter. Total: 0.3888 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0020 s/iter. Inference: 0.3418 s/iter. Eval: 0.0458 s/iter. Total: 0.3898 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 04:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0021 s/iter. Inference: 0.3456 s/iter. Eval: 0.0490 s/iter. Total: 0.3969 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 04:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0023 s/iter. Inference: 0.3430 s/iter. Eval: 0.0488 s/iter. Total: 0.3943 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 04:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0023 s/iter. Inference: 0.3429 s/iter. Eval: 0.0499 s/iter. Total: 0.3953 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 04:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0024 s/iter. Inference: 0.3434 s/iter. Eval: 0.0534 s/iter. Total: 0.3994 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 04:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0024 s/iter. Inference: 0.3423 s/iter. Eval: 0.0569 s/iter. Total: 0.4017 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 04:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0024 s/iter. Inference: 0.3404 s/iter. Eval: 0.0544 s/iter. Total: 0.3973 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 04:37:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.077444 (0.397219 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:37:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.339476 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:37:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:37:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.29109461989116997\n",
      "\u001b[32m[12/29 04:37:25 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29109, not better than best score 0.29360 @ iteration 2661.\n",
      "\u001b[32m[12/29 04:37:52 d2.utils.events]: \u001b[0m eta: 4:07:00  iter: 3399  total_loss: 3.588  loss_cls_stage0: 0.2236  loss_box_reg_stage0: 0.4978  loss_cls_stage1: 0.2348  loss_box_reg_stage1: 0.8731  loss_cls_stage2: 0.2553  loss_box_reg_stage2: 0.987  loss_mask: 0.2703  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.1771  time: 2.2275  data_time: 0.0772  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:38:37 d2.utils.events]: \u001b[0m eta: 4:06:25  iter: 3419  total_loss: 3.59  loss_cls_stage0: 0.2145  loss_box_reg_stage0: 0.4887  loss_cls_stage1: 0.2327  loss_box_reg_stage1: 0.9077  loss_cls_stage2: 0.2681  loss_box_reg_stage2: 0.9552  loss_mask: 0.2864  loss_rpn_cls: 0.0762  loss_rpn_loc: 0.1969  time: 2.2277  data_time: 0.0800  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:39:21 d2.utils.events]: \u001b[0m eta: 4:05:30  iter: 3439  total_loss: 3.295  loss_cls_stage0: 0.2084  loss_box_reg_stage0: 0.447  loss_cls_stage1: 0.2295  loss_box_reg_stage1: 0.7949  loss_cls_stage2: 0.2473  loss_box_reg_stage2: 0.8951  loss_mask: 0.2584  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.1847  time: 2.2274  data_time: 0.0811  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:40:05 d2.utils.events]: \u001b[0m eta: 4:04:47  iter: 3459  total_loss: 3.343  loss_cls_stage0: 0.1913  loss_box_reg_stage0: 0.4727  loss_cls_stage1: 0.2021  loss_box_reg_stage1: 0.8402  loss_cls_stage2: 0.2398  loss_box_reg_stage2: 0.8908  loss_mask: 0.2774  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.2004  time: 2.2273  data_time: 0.0994  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:40:48 d2.utils.events]: \u001b[0m eta: 4:04:02  iter: 3479  total_loss: 3.451  loss_cls_stage0: 0.1881  loss_box_reg_stage0: 0.4701  loss_cls_stage1: 0.2058  loss_box_reg_stage1: 0.8935  loss_cls_stage2: 0.238  loss_box_reg_stage2: 1.002  loss_mask: 0.2696  loss_rpn_cls: 0.04919  loss_rpn_loc: 0.1713  time: 2.2269  data_time: 0.0705  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:41:32 d2.utils.events]: \u001b[0m eta: 4:03:19  iter: 3499  total_loss: 3.525  loss_cls_stage0: 0.2048  loss_box_reg_stage0: 0.4707  loss_cls_stage1: 0.2163  loss_box_reg_stage1: 0.8571  loss_cls_stage2: 0.2535  loss_box_reg_stage2: 0.8436  loss_mask: 0.2771  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.2227  time: 2.2266  data_time: 0.1048  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:42:18 d2.utils.events]: \u001b[0m eta: 4:02:44  iter: 3519  total_loss: 3.56  loss_cls_stage0: 0.2389  loss_box_reg_stage0: 0.5091  loss_cls_stage1: 0.2766  loss_box_reg_stage1: 0.8816  loss_cls_stage2: 0.2688  loss_box_reg_stage2: 0.8692  loss_mask: 0.292  loss_rpn_cls: 0.0708  loss_rpn_loc: 0.2112  time: 2.2271  data_time: 0.1231  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:43:02 d2.utils.events]: \u001b[0m eta: 4:01:58  iter: 3539  total_loss: 3.499  loss_cls_stage0: 0.1983  loss_box_reg_stage0: 0.4737  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.8659  loss_cls_stage2: 0.254  loss_box_reg_stage2: 0.8637  loss_mask: 0.2935  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.1917  time: 2.2270  data_time: 0.0772  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:43:47 d2.utils.events]: \u001b[0m eta: 4:01:26  iter: 3559  total_loss: 3.525  loss_cls_stage0: 0.2103  loss_box_reg_stage0: 0.4729  loss_cls_stage1: 0.2345  loss_box_reg_stage1: 0.894  loss_cls_stage2: 0.2482  loss_box_reg_stage2: 0.938  loss_mask: 0.2761  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.1712  time: 2.2271  data_time: 0.0974  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:44:32 d2.utils.events]: \u001b[0m eta: 4:00:49  iter: 3579  total_loss: 3.527  loss_cls_stage0: 0.2256  loss_box_reg_stage0: 0.5048  loss_cls_stage1: 0.2501  loss_box_reg_stage1: 0.8929  loss_cls_stage2: 0.2609  loss_box_reg_stage2: 0.9084  loss_mask: 0.2777  loss_rpn_cls: 0.05656  loss_rpn_loc: 0.1892  time: 2.2273  data_time: 0.0874  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:45:15 d2.utils.events]: \u001b[0m eta: 3:59:43  iter: 3599  total_loss: 3.577  loss_cls_stage0: 0.229  loss_box_reg_stage0: 0.4921  loss_cls_stage1: 0.2393  loss_box_reg_stage1: 0.908  loss_cls_stage2: 0.268  loss_box_reg_stage2: 0.9402  loss_mask: 0.2776  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.1563  time: 2.2266  data_time: 0.0547  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:45:59 d2.utils.events]: \u001b[0m eta: 3:59:04  iter: 3619  total_loss: 3.475  loss_cls_stage0: 0.1967  loss_box_reg_stage0: 0.494  loss_cls_stage1: 0.2184  loss_box_reg_stage1: 0.9169  loss_cls_stage2: 0.2399  loss_box_reg_stage2: 0.9305  loss_mask: 0.2833  loss_rpn_cls: 0.06563  loss_rpn_loc: 0.1826  time: 2.2265  data_time: 0.0960  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:46:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:46:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:46:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:46:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:46:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:46:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0012 s/iter. Inference: 0.3393 s/iter. Eval: 0.0208 s/iter. Total: 0.3613 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 04:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0020 s/iter. Inference: 0.3394 s/iter. Eval: 0.0500 s/iter. Total: 0.3916 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0021 s/iter. Inference: 0.3387 s/iter. Eval: 0.0488 s/iter. Total: 0.3898 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 04:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0028 s/iter. Inference: 0.3415 s/iter. Eval: 0.0503 s/iter. Total: 0.3948 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 04:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0027 s/iter. Inference: 0.3408 s/iter. Eval: 0.0505 s/iter. Total: 0.3942 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 04:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0026 s/iter. Inference: 0.3414 s/iter. Eval: 0.0517 s/iter. Total: 0.3959 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 04:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0026 s/iter. Inference: 0.3425 s/iter. Eval: 0.0545 s/iter. Total: 0.3998 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 04:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0026 s/iter. Inference: 0.3456 s/iter. Eval: 0.0566 s/iter. Total: 0.4050 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 04:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0026 s/iter. Inference: 0.3456 s/iter. Eval: 0.0541 s/iter. Total: 0.4025 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 04:47:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.711138 (0.402682 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:47:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.344722 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:47:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:47:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2888467495427406\n",
      "\u001b[32m[12/29 04:47:14 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.28885, not better than best score 0.29360 @ iteration 2661.\n",
      "\u001b[32m[12/29 04:47:36 d2.utils.events]: \u001b[0m eta: 3:58:19  iter: 3639  total_loss: 3.578  loss_cls_stage0: 0.2317  loss_box_reg_stage0: 0.4884  loss_cls_stage1: 0.2524  loss_box_reg_stage1: 0.9178  loss_cls_stage2: 0.2689  loss_box_reg_stage2: 0.8753  loss_mask: 0.2835  loss_rpn_cls: 0.08026  loss_rpn_loc: 0.1912  time: 2.2266  data_time: 0.0832  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:48:20 d2.utils.events]: \u001b[0m eta: 3:57:30  iter: 3659  total_loss: 3.523  loss_cls_stage0: 0.2391  loss_box_reg_stage0: 0.4933  loss_cls_stage1: 0.2595  loss_box_reg_stage1: 0.8286  loss_cls_stage2: 0.271  loss_box_reg_stage2: 0.8117  loss_mask: 0.2887  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.1977  time: 2.2265  data_time: 0.1046  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:49:05 d2.utils.events]: \u001b[0m eta: 3:56:43  iter: 3679  total_loss: 3.48  loss_cls_stage0: 0.2063  loss_box_reg_stage0: 0.4826  loss_cls_stage1: 0.2089  loss_box_reg_stage1: 0.9086  loss_cls_stage2: 0.2346  loss_box_reg_stage2: 0.9598  loss_mask: 0.2921  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.1702  time: 2.2266  data_time: 0.0630  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:49:49 d2.utils.events]: \u001b[0m eta: 3:55:42  iter: 3699  total_loss: 3.557  loss_cls_stage0: 0.252  loss_box_reg_stage0: 0.5032  loss_cls_stage1: 0.2765  loss_box_reg_stage1: 0.9234  loss_cls_stage2: 0.2844  loss_box_reg_stage2: 0.8425  loss_mask: 0.2867  loss_rpn_cls: 0.0724  loss_rpn_loc: 0.2159  time: 2.2264  data_time: 0.0883  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:50:33 d2.utils.events]: \u001b[0m eta: 3:54:48  iter: 3719  total_loss: 3.431  loss_cls_stage0: 0.2047  loss_box_reg_stage0: 0.4578  loss_cls_stage1: 0.2031  loss_box_reg_stage1: 0.8811  loss_cls_stage2: 0.2387  loss_box_reg_stage2: 0.9645  loss_mask: 0.2646  loss_rpn_cls: 0.05516  loss_rpn_loc: 0.1617  time: 2.2263  data_time: 0.0682  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:51:20 d2.utils.events]: \u001b[0m eta: 3:54:15  iter: 3739  total_loss: 3.512  loss_cls_stage0: 0.2013  loss_box_reg_stage0: 0.461  loss_cls_stage1: 0.2235  loss_box_reg_stage1: 0.8633  loss_cls_stage2: 0.2392  loss_box_reg_stage2: 0.9525  loss_mask: 0.2875  loss_rpn_cls: 0.08046  loss_rpn_loc: 0.2155  time: 2.2269  data_time: 0.1517  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:52:01 d2.utils.events]: \u001b[0m eta: 3:53:06  iter: 3759  total_loss: 3.493  loss_cls_stage0: 0.1919  loss_box_reg_stage0: 0.5045  loss_cls_stage1: 0.2204  loss_box_reg_stage1: 0.8971  loss_cls_stage2: 0.2474  loss_box_reg_stage2: 0.9292  loss_mask: 0.2715  loss_rpn_cls: 0.03948  loss_rpn_loc: 0.1664  time: 2.2262  data_time: 0.0594  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:52:47 d2.utils.events]: \u001b[0m eta: 3:52:30  iter: 3779  total_loss: 3.392  loss_cls_stage0: 0.2016  loss_box_reg_stage0: 0.4459  loss_cls_stage1: 0.2157  loss_box_reg_stage1: 0.83  loss_cls_stage2: 0.2428  loss_box_reg_stage2: 0.9273  loss_mask: 0.2703  loss_rpn_cls: 0.0617  loss_rpn_loc: 0.164  time: 2.2264  data_time: 0.0794  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:53:33 d2.utils.events]: \u001b[0m eta: 3:51:36  iter: 3799  total_loss: 3.522  loss_cls_stage0: 0.195  loss_box_reg_stage0: 0.468  loss_cls_stage1: 0.21  loss_box_reg_stage1: 0.8726  loss_cls_stage2: 0.2388  loss_box_reg_stage2: 0.886  loss_mask: 0.2824  loss_rpn_cls: 0.073  loss_rpn_loc: 0.2259  time: 2.2267  data_time: 0.1093  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:54:17 d2.utils.events]: \u001b[0m eta: 3:51:04  iter: 3819  total_loss: 3.446  loss_cls_stage0: 0.2136  loss_box_reg_stage0: 0.4578  loss_cls_stage1: 0.2542  loss_box_reg_stage1: 0.8625  loss_cls_stage2: 0.2807  loss_box_reg_stage2: 0.8938  loss_mask: 0.2793  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.2086  time: 2.2266  data_time: 0.0994  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:55:00 d2.utils.events]: \u001b[0m eta: 3:50:15  iter: 3839  total_loss: 3.497  loss_cls_stage0: 0.2028  loss_box_reg_stage0: 0.4778  loss_cls_stage1: 0.2236  loss_box_reg_stage1: 0.8667  loss_cls_stage2: 0.2538  loss_box_reg_stage2: 0.9179  loss_mask: 0.2696  loss_rpn_cls: 0.05777  loss_rpn_loc: 0.1716  time: 2.2264  data_time: 0.0819  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:55:46 d2.utils.events]: \u001b[0m eta: 3:49:30  iter: 3859  total_loss: 3.469  loss_cls_stage0: 0.1847  loss_box_reg_stage0: 0.4623  loss_cls_stage1: 0.2071  loss_box_reg_stage1: 0.8869  loss_cls_stage2: 0.2187  loss_box_reg_stage2: 0.9685  loss_mask: 0.2652  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1716  time: 2.2268  data_time: 0.0949  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:56:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:56:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 04:56:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 04:56:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 04:56:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 04:56:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 04:56:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0011 s/iter. Inference: 0.3331 s/iter. Eval: 0.0240 s/iter. Total: 0.3583 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 04:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0017 s/iter. Inference: 0.3560 s/iter. Eval: 0.0456 s/iter. Total: 0.4035 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 04:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 34/121. Dataloading: 0.0033 s/iter. Inference: 0.3708 s/iter. Eval: 0.0522 s/iter. Total: 0.4265 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 04:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0031 s/iter. Inference: 0.3612 s/iter. Eval: 0.0534 s/iter. Total: 0.4179 s/iter. ETA=0:00:30\n",
      "\u001b[32m[12/29 04:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 60/121. Dataloading: 0.0030 s/iter. Inference: 0.3594 s/iter. Eval: 0.0507 s/iter. Total: 0.4134 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 04:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0030 s/iter. Inference: 0.3559 s/iter. Eval: 0.0494 s/iter. Total: 0.4086 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 04:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0033 s/iter. Inference: 0.3552 s/iter. Eval: 0.0576 s/iter. Total: 0.4162 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 04:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0032 s/iter. Inference: 0.3560 s/iter. Eval: 0.0600 s/iter. Total: 0.4193 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 04:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0031 s/iter. Inference: 0.3554 s/iter. Eval: 0.0604 s/iter. Total: 0.4192 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 04:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0030 s/iter. Inference: 0.3572 s/iter. Eval: 0.0576 s/iter. Total: 0.4181 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/29 04:57:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.684353 (0.419693 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:57:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.357217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 04:57:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 04:57:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.29619543280356125\n",
      "\u001b[32m[12/29 04:57:08 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.29620, better than last best score 0.29360 @ iteration 2661.\n",
      "\u001b[32m[12/29 04:57:26 d2.utils.events]: \u001b[0m eta: 3:48:23  iter: 3879  total_loss: 3.774  loss_cls_stage0: 0.2483  loss_box_reg_stage0: 0.5075  loss_cls_stage1: 0.2686  loss_box_reg_stage1: 0.9253  loss_cls_stage2: 0.2761  loss_box_reg_stage2: 0.9148  loss_mask: 0.2744  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1816  time: 2.2261  data_time: 0.0641  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:58:10 d2.utils.events]: \u001b[0m eta: 3:48:01  iter: 3899  total_loss: 3.516  loss_cls_stage0: 0.2148  loss_box_reg_stage0: 0.4896  loss_cls_stage1: 0.2387  loss_box_reg_stage1: 0.8805  loss_cls_stage2: 0.26  loss_box_reg_stage2: 1.006  loss_mask: 0.2749  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.1742  time: 2.2261  data_time: 0.0779  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:58:54 d2.utils.events]: \u001b[0m eta: 3:47:09  iter: 3919  total_loss: 3.431  loss_cls_stage0: 0.2195  loss_box_reg_stage0: 0.4766  loss_cls_stage1: 0.2331  loss_box_reg_stage1: 0.8581  loss_cls_stage2: 0.2515  loss_box_reg_stage2: 0.8511  loss_mask: 0.2821  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.1758  time: 2.2260  data_time: 0.0877  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 04:59:39 d2.utils.events]: \u001b[0m eta: 3:46:39  iter: 3939  total_loss: 3.444  loss_cls_stage0: 0.2149  loss_box_reg_stage0: 0.4568  loss_cls_stage1: 0.24  loss_box_reg_stage1: 0.8471  loss_cls_stage2: 0.2431  loss_box_reg_stage2: 0.8993  loss_mask: 0.2688  loss_rpn_cls: 0.05279  loss_rpn_loc: 0.1651  time: 2.2261  data_time: 0.0674  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:00:24 d2.utils.events]: \u001b[0m eta: 3:45:46  iter: 3959  total_loss: 3.652  loss_cls_stage0: 0.236  loss_box_reg_stage0: 0.5057  loss_cls_stage1: 0.2578  loss_box_reg_stage1: 0.8703  loss_cls_stage2: 0.2655  loss_box_reg_stage2: 0.8106  loss_mask: 0.2822  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.1912  time: 2.2261  data_time: 0.0964  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:01:08 d2.utils.events]: \u001b[0m eta: 3:44:33  iter: 3979  total_loss: 3.338  loss_cls_stage0: 0.1852  loss_box_reg_stage0: 0.4694  loss_cls_stage1: 0.2118  loss_box_reg_stage1: 0.8316  loss_cls_stage2: 0.2311  loss_box_reg_stage2: 0.8709  loss_mask: 0.2869  loss_rpn_cls: 0.04763  loss_rpn_loc: 0.1947  time: 2.2261  data_time: 0.0801  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:01:54 d2.utils.events]: \u001b[0m eta: 3:44:16  iter: 3999  total_loss: 3.502  loss_cls_stage0: 0.1968  loss_box_reg_stage0: 0.4733  loss_cls_stage1: 0.2124  loss_box_reg_stage1: 0.8851  loss_cls_stage2: 0.2287  loss_box_reg_stage2: 0.8863  loss_mask: 0.2681  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.1915  time: 2.2263  data_time: 0.0804  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:02:41 d2.utils.events]: \u001b[0m eta: 3:43:35  iter: 4019  total_loss: 3.449  loss_cls_stage0: 0.1926  loss_box_reg_stage0: 0.482  loss_cls_stage1: 0.206  loss_box_reg_stage1: 0.9051  loss_cls_stage2: 0.2305  loss_box_reg_stage2: 0.9541  loss_mask: 0.2815  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1909  time: 2.2269  data_time: 0.0743  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:03:25 d2.utils.events]: \u001b[0m eta: 3:42:47  iter: 4039  total_loss: 3.447  loss_cls_stage0: 0.1994  loss_box_reg_stage0: 0.4737  loss_cls_stage1: 0.2131  loss_box_reg_stage1: 0.9015  loss_cls_stage2: 0.2355  loss_box_reg_stage2: 0.9462  loss_mask: 0.2714  loss_rpn_cls: 0.05502  loss_rpn_loc: 0.1894  time: 2.2269  data_time: 0.0759  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:04:09 d2.utils.events]: \u001b[0m eta: 3:41:55  iter: 4059  total_loss: 3.594  loss_cls_stage0: 0.2387  loss_box_reg_stage0: 0.4914  loss_cls_stage1: 0.2449  loss_box_reg_stage1: 0.907  loss_cls_stage2: 0.2547  loss_box_reg_stage2: 0.8958  loss_mask: 0.2734  loss_rpn_cls: 0.07048  loss_rpn_loc: 0.1843  time: 2.2266  data_time: 0.0807  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:04:53 d2.utils.events]: \u001b[0m eta: 3:41:02  iter: 4079  total_loss: 3.45  loss_cls_stage0: 0.2078  loss_box_reg_stage0: 0.4948  loss_cls_stage1: 0.2245  loss_box_reg_stage1: 0.8815  loss_cls_stage2: 0.2551  loss_box_reg_stage2: 0.8938  loss_mask: 0.2881  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.1639  time: 2.2266  data_time: 0.0779  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:05:37 d2.utils.events]: \u001b[0m eta: 3:39:53  iter: 4099  total_loss: 3.615  loss_cls_stage0: 0.1858  loss_box_reg_stage0: 0.4676  loss_cls_stage1: 0.2051  loss_box_reg_stage1: 0.9154  loss_cls_stage2: 0.241  loss_box_reg_stage2: 0.9333  loss_mask: 0.2859  loss_rpn_cls: 0.04423  loss_rpn_loc: 0.1814  time: 2.2265  data_time: 0.0653  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:06:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:06:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:06:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:06:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:06:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:06:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0026 s/iter. Inference: 0.3403 s/iter. Eval: 0.0214 s/iter. Total: 0.3643 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 05:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0021 s/iter. Inference: 0.3476 s/iter. Eval: 0.0496 s/iter. Total: 0.3995 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0024 s/iter. Inference: 0.3510 s/iter. Eval: 0.0567 s/iter. Total: 0.4102 s/iter. ETA=0:00:35\n",
      "\u001b[32m[12/29 05:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0025 s/iter. Inference: 0.3490 s/iter. Eval: 0.0566 s/iter. Total: 0.4083 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/29 05:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0026 s/iter. Inference: 0.3504 s/iter. Eval: 0.0531 s/iter. Total: 0.4063 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/29 05:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0029 s/iter. Inference: 0.3467 s/iter. Eval: 0.0548 s/iter. Total: 0.4046 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 05:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0029 s/iter. Inference: 0.3515 s/iter. Eval: 0.0648 s/iter. Total: 0.4194 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 05:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0029 s/iter. Inference: 0.3543 s/iter. Eval: 0.0648 s/iter. Total: 0.4222 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 05:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0029 s/iter. Inference: 0.3558 s/iter. Eval: 0.0656 s/iter. Total: 0.4245 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 05:07:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.126348 (0.423503 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:07:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.354469 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:07:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:07:04 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.30302575749815075\n",
      "\u001b[32m[12/29 05:07:07 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.30303, better than last best score 0.29620 @ iteration 3871.\n",
      "\u001b[32m[12/29 05:07:20 d2.utils.events]: \u001b[0m eta: 3:38:53  iter: 4119  total_loss: 3.43  loss_cls_stage0: 0.2246  loss_box_reg_stage0: 0.4779  loss_cls_stage1: 0.2514  loss_box_reg_stage1: 0.8644  loss_cls_stage2: 0.2527  loss_box_reg_stage2: 0.9037  loss_mask: 0.2657  loss_rpn_cls: 0.06548  loss_rpn_loc: 0.202  time: 2.2265  data_time: 0.0987  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:08:06 d2.utils.events]: \u001b[0m eta: 3:38:29  iter: 4139  total_loss: 3.404  loss_cls_stage0: 0.1957  loss_box_reg_stage0: 0.4731  loss_cls_stage1: 0.1974  loss_box_reg_stage1: 0.8871  loss_cls_stage2: 0.2218  loss_box_reg_stage2: 0.9341  loss_mask: 0.2867  loss_rpn_cls: 0.05068  loss_rpn_loc: 0.1712  time: 2.2269  data_time: 0.0795  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:08:52 d2.utils.events]: \u001b[0m eta: 3:37:45  iter: 4159  total_loss: 3.594  loss_cls_stage0: 0.2112  loss_box_reg_stage0: 0.4605  loss_cls_stage1: 0.2364  loss_box_reg_stage1: 0.9036  loss_cls_stage2: 0.2544  loss_box_reg_stage2: 0.8993  loss_mask: 0.2705  loss_rpn_cls: 0.05777  loss_rpn_loc: 0.2079  time: 2.2272  data_time: 0.0935  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:09:38 d2.utils.events]: \u001b[0m eta: 3:37:01  iter: 4179  total_loss: 3.454  loss_cls_stage0: 0.2114  loss_box_reg_stage0: 0.4743  loss_cls_stage1: 0.2255  loss_box_reg_stage1: 0.8547  loss_cls_stage2: 0.245  loss_box_reg_stage2: 0.9269  loss_mask: 0.2768  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.1683  time: 2.2276  data_time: 0.0814  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:10:24 d2.utils.events]: \u001b[0m eta: 3:36:16  iter: 4199  total_loss: 3.461  loss_cls_stage0: 0.219  loss_box_reg_stage0: 0.4906  loss_cls_stage1: 0.2393  loss_box_reg_stage1: 0.8692  loss_cls_stage2: 0.2667  loss_box_reg_stage2: 0.8316  loss_mask: 0.3049  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.1844  time: 2.2280  data_time: 0.1094  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:11:08 d2.utils.events]: \u001b[0m eta: 3:35:17  iter: 4219  total_loss: 3.526  loss_cls_stage0: 0.2113  loss_box_reg_stage0: 0.4524  loss_cls_stage1: 0.2319  loss_box_reg_stage1: 0.8689  loss_cls_stage2: 0.2486  loss_box_reg_stage2: 0.8701  loss_mask: 0.276  loss_rpn_cls: 0.0784  loss_rpn_loc: 0.1789  time: 2.2278  data_time: 0.1029  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:11:54 d2.utils.events]: \u001b[0m eta: 3:34:46  iter: 4239  total_loss: 3.577  loss_cls_stage0: 0.2209  loss_box_reg_stage0: 0.4843  loss_cls_stage1: 0.243  loss_box_reg_stage1: 0.8711  loss_cls_stage2: 0.2635  loss_box_reg_stage2: 0.9406  loss_mask: 0.2788  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.214  time: 2.2282  data_time: 0.0939  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:12:39 d2.utils.events]: \u001b[0m eta: 3:34:02  iter: 4259  total_loss: 3.417  loss_cls_stage0: 0.1858  loss_box_reg_stage0: 0.4636  loss_cls_stage1: 0.2048  loss_box_reg_stage1: 0.8616  loss_cls_stage2: 0.2486  loss_box_reg_stage2: 0.938  loss_mask: 0.2668  loss_rpn_cls: 0.06001  loss_rpn_loc: 0.1673  time: 2.2282  data_time: 0.0662  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:13:22 d2.utils.events]: \u001b[0m eta: 3:33:10  iter: 4279  total_loss: 3.55  loss_cls_stage0: 0.1867  loss_box_reg_stage0: 0.4862  loss_cls_stage1: 0.2008  loss_box_reg_stage1: 0.8841  loss_cls_stage2: 0.2418  loss_box_reg_stage2: 0.9757  loss_mask: 0.266  loss_rpn_cls: 0.05223  loss_rpn_loc: 0.1914  time: 2.2278  data_time: 0.0650  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:14:07 d2.utils.events]: \u001b[0m eta: 3:32:20  iter: 4299  total_loss: 3.39  loss_cls_stage0: 0.197  loss_box_reg_stage0: 0.4697  loss_cls_stage1: 0.2164  loss_box_reg_stage1: 0.8948  loss_cls_stage2: 0.2351  loss_box_reg_stage2: 0.9757  loss_mask: 0.2657  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.1517  time: 2.2279  data_time: 0.0870  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:14:52 d2.utils.events]: \u001b[0m eta: 3:31:41  iter: 4319  total_loss: 3.324  loss_cls_stage0: 0.229  loss_box_reg_stage0: 0.4722  loss_cls_stage1: 0.2321  loss_box_reg_stage1: 0.8105  loss_cls_stage2: 0.2457  loss_box_reg_stage2: 0.8381  loss_mask: 0.273  loss_rpn_cls: 0.05321  loss_rpn_loc: 0.185  time: 2.2280  data_time: 0.1029  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:15:37 d2.utils.events]: \u001b[0m eta: 3:30:45  iter: 4339  total_loss: 3.456  loss_cls_stage0: 0.2049  loss_box_reg_stage0: 0.4623  loss_cls_stage1: 0.2202  loss_box_reg_stage1: 0.865  loss_cls_stage2: 0.2373  loss_box_reg_stage2: 0.932  loss_mask: 0.2557  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.1886  time: 2.2281  data_time: 0.0794  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:16:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:16:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:16:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:16:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:16:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:16:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0012 s/iter. Inference: 0.3741 s/iter. Eval: 0.0212 s/iter. Total: 0.3965 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/29 05:16:25 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0016 s/iter. Inference: 0.3474 s/iter. Eval: 0.0483 s/iter. Total: 0.3974 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 05:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0019 s/iter. Inference: 0.3410 s/iter. Eval: 0.0468 s/iter. Total: 0.3899 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 05:16:36 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0020 s/iter. Inference: 0.3384 s/iter. Eval: 0.0493 s/iter. Total: 0.3899 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 05:16:41 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0026 s/iter. Inference: 0.3402 s/iter. Eval: 0.0498 s/iter. Total: 0.3927 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 05:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0026 s/iter. Inference: 0.3453 s/iter. Eval: 0.0518 s/iter. Total: 0.3998 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 05:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0026 s/iter. Inference: 0.3451 s/iter. Eval: 0.0553 s/iter. Total: 0.4033 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 05:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0026 s/iter. Inference: 0.3465 s/iter. Eval: 0.0586 s/iter. Total: 0.4080 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 05:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0026 s/iter. Inference: 0.3443 s/iter. Eval: 0.0560 s/iter. Total: 0.4031 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 05:17:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.832777 (0.403731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:17:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.343901 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:17:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:17:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.29657336335347934\n",
      "\u001b[32m[12/29 05:17:05 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29657, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 05:17:14 d2.utils.events]: \u001b[0m eta: 3:29:53  iter: 4359  total_loss: 3.574  loss_cls_stage0: 0.1999  loss_box_reg_stage0: 0.5115  loss_cls_stage1: 0.229  loss_box_reg_stage1: 0.9162  loss_cls_stage2: 0.2686  loss_box_reg_stage2: 0.9208  loss_mask: 0.2862  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.1784  time: 2.2281  data_time: 0.0816  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:18:00 d2.utils.events]: \u001b[0m eta: 3:28:59  iter: 4379  total_loss: 3.377  loss_cls_stage0: 0.2007  loss_box_reg_stage0: 0.4514  loss_cls_stage1: 0.2299  loss_box_reg_stage1: 0.8433  loss_cls_stage2: 0.2476  loss_box_reg_stage2: 0.8599  loss_mask: 0.2735  loss_rpn_cls: 0.06292  loss_rpn_loc: 0.2006  time: 2.2284  data_time: 0.1149  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:18:46 d2.utils.events]: \u001b[0m eta: 3:28:14  iter: 4399  total_loss: 3.452  loss_cls_stage0: 0.2043  loss_box_reg_stage0: 0.469  loss_cls_stage1: 0.238  loss_box_reg_stage1: 0.8751  loss_cls_stage2: 0.262  loss_box_reg_stage2: 0.8844  loss_mask: 0.2733  loss_rpn_cls: 0.06361  loss_rpn_loc: 0.203  time: 2.2287  data_time: 0.1241  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:19:31 d2.utils.events]: \u001b[0m eta: 3:27:19  iter: 4419  total_loss: 3.444  loss_cls_stage0: 0.2019  loss_box_reg_stage0: 0.4582  loss_cls_stage1: 0.2034  loss_box_reg_stage1: 0.8849  loss_cls_stage2: 0.2475  loss_box_reg_stage2: 0.9863  loss_mask: 0.2665  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.1615  time: 2.2288  data_time: 0.0501  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:20:14 d2.utils.events]: \u001b[0m eta: 3:26:29  iter: 4439  total_loss: 3.611  loss_cls_stage0: 0.2217  loss_box_reg_stage0: 0.4948  loss_cls_stage1: 0.2477  loss_box_reg_stage1: 0.9263  loss_cls_stage2: 0.2646  loss_box_reg_stage2: 0.9294  loss_mask: 0.2643  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.1922  time: 2.2284  data_time: 0.0815  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:20:56 d2.utils.events]: \u001b[0m eta: 3:25:28  iter: 4459  total_loss: 3.524  loss_cls_stage0: 0.2019  loss_box_reg_stage0: 0.4837  loss_cls_stage1: 0.2088  loss_box_reg_stage1: 0.9136  loss_cls_stage2: 0.2256  loss_box_reg_stage2: 0.9732  loss_mask: 0.271  loss_rpn_cls: 0.04438  loss_rpn_loc: 0.1761  time: 2.2280  data_time: 0.0447  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:21:41 d2.utils.events]: \u001b[0m eta: 3:25:05  iter: 4479  total_loss: 3.586  loss_cls_stage0: 0.2057  loss_box_reg_stage0: 0.4867  loss_cls_stage1: 0.2205  loss_box_reg_stage1: 0.8882  loss_cls_stage2: 0.2533  loss_box_reg_stage2: 0.9336  loss_mask: 0.2794  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1773  time: 2.2280  data_time: 0.0724  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:22:28 d2.utils.events]: \u001b[0m eta: 3:24:43  iter: 4499  total_loss: 3.502  loss_cls_stage0: 0.2211  loss_box_reg_stage0: 0.4657  loss_cls_stage1: 0.2345  loss_box_reg_stage1: 0.7992  loss_cls_stage2: 0.2515  loss_box_reg_stage2: 0.8517  loss_mask: 0.294  loss_rpn_cls: 0.07543  loss_rpn_loc: 0.1914  time: 2.2285  data_time: 0.1165  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:23:09 d2.utils.events]: \u001b[0m eta: 3:23:23  iter: 4519  total_loss: 3.634  loss_cls_stage0: 0.2036  loss_box_reg_stage0: 0.4501  loss_cls_stage1: 0.2403  loss_box_reg_stage1: 0.8925  loss_cls_stage2: 0.2563  loss_box_reg_stage2: 0.9676  loss_mask: 0.2586  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.1739  time: 2.2277  data_time: 0.0674  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:23:55 d2.utils.events]: \u001b[0m eta: 3:22:48  iter: 4539  total_loss: 3.521  loss_cls_stage0: 0.2029  loss_box_reg_stage0: 0.4942  loss_cls_stage1: 0.22  loss_box_reg_stage1: 0.8833  loss_cls_stage2: 0.2436  loss_box_reg_stage2: 0.9067  loss_mask: 0.2875  loss_rpn_cls: 0.05602  loss_rpn_loc: 0.1767  time: 2.2280  data_time: 0.1200  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:24:40 d2.utils.events]: \u001b[0m eta: 3:22:02  iter: 4559  total_loss: 3.371  loss_cls_stage0: 0.2153  loss_box_reg_stage0: 0.4722  loss_cls_stage1: 0.2358  loss_box_reg_stage1: 0.8585  loss_cls_stage2: 0.2545  loss_box_reg_stage2: 0.8823  loss_mask: 0.2639  loss_rpn_cls: 0.06387  loss_rpn_loc: 0.16  time: 2.2280  data_time: 0.0895  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:25:25 d2.utils.events]: \u001b[0m eta: 3:21:17  iter: 4579  total_loss: 3.428  loss_cls_stage0: 0.1923  loss_box_reg_stage0: 0.4493  loss_cls_stage1: 0.203  loss_box_reg_stage1: 0.834  loss_cls_stage2: 0.232  loss_box_reg_stage2: 0.8495  loss_mask: 0.2722  loss_rpn_cls: 0.04905  loss_rpn_loc: 0.1851  time: 2.2284  data_time: 0.1251  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:26:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:26:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:26:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:26:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:26:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:26:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0014 s/iter. Inference: 0.3604 s/iter. Eval: 0.0235 s/iter. Total: 0.3854 s/iter. ETA=0:00:42\n",
      "\u001b[32m[12/29 05:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 23/121. Dataloading: 0.0016 s/iter. Inference: 0.3539 s/iter. Eval: 0.0508 s/iter. Total: 0.4065 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0017 s/iter. Inference: 0.3469 s/iter. Eval: 0.0566 s/iter. Total: 0.4054 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 05:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0022 s/iter. Inference: 0.3510 s/iter. Eval: 0.0578 s/iter. Total: 0.4111 s/iter. ETA=0:00:30\n",
      "\u001b[32m[12/29 05:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0022 s/iter. Inference: 0.3533 s/iter. Eval: 0.0545 s/iter. Total: 0.4102 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/29 05:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0538 s/iter. Total: 0.4130 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/29 05:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0024 s/iter. Inference: 0.3567 s/iter. Eval: 0.0628 s/iter. Total: 0.4221 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/29 05:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0026 s/iter. Inference: 0.3557 s/iter. Eval: 0.0646 s/iter. Total: 0.4230 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 05:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0026 s/iter. Inference: 0.3563 s/iter. Eval: 0.0645 s/iter. Total: 0.4236 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 05:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.692973 (0.419767 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.353628 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:26:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:26:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2905445559574572\n",
      "\u001b[32m[12/29 05:26:58 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29054, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 05:27:03 d2.utils.events]: \u001b[0m eta: 3:20:49  iter: 4599  total_loss: 3.431  loss_cls_stage0: 0.1965  loss_box_reg_stage0: 0.4598  loss_cls_stage1: 0.2072  loss_box_reg_stage1: 0.879  loss_cls_stage2: 0.2437  loss_box_reg_stage2: 0.9327  loss_mask: 0.2766  loss_rpn_cls: 0.04886  loss_rpn_loc: 0.1695  time: 2.2281  data_time: 0.0766  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:27:48 d2.utils.events]: \u001b[0m eta: 3:20:04  iter: 4619  total_loss: 3.459  loss_cls_stage0: 0.2208  loss_box_reg_stage0: 0.4668  loss_cls_stage1: 0.2353  loss_box_reg_stage1: 0.841  loss_cls_stage2: 0.2374  loss_box_reg_stage2: 0.8864  loss_mask: 0.273  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.1916  time: 2.2282  data_time: 0.1012  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:28:36 d2.utils.events]: \u001b[0m eta: 3:19:31  iter: 4639  total_loss: 3.406  loss_cls_stage0: 0.2148  loss_box_reg_stage0: 0.4971  loss_cls_stage1: 0.2435  loss_box_reg_stage1: 0.8646  loss_cls_stage2: 0.2393  loss_box_reg_stage2: 0.8931  loss_mask: 0.2788  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.1839  time: 2.2289  data_time: 0.0858  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:29:24 d2.utils.events]: \u001b[0m eta: 3:19:08  iter: 4659  total_loss: 3.503  loss_cls_stage0: 0.205  loss_box_reg_stage0: 0.4534  loss_cls_stage1: 0.2191  loss_box_reg_stage1: 0.8703  loss_cls_stage2: 0.2628  loss_box_reg_stage2: 0.8802  loss_mask: 0.2779  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.2109  time: 2.2297  data_time: 0.0919  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:30:10 d2.utils.events]: \u001b[0m eta: 3:18:23  iter: 4679  total_loss: 3.536  loss_cls_stage0: 0.2044  loss_box_reg_stage0: 0.499  loss_cls_stage1: 0.228  loss_box_reg_stage1: 0.8573  loss_cls_stage2: 0.2547  loss_box_reg_stage2: 0.9249  loss_mask: 0.2813  loss_rpn_cls: 0.06659  loss_rpn_loc: 0.2124  time: 2.2299  data_time: 0.0828  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:30:55 d2.utils.events]: \u001b[0m eta: 3:17:40  iter: 4699  total_loss: 3.477  loss_cls_stage0: 0.2086  loss_box_reg_stage0: 0.4818  loss_cls_stage1: 0.2264  loss_box_reg_stage1: 0.8876  loss_cls_stage2: 0.2439  loss_box_reg_stage2: 0.9125  loss_mask: 0.2753  loss_rpn_cls: 0.0524  loss_rpn_loc: 0.2022  time: 2.2299  data_time: 0.0824  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:31:38 d2.utils.events]: \u001b[0m eta: 3:16:54  iter: 4719  total_loss: 3.416  loss_cls_stage0: 0.2038  loss_box_reg_stage0: 0.4379  loss_cls_stage1: 0.2203  loss_box_reg_stage1: 0.8468  loss_cls_stage2: 0.234  loss_box_reg_stage2: 0.9191  loss_mask: 0.2694  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.1845  time: 2.2297  data_time: 0.0764  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:32:21 d2.utils.events]: \u001b[0m eta: 3:15:51  iter: 4739  total_loss: 3.579  loss_cls_stage0: 0.2065  loss_box_reg_stage0: 0.477  loss_cls_stage1: 0.2094  loss_box_reg_stage1: 0.8721  loss_cls_stage2: 0.2486  loss_box_reg_stage2: 0.9178  loss_mask: 0.2689  loss_rpn_cls: 0.0601  loss_rpn_loc: 0.2015  time: 2.2294  data_time: 0.0730  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:33:05 d2.utils.events]: \u001b[0m eta: 3:15:09  iter: 4759  total_loss: 3.435  loss_cls_stage0: 0.2019  loss_box_reg_stage0: 0.4613  loss_cls_stage1: 0.2415  loss_box_reg_stage1: 0.8247  loss_cls_stage2: 0.257  loss_box_reg_stage2: 0.8941  loss_mask: 0.287  loss_rpn_cls: 0.06929  loss_rpn_loc: 0.2121  time: 2.2291  data_time: 0.0894  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:33:47 d2.utils.events]: \u001b[0m eta: 3:14:12  iter: 4779  total_loss: 3.43  loss_cls_stage0: 0.1827  loss_box_reg_stage0: 0.4671  loss_cls_stage1: 0.1991  loss_box_reg_stage1: 0.8869  loss_cls_stage2: 0.2408  loss_box_reg_stage2: 0.9352  loss_mask: 0.2676  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.1653  time: 2.2285  data_time: 0.0688  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:34:31 d2.utils.events]: \u001b[0m eta: 3:13:22  iter: 4799  total_loss: 3.356  loss_cls_stage0: 0.2118  loss_box_reg_stage0: 0.4795  loss_cls_stage1: 0.2145  loss_box_reg_stage1: 0.8492  loss_cls_stage2: 0.2307  loss_box_reg_stage2: 0.9294  loss_mask: 0.275  loss_rpn_cls: 0.0583  loss_rpn_loc: 0.1531  time: 2.2286  data_time: 0.0568  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:35:17 d2.utils.events]: \u001b[0m eta: 3:12:46  iter: 4819  total_loss: 3.55  loss_cls_stage0: 0.2213  loss_box_reg_stage0: 0.4744  loss_cls_stage1: 0.2311  loss_box_reg_stage1: 0.8887  loss_cls_stage2: 0.2469  loss_box_reg_stage2: 0.8809  loss_mask: 0.2759  loss_rpn_cls: 0.07592  loss_rpn_loc: 0.1938  time: 2.2289  data_time: 0.0934  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:36:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:36:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:36:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:36:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:36:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:36:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.3553 s/iter. Eval: 0.0222 s/iter. Total: 0.3791 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 05:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0022 s/iter. Inference: 0.3421 s/iter. Eval: 0.0501 s/iter. Total: 0.3946 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 05:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0029 s/iter. Inference: 0.3461 s/iter. Eval: 0.0492 s/iter. Total: 0.3983 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 05:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0029 s/iter. Inference: 0.3467 s/iter. Eval: 0.0506 s/iter. Total: 0.4003 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 05:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0029 s/iter. Inference: 0.3456 s/iter. Eval: 0.0509 s/iter. Total: 0.3996 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 05:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0029 s/iter. Inference: 0.3441 s/iter. Eval: 0.0522 s/iter. Total: 0.3995 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 05:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0029 s/iter. Inference: 0.3457 s/iter. Eval: 0.0556 s/iter. Total: 0.4045 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 05:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0030 s/iter. Inference: 0.3454 s/iter. Eval: 0.0583 s/iter. Total: 0.4069 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 05:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0029 s/iter. Inference: 0.3434 s/iter. Eval: 0.0558 s/iter. Total: 0.4022 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 05:36:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.711362 (0.402684 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:36:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.342369 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:36:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:36:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2917092255738568\n",
      "\u001b[32m[12/29 05:36:55 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29171, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 05:36:55 d2.utils.events]: \u001b[0m eta: 3:12:06  iter: 4839  total_loss: 3.402  loss_cls_stage0: 0.1873  loss_box_reg_stage0: 0.4319  loss_cls_stage1: 0.2167  loss_box_reg_stage1: 0.8402  loss_cls_stage2: 0.2319  loss_box_reg_stage2: 0.9376  loss_mask: 0.2649  loss_rpn_cls: 0.05725  loss_rpn_loc: 0.1577  time: 2.2291  data_time: 0.1058  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:37:39 d2.utils.events]: \u001b[0m eta: 3:11:12  iter: 4859  total_loss: 3.466  loss_cls_stage0: 0.2127  loss_box_reg_stage0: 0.4655  loss_cls_stage1: 0.2342  loss_box_reg_stage1: 0.8262  loss_cls_stage2: 0.2544  loss_box_reg_stage2: 0.9311  loss_mask: 0.2719  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.2034  time: 2.2289  data_time: 0.0747  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:38:23 d2.utils.events]: \u001b[0m eta: 3:10:22  iter: 4879  total_loss: 3.519  loss_cls_stage0: 0.2162  loss_box_reg_stage0: 0.4922  loss_cls_stage1: 0.2347  loss_box_reg_stage1: 0.8847  loss_cls_stage2: 0.2695  loss_box_reg_stage2: 0.9354  loss_mask: 0.2931  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.2154  time: 2.2287  data_time: 0.0772  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:39:09 d2.utils.events]: \u001b[0m eta: 3:09:47  iter: 4899  total_loss: 3.442  loss_cls_stage0: 0.2011  loss_box_reg_stage0: 0.459  loss_cls_stage1: 0.2136  loss_box_reg_stage1: 0.854  loss_cls_stage2: 0.2335  loss_box_reg_stage2: 0.8648  loss_mask: 0.2553  loss_rpn_cls: 0.05367  loss_rpn_loc: 0.2092  time: 2.2291  data_time: 0.0805  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:39:56 d2.utils.events]: \u001b[0m eta: 3:09:05  iter: 4919  total_loss: 3.554  loss_cls_stage0: 0.1964  loss_box_reg_stage0: 0.4835  loss_cls_stage1: 0.2116  loss_box_reg_stage1: 0.8904  loss_cls_stage2: 0.2528  loss_box_reg_stage2: 0.9796  loss_mask: 0.2776  loss_rpn_cls: 0.05437  loss_rpn_loc: 0.1894  time: 2.2295  data_time: 0.0874  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:40:42 d2.utils.events]: \u001b[0m eta: 3:08:18  iter: 4939  total_loss: 3.493  loss_cls_stage0: 0.2005  loss_box_reg_stage0: 0.4804  loss_cls_stage1: 0.1956  loss_box_reg_stage1: 0.897  loss_cls_stage2: 0.243  loss_box_reg_stage2: 0.9554  loss_mask: 0.2758  loss_rpn_cls: 0.04911  loss_rpn_loc: 0.1632  time: 2.2298  data_time: 0.0927  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:41:26 d2.utils.events]: \u001b[0m eta: 3:07:33  iter: 4959  total_loss: 3.392  loss_cls_stage0: 0.2255  loss_box_reg_stage0: 0.4971  loss_cls_stage1: 0.2398  loss_box_reg_stage1: 0.8324  loss_cls_stage2: 0.2484  loss_box_reg_stage2: 0.8108  loss_mask: 0.2957  loss_rpn_cls: 0.07191  loss_rpn_loc: 0.2053  time: 2.2298  data_time: 0.0949  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:42:12 d2.utils.events]: \u001b[0m eta: 3:06:56  iter: 4979  total_loss: 3.533  loss_cls_stage0: 0.2241  loss_box_reg_stage0: 0.4808  loss_cls_stage1: 0.2548  loss_box_reg_stage1: 0.86  loss_cls_stage2: 0.2634  loss_box_reg_stage2: 0.9051  loss_mask: 0.2747  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.1688  time: 2.2299  data_time: 0.0818  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:42:57 d2.utils.events]: \u001b[0m eta: 3:06:04  iter: 4999  total_loss: 3.363  loss_cls_stage0: 0.1993  loss_box_reg_stage0: 0.4474  loss_cls_stage1: 0.2135  loss_box_reg_stage1: 0.8519  loss_cls_stage2: 0.2379  loss_box_reg_stage2: 0.9558  loss_mask: 0.2698  loss_rpn_cls: 0.04616  loss_rpn_loc: 0.1662  time: 2.2298  data_time: 0.0758  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:43:44 d2.utils.events]: \u001b[0m eta: 3:05:19  iter: 5019  total_loss: 3.631  loss_cls_stage0: 0.2277  loss_box_reg_stage0: 0.5044  loss_cls_stage1: 0.2573  loss_box_reg_stage1: 0.8696  loss_cls_stage2: 0.286  loss_box_reg_stage2: 0.8727  loss_mask: 0.2887  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.1959  time: 2.2301  data_time: 0.0827  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:44:28 d2.utils.events]: \u001b[0m eta: 3:04:35  iter: 5039  total_loss: 3.501  loss_cls_stage0: 0.2102  loss_box_reg_stage0: 0.4865  loss_cls_stage1: 0.2256  loss_box_reg_stage1: 0.878  loss_cls_stage2: 0.2378  loss_box_reg_stage2: 0.9208  loss_mask: 0.2706  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.2058  time: 2.2302  data_time: 0.0822  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:45:11 d2.utils.events]: \u001b[0m eta: 3:03:50  iter: 5059  total_loss: 3.392  loss_cls_stage0: 0.2067  loss_box_reg_stage0: 0.4777  loss_cls_stage1: 0.2258  loss_box_reg_stage1: 0.8705  loss_cls_stage2: 0.2354  loss_box_reg_stage2: 0.9239  loss_mask: 0.2728  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.1683  time: 2.2298  data_time: 0.0583  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:45:57 d2.utils.events]: \u001b[0m eta: 3:03:05  iter: 5079  total_loss: 3.351  loss_cls_stage0: 0.1877  loss_box_reg_stage0: 0.4604  loss_cls_stage1: 0.2147  loss_box_reg_stage1: 0.8576  loss_cls_stage2: 0.2367  loss_box_reg_stage2: 0.9285  loss_mask: 0.2672  loss_rpn_cls: 0.05678  loss_rpn_loc: 0.18  time: 2.2300  data_time: 0.0882  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:46:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:46:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:46:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:46:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:46:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:46:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0023 s/iter. Inference: 0.4078 s/iter. Eval: 0.0212 s/iter. Total: 0.4313 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/29 05:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0019 s/iter. Inference: 0.3579 s/iter. Eval: 0.0439 s/iter. Total: 0.4038 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0020 s/iter. Inference: 0.3586 s/iter. Eval: 0.0445 s/iter. Total: 0.4053 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/29 05:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0022 s/iter. Inference: 0.3526 s/iter. Eval: 0.0469 s/iter. Total: 0.4019 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/29 05:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0023 s/iter. Inference: 0.3519 s/iter. Eval: 0.0504 s/iter. Total: 0.4048 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 05:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0027 s/iter. Inference: 0.3503 s/iter. Eval: 0.0526 s/iter. Total: 0.4058 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 05:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0028 s/iter. Inference: 0.3520 s/iter. Eval: 0.0565 s/iter. Total: 0.4115 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 05:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0027 s/iter. Inference: 0.3515 s/iter. Eval: 0.0600 s/iter. Total: 0.4145 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 05:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0027 s/iter. Inference: 0.3491 s/iter. Eval: 0.0578 s/iter. Total: 0.4098 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 05:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.557365 (0.409977 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.347916 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:46:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:46:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2908896858264225\n",
      "\u001b[32m[12/29 05:46:55 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29089, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 05:47:36 d2.utils.events]: \u001b[0m eta: 3:02:34  iter: 5099  total_loss: 3.623  loss_cls_stage0: 0.2215  loss_box_reg_stage0: 0.4943  loss_cls_stage1: 0.2306  loss_box_reg_stage1: 0.8742  loss_cls_stage2: 0.2503  loss_box_reg_stage2: 0.8922  loss_mask: 0.2798  loss_rpn_cls: 0.08361  loss_rpn_loc: 0.2086  time: 2.2302  data_time: 0.0945  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:48:20 d2.utils.events]: \u001b[0m eta: 3:01:46  iter: 5119  total_loss: 3.479  loss_cls_stage0: 0.2055  loss_box_reg_stage0: 0.4658  loss_cls_stage1: 0.2228  loss_box_reg_stage1: 0.8792  loss_cls_stage2: 0.2484  loss_box_reg_stage2: 0.9408  loss_mask: 0.2861  loss_rpn_cls: 0.06297  loss_rpn_loc: 0.2074  time: 2.2301  data_time: 0.0876  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:49:07 d2.utils.events]: \u001b[0m eta: 3:01:12  iter: 5139  total_loss: 3.371  loss_cls_stage0: 0.1874  loss_box_reg_stage0: 0.4743  loss_cls_stage1: 0.1901  loss_box_reg_stage1: 0.8464  loss_cls_stage2: 0.229  loss_box_reg_stage2: 0.9617  loss_mask: 0.2748  loss_rpn_cls: 0.0398  loss_rpn_loc: 0.1601  time: 2.2306  data_time: 0.0568  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:49:50 d2.utils.events]: \u001b[0m eta: 3:00:16  iter: 5159  total_loss: 3.405  loss_cls_stage0: 0.1901  loss_box_reg_stage0: 0.4731  loss_cls_stage1: 0.2045  loss_box_reg_stage1: 0.8679  loss_cls_stage2: 0.228  loss_box_reg_stage2: 0.883  loss_mask: 0.2723  loss_rpn_cls: 0.0582  loss_rpn_loc: 0.1546  time: 2.2303  data_time: 0.0604  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:50:36 d2.utils.events]: \u001b[0m eta: 2:59:40  iter: 5179  total_loss: 3.325  loss_cls_stage0: 0.2186  loss_box_reg_stage0: 0.4574  loss_cls_stage1: 0.215  loss_box_reg_stage1: 0.8399  loss_cls_stage2: 0.2478  loss_box_reg_stage2: 0.9142  loss_mask: 0.2694  loss_rpn_cls: 0.0595  loss_rpn_loc: 0.1904  time: 2.2304  data_time: 0.0931  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:51:22 d2.utils.events]: \u001b[0m eta: 2:58:59  iter: 5199  total_loss: 3.482  loss_cls_stage0: 0.2429  loss_box_reg_stage0: 0.4772  loss_cls_stage1: 0.2536  loss_box_reg_stage1: 0.8745  loss_cls_stage2: 0.2668  loss_box_reg_stage2: 0.8758  loss_mask: 0.2779  loss_rpn_cls: 0.07333  loss_rpn_loc: 0.1979  time: 2.2308  data_time: 0.0991  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:52:06 d2.utils.events]: \u001b[0m eta: 2:58:16  iter: 5219  total_loss: 3.483  loss_cls_stage0: 0.1962  loss_box_reg_stage0: 0.4708  loss_cls_stage1: 0.193  loss_box_reg_stage1: 0.8634  loss_cls_stage2: 0.2315  loss_box_reg_stage2: 0.9175  loss_mask: 0.2803  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.1982  time: 2.2306  data_time: 0.0767  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:52:49 d2.utils.events]: \u001b[0m eta: 2:57:10  iter: 5239  total_loss: 3.437  loss_cls_stage0: 0.2003  loss_box_reg_stage0: 0.4704  loss_cls_stage1: 0.2069  loss_box_reg_stage1: 0.8731  loss_cls_stage2: 0.233  loss_box_reg_stage2: 0.9341  loss_mask: 0.2781  loss_rpn_cls: 0.05541  loss_rpn_loc: 0.2022  time: 2.2303  data_time: 0.1064  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:53:33 d2.utils.events]: \u001b[0m eta: 2:56:15  iter: 5259  total_loss: 3.469  loss_cls_stage0: 0.1908  loss_box_reg_stage0: 0.4565  loss_cls_stage1: 0.2117  loss_box_reg_stage1: 0.8855  loss_cls_stage2: 0.2355  loss_box_reg_stage2: 0.9667  loss_mask: 0.2689  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.2004  time: 2.2302  data_time: 0.0804  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:54:17 d2.utils.events]: \u001b[0m eta: 2:55:41  iter: 5279  total_loss: 3.425  loss_cls_stage0: 0.196  loss_box_reg_stage0: 0.4439  loss_cls_stage1: 0.1992  loss_box_reg_stage1: 0.8751  loss_cls_stage2: 0.2294  loss_box_reg_stage2: 0.8792  loss_mask: 0.2772  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.1822  time: 2.2301  data_time: 0.1150  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:55:04 d2.utils.events]: \u001b[0m eta: 2:55:06  iter: 5299  total_loss: 3.504  loss_cls_stage0: 0.2063  loss_box_reg_stage0: 0.4484  loss_cls_stage1: 0.2352  loss_box_reg_stage1: 0.8948  loss_cls_stage2: 0.256  loss_box_reg_stage2: 0.9648  loss_mask: 0.2841  loss_rpn_cls: 0.04779  loss_rpn_loc: 0.1721  time: 2.2306  data_time: 0.0912  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:55:50 d2.utils.events]: \u001b[0m eta: 2:54:31  iter: 5319  total_loss: 3.536  loss_cls_stage0: 0.2286  loss_box_reg_stage0: 0.4757  loss_cls_stage1: 0.2298  loss_box_reg_stage1: 0.8624  loss_cls_stage2: 0.2566  loss_box_reg_stage2: 0.8999  loss_mask: 0.2696  loss_rpn_cls: 0.05772  loss_rpn_loc: 0.1988  time: 2.2309  data_time: 0.0859  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:55:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:56:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 05:56:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 05:56:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 05:56:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 05:56:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 05:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0023 s/iter. Inference: 0.3325 s/iter. Eval: 0.0201 s/iter. Total: 0.3549 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 05:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0016 s/iter. Inference: 0.3331 s/iter. Eval: 0.0449 s/iter. Total: 0.3798 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/29 05:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0018 s/iter. Inference: 0.3340 s/iter. Eval: 0.0452 s/iter. Total: 0.3811 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 05:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0019 s/iter. Inference: 0.3375 s/iter. Eval: 0.0493 s/iter. Total: 0.3888 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 05:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0019 s/iter. Inference: 0.3396 s/iter. Eval: 0.0505 s/iter. Total: 0.3922 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 05:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0020 s/iter. Inference: 0.3414 s/iter. Eval: 0.0542 s/iter. Total: 0.3978 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 05:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0021 s/iter. Inference: 0.3417 s/iter. Eval: 0.0595 s/iter. Total: 0.4034 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 05:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0022 s/iter. Inference: 0.3416 s/iter. Eval: 0.0627 s/iter. Total: 0.4067 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 05:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0022 s/iter. Inference: 0.3408 s/iter. Eval: 0.0602 s/iter. Total: 0.4034 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 05:56:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.836335 (0.403762 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:56:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.339918 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 05:56:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 05:56:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2960452639549917\n",
      "\u001b[32m[12/29 05:56:52 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.29605, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 05:57:27 d2.utils.events]: \u001b[0m eta: 2:53:37  iter: 5339  total_loss: 3.476  loss_cls_stage0: 0.1781  loss_box_reg_stage0: 0.4641  loss_cls_stage1: 0.1879  loss_box_reg_stage1: 0.8775  loss_cls_stage2: 0.2185  loss_box_reg_stage2: 0.9767  loss_mask: 0.273  loss_rpn_cls: 0.0419  loss_rpn_loc: 0.1851  time: 2.2308  data_time: 0.0647  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:58:09 d2.utils.events]: \u001b[0m eta: 2:52:38  iter: 5359  total_loss: 3.481  loss_cls_stage0: 0.2048  loss_box_reg_stage0: 0.4804  loss_cls_stage1: 0.2187  loss_box_reg_stage1: 0.8824  loss_cls_stage2: 0.236  loss_box_reg_stage2: 0.9416  loss_mask: 0.2825  loss_rpn_cls: 0.06438  loss_rpn_loc: 0.1463  time: 2.2302  data_time: 0.0597  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:58:54 d2.utils.events]: \u001b[0m eta: 2:51:55  iter: 5379  total_loss: 3.422  loss_cls_stage0: 0.1892  loss_box_reg_stage0: 0.4755  loss_cls_stage1: 0.2072  loss_box_reg_stage1: 0.89  loss_cls_stage2: 0.2353  loss_box_reg_stage2: 0.9244  loss_mask: 0.2901  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.1935  time: 2.2305  data_time: 0.0764  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 05:59:41 d2.utils.events]: \u001b[0m eta: 2:51:17  iter: 5399  total_loss: 3.61  loss_cls_stage0: 0.2299  loss_box_reg_stage0: 0.4804  loss_cls_stage1: 0.2379  loss_box_reg_stage1: 0.916  loss_cls_stage2: 0.2662  loss_box_reg_stage2: 1.045  loss_mask: 0.2743  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.1675  time: 2.2309  data_time: 0.0767  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:00:26 d2.utils.events]: \u001b[0m eta: 2:50:38  iter: 5419  total_loss: 3.396  loss_cls_stage0: 0.1929  loss_box_reg_stage0: 0.465  loss_cls_stage1: 0.2001  loss_box_reg_stage1: 0.8499  loss_cls_stage2: 0.2314  loss_box_reg_stage2: 0.9418  loss_mask: 0.264  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.1681  time: 2.2309  data_time: 0.0841  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:01:12 d2.utils.events]: \u001b[0m eta: 2:50:04  iter: 5439  total_loss: 3.444  loss_cls_stage0: 0.244  loss_box_reg_stage0: 0.4729  loss_cls_stage1: 0.2642  loss_box_reg_stage1: 0.7923  loss_cls_stage2: 0.2797  loss_box_reg_stage2: 0.7875  loss_mask: 0.2885  loss_rpn_cls: 0.09088  loss_rpn_loc: 0.2111  time: 2.2312  data_time: 0.1280  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:01:56 d2.utils.events]: \u001b[0m eta: 2:49:37  iter: 5459  total_loss: 3.514  loss_cls_stage0: 0.2012  loss_box_reg_stage0: 0.4906  loss_cls_stage1: 0.2156  loss_box_reg_stage1: 0.8977  loss_cls_stage2: 0.253  loss_box_reg_stage2: 0.9384  loss_mask: 0.281  loss_rpn_cls: 0.0678  loss_rpn_loc: 0.1657  time: 2.2310  data_time: 0.1043  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:02:41 d2.utils.events]: \u001b[0m eta: 2:48:41  iter: 5479  total_loss: 3.318  loss_cls_stage0: 0.1731  loss_box_reg_stage0: 0.4272  loss_cls_stage1: 0.2018  loss_box_reg_stage1: 0.8404  loss_cls_stage2: 0.2292  loss_box_reg_stage2: 0.8839  loss_mask: 0.2682  loss_rpn_cls: 0.06295  loss_rpn_loc: 0.1903  time: 2.2310  data_time: 0.0994  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:03:26 d2.utils.events]: \u001b[0m eta: 2:47:49  iter: 5499  total_loss: 3.539  loss_cls_stage0: 0.2226  loss_box_reg_stage0: 0.4806  loss_cls_stage1: 0.2405  loss_box_reg_stage1: 0.8687  loss_cls_stage2: 0.2606  loss_box_reg_stage2: 0.864  loss_mask: 0.2872  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.1879  time: 2.2312  data_time: 0.0829  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:04:12 d2.utils.events]: \u001b[0m eta: 2:47:45  iter: 5519  total_loss: 3.363  loss_cls_stage0: 0.1925  loss_box_reg_stage0: 0.4439  loss_cls_stage1: 0.2184  loss_box_reg_stage1: 0.834  loss_cls_stage2: 0.2407  loss_box_reg_stage2: 0.9436  loss_mask: 0.2618  loss_rpn_cls: 0.05763  loss_rpn_loc: 0.1552  time: 2.2315  data_time: 0.1039  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:04:57 d2.utils.events]: \u001b[0m eta: 2:46:47  iter: 5539  total_loss: 3.307  loss_cls_stage0: 0.1874  loss_box_reg_stage0: 0.4345  loss_cls_stage1: 0.1975  loss_box_reg_stage1: 0.8022  loss_cls_stage2: 0.2275  loss_box_reg_stage2: 0.9268  loss_mask: 0.2651  loss_rpn_cls: 0.06222  loss_rpn_loc: 0.1717  time: 2.2315  data_time: 0.0967  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:05:44 d2.utils.events]: \u001b[0m eta: 2:46:22  iter: 5559  total_loss: 3.438  loss_cls_stage0: 0.2005  loss_box_reg_stage0: 0.4637  loss_cls_stage1: 0.2163  loss_box_reg_stage1: 0.902  loss_cls_stage2: 0.2394  loss_box_reg_stage2: 1.007  loss_mask: 0.2824  loss_rpn_cls: 0.04918  loss_rpn_loc: 0.1903  time: 2.2319  data_time: 0.1434  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:05:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:05:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 06:05:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 06:05:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 06:05:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:05:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 06:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0020 s/iter. Inference: 0.3324 s/iter. Eval: 0.0210 s/iter. Total: 0.3554 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 06:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0017 s/iter. Inference: 0.3328 s/iter. Eval: 0.0475 s/iter. Total: 0.3823 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 06:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0020 s/iter. Inference: 0.3319 s/iter. Eval: 0.0468 s/iter. Total: 0.3809 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 06:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0021 s/iter. Inference: 0.3325 s/iter. Eval: 0.0495 s/iter. Total: 0.3842 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/29 06:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0022 s/iter. Inference: 0.3347 s/iter. Eval: 0.0498 s/iter. Total: 0.3869 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 06:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0022 s/iter. Inference: 0.3349 s/iter. Eval: 0.0528 s/iter. Total: 0.3901 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 06:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0024 s/iter. Inference: 0.3364 s/iter. Eval: 0.0568 s/iter. Total: 0.3959 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 06:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0024 s/iter. Inference: 0.3369 s/iter. Eval: 0.0596 s/iter. Total: 0.3991 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 06:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0024 s/iter. Inference: 0.3371 s/iter. Eval: 0.0573 s/iter. Total: 0.3970 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 06:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.215309 (0.398408 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.336899 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:06:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 06:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.30271507217925503\n",
      "\u001b[32m[12/29 06:06:48 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30272, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 06:07:18 d2.utils.events]: \u001b[0m eta: 2:45:22  iter: 5579  total_loss: 3.431  loss_cls_stage0: 0.1808  loss_box_reg_stage0: 0.4656  loss_cls_stage1: 0.2114  loss_box_reg_stage1: 0.883  loss_cls_stage2: 0.2397  loss_box_reg_stage2: 0.9575  loss_mask: 0.2641  loss_rpn_cls: 0.05349  loss_rpn_loc: 0.1953  time: 2.2315  data_time: 0.0644  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:08:04 d2.utils.events]: \u001b[0m eta: 2:44:52  iter: 5599  total_loss: 3.436  loss_cls_stage0: 0.2161  loss_box_reg_stage0: 0.461  loss_cls_stage1: 0.2369  loss_box_reg_stage1: 0.8608  loss_cls_stage2: 0.2453  loss_box_reg_stage2: 0.9398  loss_mask: 0.2685  loss_rpn_cls: 0.05437  loss_rpn_loc: 0.1613  time: 2.2317  data_time: 0.0846  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:08:49 d2.utils.events]: \u001b[0m eta: 2:44:13  iter: 5619  total_loss: 3.336  loss_cls_stage0: 0.2019  loss_box_reg_stage0: 0.4604  loss_cls_stage1: 0.2276  loss_box_reg_stage1: 0.8183  loss_cls_stage2: 0.2559  loss_box_reg_stage2: 0.8264  loss_mask: 0.3011  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.2129  time: 2.2318  data_time: 0.1028  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:09:34 d2.utils.events]: \u001b[0m eta: 2:43:18  iter: 5639  total_loss: 3.526  loss_cls_stage0: 0.2301  loss_box_reg_stage0: 0.5058  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.8644  loss_cls_stage2: 0.2627  loss_box_reg_stage2: 0.9365  loss_mask: 0.2895  loss_rpn_cls: 0.05104  loss_rpn_loc: 0.2007  time: 2.2318  data_time: 0.0905  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:10:18 d2.utils.events]: \u001b[0m eta: 2:41:54  iter: 5659  total_loss: 3.389  loss_cls_stage0: 0.1724  loss_box_reg_stage0: 0.4517  loss_cls_stage1: 0.1981  loss_box_reg_stage1: 0.8587  loss_cls_stage2: 0.2076  loss_box_reg_stage2: 0.9952  loss_mask: 0.2598  loss_rpn_cls: 0.0467  loss_rpn_loc: 0.1852  time: 2.2317  data_time: 0.0664  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:11:02 d2.utils.events]: \u001b[0m eta: 2:41:06  iter: 5679  total_loss: 3.48  loss_cls_stage0: 0.2159  loss_box_reg_stage0: 0.4729  loss_cls_stage1: 0.2329  loss_box_reg_stage1: 0.8639  loss_cls_stage2: 0.2621  loss_box_reg_stage2: 0.9192  loss_mask: 0.2839  loss_rpn_cls: 0.06229  loss_rpn_loc: 0.2081  time: 2.2316  data_time: 0.0862  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:11:47 d2.utils.events]: \u001b[0m eta: 2:40:17  iter: 5699  total_loss: 3.456  loss_cls_stage0: 0.2078  loss_box_reg_stage0: 0.4514  loss_cls_stage1: 0.2187  loss_box_reg_stage1: 0.8514  loss_cls_stage2: 0.2489  loss_box_reg_stage2: 0.9488  loss_mask: 0.274  loss_rpn_cls: 0.05135  loss_rpn_loc: 0.1871  time: 2.2316  data_time: 0.0999  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:12:33 d2.utils.events]: \u001b[0m eta: 2:39:40  iter: 5719  total_loss: 3.404  loss_cls_stage0: 0.2076  loss_box_reg_stage0: 0.4495  loss_cls_stage1: 0.2072  loss_box_reg_stage1: 0.854  loss_cls_stage2: 0.2278  loss_box_reg_stage2: 0.9492  loss_mask: 0.2701  loss_rpn_cls: 0.05571  loss_rpn_loc: 0.1676  time: 2.2318  data_time: 0.1471  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:13:16 d2.utils.events]: \u001b[0m eta: 2:39:20  iter: 5739  total_loss: 3.284  loss_cls_stage0: 0.194  loss_box_reg_stage0: 0.457  loss_cls_stage1: 0.1963  loss_box_reg_stage1: 0.8582  loss_cls_stage2: 0.2251  loss_box_reg_stage2: 0.9812  loss_mask: 0.2746  loss_rpn_cls: 0.0373  loss_rpn_loc: 0.1713  time: 2.2316  data_time: 0.0679  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:14:02 d2.utils.events]: \u001b[0m eta: 2:38:53  iter: 5759  total_loss: 3.515  loss_cls_stage0: 0.2035  loss_box_reg_stage0: 0.4777  loss_cls_stage1: 0.2251  loss_box_reg_stage1: 0.872  loss_cls_stage2: 0.2354  loss_box_reg_stage2: 0.9061  loss_mask: 0.2804  loss_rpn_cls: 0.05813  loss_rpn_loc: 0.1761  time: 2.2318  data_time: 0.1198  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:14:45 d2.utils.events]: \u001b[0m eta: 2:38:23  iter: 5779  total_loss: 3.481  loss_cls_stage0: 0.2035  loss_box_reg_stage0: 0.4646  loss_cls_stage1: 0.1962  loss_box_reg_stage1: 0.867  loss_cls_stage2: 0.2349  loss_box_reg_stage2: 0.9149  loss_mask: 0.2788  loss_rpn_cls: 0.04764  loss_rpn_loc: 0.1742  time: 2.2315  data_time: 0.0772  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:15:27 d2.utils.events]: \u001b[0m eta: 2:37:21  iter: 5799  total_loss: 3.538  loss_cls_stage0: 0.2244  loss_box_reg_stage0: 0.4525  loss_cls_stage1: 0.2436  loss_box_reg_stage1: 0.8986  loss_cls_stage2: 0.2407  loss_box_reg_stage2: 0.9799  loss_mask: 0.2751  loss_rpn_cls: 0.05513  loss_rpn_loc: 0.1953  time: 2.2312  data_time: 0.0822  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:15:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:15:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1300, 1300), max_size=2000, sample_style='choice')]\n",
      "\u001b[32m[12/29 06:15:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 06:15:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[12/29 06:15:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from input/all/annotations_val.json\n",
      "\u001b[32m[12/29 06:15:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/29 06:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.3257 s/iter. Eval: 0.0222 s/iter. Total: 0.3494 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/29 06:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0018 s/iter. Inference: 0.3325 s/iter. Eval: 0.0546 s/iter. Total: 0.3892 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 06:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0020 s/iter. Inference: 0.3327 s/iter. Eval: 0.0529 s/iter. Total: 0.3879 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 06:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0024 s/iter. Inference: 0.3360 s/iter. Eval: 0.0544 s/iter. Total: 0.3930 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 06:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0025 s/iter. Inference: 0.3396 s/iter. Eval: 0.0549 s/iter. Total: 0.3972 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/29 06:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0028 s/iter. Inference: 0.3388 s/iter. Eval: 0.0576 s/iter. Total: 0.3994 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 06:16:25 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0028 s/iter. Inference: 0.3380 s/iter. Eval: 0.0619 s/iter. Total: 0.4029 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 06:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0030 s/iter. Inference: 0.3375 s/iter. Eval: 0.0657 s/iter. Total: 0.4064 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/29 06:16:36 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0029 s/iter. Inference: 0.3374 s/iter. Eval: 0.0634 s/iter. Total: 0.4039 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 06:16:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.941175 (0.404665 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:16:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.337547 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 06:16:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/29 06:16:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.30040701462999353\n",
      "\u001b[32m[12/29 06:16:39 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.30041, not better than best score 0.30303 @ iteration 4113.\n",
      "\u001b[32m[12/29 06:17:07 d2.utils.events]: \u001b[0m eta: 2:36:36  iter: 5819  total_loss: 3.29  loss_cls_stage0: 0.1992  loss_box_reg_stage0: 0.4486  loss_cls_stage1: 0.2101  loss_box_reg_stage1: 0.8013  loss_cls_stage2: 0.2526  loss_box_reg_stage2: 0.8367  loss_mask: 0.2683  loss_rpn_cls: 0.04435  loss_rpn_loc: 0.1859  time: 2.2315  data_time: 0.1147  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:17:50 d2.utils.events]: \u001b[0m eta: 2:35:50  iter: 5839  total_loss: 3.498  loss_cls_stage0: 0.2086  loss_box_reg_stage0: 0.4906  loss_cls_stage1: 0.236  loss_box_reg_stage1: 0.9038  loss_cls_stage2: 0.25  loss_box_reg_stage2: 0.904  loss_mask: 0.2935  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1813  time: 2.2313  data_time: 0.0905  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:18:36 d2.utils.events]: \u001b[0m eta: 2:35:16  iter: 5859  total_loss: 3.318  loss_cls_stage0: 0.2088  loss_box_reg_stage0: 0.4439  loss_cls_stage1: 0.2296  loss_box_reg_stage1: 0.802  loss_cls_stage2: 0.2342  loss_box_reg_stage2: 0.8208  loss_mask: 0.2742  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.1913  time: 2.2315  data_time: 0.0991  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:19:18 d2.utils.events]: \u001b[0m eta: 2:34:30  iter: 5879  total_loss: 3.39  loss_cls_stage0: 0.1812  loss_box_reg_stage0: 0.459  loss_cls_stage1: 0.1983  loss_box_reg_stage1: 0.8913  loss_cls_stage2: 0.229  loss_box_reg_stage2: 0.9875  loss_mask: 0.278  loss_rpn_cls: 0.05138  loss_rpn_loc: 0.1723  time: 2.2310  data_time: 0.0684  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:20:01 d2.utils.events]: \u001b[0m eta: 2:33:32  iter: 5899  total_loss: 3.442  loss_cls_stage0: 0.2133  loss_box_reg_stage0: 0.4403  loss_cls_stage1: 0.2163  loss_box_reg_stage1: 0.8618  loss_cls_stage2: 0.231  loss_box_reg_stage2: 0.9861  loss_mask: 0.2644  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.1692  time: 2.2307  data_time: 0.0601  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:20:45 d2.utils.events]: \u001b[0m eta: 2:32:39  iter: 5919  total_loss: 3.346  loss_cls_stage0: 0.1855  loss_box_reg_stage0: 0.4457  loss_cls_stage1: 0.2046  loss_box_reg_stage1: 0.8409  loss_cls_stage2: 0.2263  loss_box_reg_stage2: 0.9751  loss_mask: 0.2662  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1735  time: 2.2307  data_time: 0.0895  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:21:33 d2.utils.events]: \u001b[0m eta: 2:31:52  iter: 5939  total_loss: 3.453  loss_cls_stage0: 0.2097  loss_box_reg_stage0: 0.4658  loss_cls_stage1: 0.2297  loss_box_reg_stage1: 0.8717  loss_cls_stage2: 0.2456  loss_box_reg_stage2: 0.8962  loss_mask: 0.2709  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1837  time: 2.2313  data_time: 0.1157  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:22:17 d2.utils.events]: \u001b[0m eta: 2:31:02  iter: 5959  total_loss: 3.49  loss_cls_stage0: 0.2065  loss_box_reg_stage0: 0.4739  loss_cls_stage1: 0.2238  loss_box_reg_stage1: 0.8625  loss_cls_stage2: 0.2546  loss_box_reg_stage2: 0.9244  loss_mask: 0.2772  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.2126  time: 2.2312  data_time: 0.0771  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:23:00 d2.utils.events]: \u001b[0m eta: 2:29:58  iter: 5979  total_loss: 3.326  loss_cls_stage0: 0.1888  loss_box_reg_stage0: 0.4226  loss_cls_stage1: 0.2031  loss_box_reg_stage1: 0.8401  loss_cls_stage2: 0.2228  loss_box_reg_stage2: 0.9394  loss_mask: 0.2637  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.1699  time: 2.2309  data_time: 0.0757  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:23:43 d2.utils.events]: \u001b[0m eta: 2:29:10  iter: 5999  total_loss: 3.356  loss_cls_stage0: 0.1806  loss_box_reg_stage0: 0.438  loss_cls_stage1: 0.1853  loss_box_reg_stage1: 0.8405  loss_cls_stage2: 0.2172  loss_box_reg_stage2: 0.915  loss_mask: 0.2732  loss_rpn_cls: 0.05384  loss_rpn_loc: 0.1949  time: 2.2306  data_time: 0.0749  lr: 0.0005  max_mem: 29894M\n",
      "\u001b[32m[12/29 06:24:28 d2.utils.events]: \u001b[0m eta: 2:27:50  iter: 6019  total_loss: 3.558  loss_cls_stage0: 0.1886  loss_box_reg_stage0: 0.4681  loss_cls_stage1: 0.2212  loss_box_reg_stage1: 0.9111  loss_cls_stage2: 0.2533  loss_box_reg_stage2: 0.9785  loss_mask: 0.2861  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.1851  time: 2.2306  data_time: 0.1102  lr: 0.0005  max_mem: 29894M\n"
     ]
    }
   ],
   "source": [
    "# 2 的理论score最高\n",
    "for fold in range(1,2):\n",
    "  run()\n",
    "\n",
    "#run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cascade_finetune.ipynb",
   "provenance": [
    {
     "file_id": "1oh61M2NOWV8WgXX74dQV4br7Uja5-0hm",
     "timestamp": 1639284132292
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
